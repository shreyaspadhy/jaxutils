/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/chex/_src/pytypes.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.
  PyTreeDef = type(jax.tree_structure(None))
I0820 02:20:32.218929 139900878969920 xla_bridge.py:345] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0820 02:20:32.219272 139900878969920 xla_bridge.py:345] Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0820 02:20:32.219373 139900878969920 xla_bridge.py:345] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0820 02:20:32.275944 139900878969920 xla_bridge.py:345] Unable to initialize backend 'tpu': ABORTED: libtpu.so is already in use by process with pid 2097414. Not attempting to load libtpu.so in this process.
W0820 02:20:32.276207 139900878969920 xla_bridge.py:352] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0820 02:20:32.426078 139900878969920 dataset_info.py:385] Load dataset info from /home/shreyaspadhy_gmail_com/raw_data/cifar100/3.0.2
I0820 02:20:32.428871 139900878969920 dataset_builder.py:354] Reusing dataset cifar100 (/home/shreyaspadhy_gmail_com/raw_data/cifar100/3.0.2)
I0820 02:20:32.490485 139900878969920 logging_logger.py:35] Constructing tf.data.Dataset cifar100 for split _EvenSplit(split='train', index=0, count=1, drop_remainder=True), from /home/shreyaspadhy_gmail_com/raw_data/cifar100/3.0.2
I0820 02:20:32.569006 139900878969920 logging_logger.py:35] Constructing tf.data.Dataset cifar100 for split _EvenSplit(split='test', index=0, count=1, drop_remainder=True), from /home/shreyaspadhy_gmail_com/raw_data/cifar100/3.0.2
I0820 02:20:33.027750 139900878969920 api.py:459] Features before preprocessing: {'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'string[]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.059439 139900878969920 api.py:459] Features after op Decode(channels=3, key='image', key_result=None):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'uint8[None, None, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.184469 139900878969920 api.py:459] Features after op RandomCropWithPad(crop_size=32, padding=4, key='image', key_result=None, rng_key='rng'):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'uint8[32, 32, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.227079 139900878969920 api.py:459] Features after op FlipLr(key='image', key_result=None, rng_key='rng'):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'uint8[32, 32, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.288503 139900878969920 api.py:459] Features after op ValueRange(vmin=0, vmax=1, in_min=0, in_max=255.0, clip_values=False, key='image', key_result=None):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'float32[32, 32, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.328192 139900878969920 api.py:459] Features after op Normalize(mean=(0.5071, 0.4866, 0.4409), std=(0.2673, 0.2564, 0.2762), key='image', key_result=None):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'float32[32, 32, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.328852 139900878969920 api.py:459] Features after preprocessing: {'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'float32[32, 32, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
W0820 02:20:33.759041 139900878969920 api.py:459] Removing feature ('id',) because dtype <dtype: 'string'> is not supported in JAX.
I0820 02:20:33.946040 139900878969920 api.py:459] Features before preprocessing: {'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'string[]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.947655 139900878969920 api.py:459] Features after op Decode(channels=3, key='image', key_result=None):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'uint8[None, None, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.952833 139900878969920 api.py:459] Features after op ValueRange(vmin=0, vmax=1, in_min=0, in_max=255.0, clip_values=False, key='image', key_result=None):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'float32[None, None, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.955458 139900878969920 api.py:459] Features after op Normalize(mean=(0.5071, 0.4866, 0.4409), std=(0.2673, 0.2564, 0.2762), key='image', key_result=None):
{'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'float32[None, None, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
I0820 02:20:33.956031 139900878969920 api.py:459] Features after preprocessing: {'coarse_label': 'int64[]', 'id': 'string[]', 'image': 'float32[None, None, 3]', 'label': 'int64[]', 'rng': 'int32[2]'}
W0820 02:20:33.957258 139900878969920 api.py:459] Removing feature ('id',) because dtype <dtype: 'string'> is not supported in JAX.
I0820 02:20:38.127812 139900878969920 checkpoints.py:253] Restoring checkpoint from /home/shreyaspadhy_gmail_com/converted_models/cifar100/0/checkpoint_289
cpu
1 1
8 cores of TPU ( Local devices in Jax ):
TFRT_CPU_0
length params :  11 1
checkpoint_dir: /home/shreyaspadhy_gmail_com/converted_models/cifar100/0
test
dict_keys(['step', 'params', 'opt_state', 'model_state'])
resturn all
test
  0%|          | 0/300 [00:00<?, ?it/s]/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/flax/core/scope.py:740: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  abs_value_flat = jax.tree_leaves(abs_value)
/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/flax/core/scope.py:741: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.
  value_flat = jax.tree_leaves(value)
/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py:592: UserWarning: Some donated buffers were not usable: ShapedArray(int32[], weak_type=True), ShapedArray(float32[100]), ShapedArray(float32[512,100]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,64,128]), ShapedArray(float32[3,3,128,128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,128]), ShapedArray(float32[3,3,128,128]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,128,256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[3,3,256,512]), ShapedArray(float32[3,3,512,512]), ShapedArray(float32[1,1,256,512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[3,3,512,512]), ShapedArray(float32[3,3,512,512]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,3,64]), ShapedArray(int32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[100]), ShapedArray(float32[512,100]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[3,3,64,64]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,64,128]), ShapedArray(float32[3,3,128,128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,128]), ShapedArray(float32[3,3,128,128]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,128,256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[3,3,256,512]), ShapedArray(float32[3,3,512,512]), ShapedArray(float32[1,1,256,512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[3,3,512,512]), ShapedArray(float32[3,3,512,512]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,3,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[512]), ShapedArray(float32[64]), ShapedArray(float32[64]).
Donation is not implemented for cpu.
See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.
  warnings.warn(f"Some donated buffers were not usable: {', '.join(unused_donations)}.\n{msg}")
  0%|          | 0/300 [00:25<?, ?it/s]
Traceback (most recent call last):
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1087, in _lower_jaxpr_to_fun_cached
    func_op = ctx.cached_call_jaxpr_lowerings[key]
KeyError: ('train_step', { lambda ; a:i32[] b:f32[100] c:f32[512,100] d:f32[64] e:f32[64] f:f32[64] g:f32[64]
    h:f32[3,3,64,64] i:f32[3,3,64,64] j:f32[64] k:f32[64] l:f32[64] m:f32[64] n:f32[3,3,64,64]
    o:f32[3,3,64,64] p:f32[128] q:f32[128] r:f32[128] s:f32[128] t:f32[3,3,64,128]
    u:f32[3,3,128,128] v:f32[1,1,64,128] w:f32[128] x:f32[128] y:f32[128] z:f32[128]
    ba:f32[128] bb:f32[128] bc:f32[3,3,128,128] bd:f32[3,3,128,128] be:f32[256] bf:f32[256]
    bg:f32[256] bh:f32[256] bi:f32[3,3,128,256] bj:f32[3,3,256,256] bk:f32[1,1,128,256]
    bl:f32[256] bm:f32[256] bn:f32[256] bo:f32[256] bp:f32[256] bq:f32[256] br:f32[3,3,256,256]
    bs:f32[3,3,256,256] bt:f32[512] bu:f32[512] bv:f32[512] bw:f32[512] bx:f32[3,3,256,512]
    by:f32[3,3,512,512] bz:f32[1,1,256,512] ca:f32[512] cb:f32[512] cc:f32[512] cd:f32[512]
    ce:f32[512] cf:f32[512] cg:f32[3,3,512,512] ch:f32[3,3,512,512] ci:f32[64] cj:f32[64]
    ck:f32[3,3,3,64] cl:i32[] cm:f32[] cn:f32[] co:f32[100] cp:f32[512,100] cq:f32[64]
    cr:f32[64] cs:f32[64] ct:f32[64] cu:f32[3,3,64,64] cv:f32[3,3,64,64] cw:f32[64]
    cx:f32[64] cy:f32[64] cz:f32[64] da:f32[3,3,64,64] db:f32[3,3,64,64] dc:f32[128]
    dd:f32[128] de:f32[128] df:f32[128] dg:f32[3,3,64,128] dh:f32[3,3,128,128] di:f32[1,1,64,128]
    dj:f32[128] dk:f32[128] dl:f32[128] dm:f32[128] dn:f32[128] do:f32[128] dp:f32[3,3,128,128]
    dq:f32[3,3,128,128] dr:f32[256] ds:f32[256] dt:f32[256] du:f32[256] dv:f32[3,3,128,256]
    dw:f32[3,3,256,256] dx:f32[1,1,128,256] dy:f32[256] dz:f32[256] ea:f32[256] eb:f32[256]
    ec:f32[256] ed:f32[256] ee:f32[3,3,256,256] ef:f32[3,3,256,256] eg:f32[512] eh:f32[512]
    ei:f32[512] ej:f32[512] ek:f32[3,3,256,512] el:f32[3,3,512,512] em:f32[1,1,256,512]
    en:f32[512] eo:f32[512] ep:f32[512] eq:f32[512] er:f32[512] es:f32[512] et:f32[3,3,512,512]
    eu:f32[3,3,512,512] ev:f32[64] ew:f32[64] ex:f32[3,3,3,64] ey:f32[64] ez:f32[64]
    fa:f32[64] fb:f32[64] fc:f32[64] fd:f32[64] fe:f32[64] ff:f32[64] fg:f32[128]
    fh:f32[128] fi:f32[128] fj:f32[128] fk:f32[128] fl:f32[128] fm:f32[128] fn:f32[128]
    fo:f32[128] fp:f32[128] fq:f32[256] fr:f32[256] fs:f32[256] ft:f32[256] fu:f32[256]
    fv:f32[256] fw:f32[256] fx:f32[256] fy:f32[256] fz:f32[256] ga:f32[512] gb:f32[512]
    gc:f32[512] gd:f32[512] ge:f32[512] gf:f32[512] gg:f32[512] gh:f32[512] gi:f32[512]
    gj:f32[512] gk:f32[64] gl:f32[64] gm:f32[200,32,32,3] gn:i32[200]. let
    _:f32[] go:i32[] gp:i32[] gq:f32[] gr:f32[64] gs:f32[64] gt:f32[64] gu:f32[64]
      gv:f32[64] gw:f32[64] gx:f32[64] gy:f32[64] gz:f32[128] ha:f32[128] hb:f32[128]
      hc:f32[128] hd:f32[128] he:f32[128] hf:f32[128] hg:f32[128] hh:f32[128] hi:f32[128]
      hj:f32[256] hk:f32[256] hl:f32[256] hm:f32[256] hn:f32[256] ho:f32[256] hp:f32[256]
      hq:f32[256] hr:f32[256] hs:f32[256] ht:f32[512] hu:f32[512] hv:f32[512] hw:f32[512]
      hx:f32[512] hy:f32[512] hz:f32[512] ia:f32[512] ib:f32[512] ic:f32[512] id:f32[64]
      ie:f32[64] if:f32[200,100] ig:f32[200,1] ih:f32[200,100] ii:bool[200,4,4,512]
      ij:f32[200,4,4,512] ik:f32[1,1,1,512] il:f32[200,4,4,512] im:bool[200,4,4,512]
      in:f32[200,4,4,512] io:f32[1,1,1,512] ip:f32[200,4,4,512] iq:bool[200,4,4,512]
      ir:f32[200,4,4,512] is:f32[1,1,1,512] it:f32[200,4,4,512] iu:bool[200,8,8,256]
      iv:f32[200,8,8,256] iw:f32[1,1,1,256] ix:f32[200,8,8,256] iy:bool[200,8,8,256]
      iz:f32[200,8,8,256] ja:f32[1,1,1,256] jb:f32[200,8,8,256] jc:bool[200,8,8,256]
      jd:f32[200,8,8,256] je:f32[1,1,1,256] jf:f32[200,8,8,256] jg:bool[200,16,16,128]
      jh:f32[200,16,16,128] ji:f32[1,1,1,128] jj:f32[200,16,16,128] jk:bool[200,16,16,128]
      jl:f32[200,16,16,128] jm:f32[1,1,1,128] jn:f32[200,16,16,128] jo:bool[200,16,16,128]
      jp:f32[200,16,16,128] jq:f32[1,1,1,128] jr:f32[200,16,16,128] js:bool[200,32,32,64]
      jt:f32[200,32,32,64] ju:f32[1,1,1,64] jv:f32[200,32,32,64] jw:bool[200,32,32,64]
      jx:f32[200,32,32,64] jy:f32[1,1,1,64] jz:f32[200,32,32,64] ka:bool[200,32,32,64]
      kb:f32[200,32,32,64] kc:f32[1,1,1,64] kd:f32[200,32,32,64] ke:bool[200,32,32,64]
      kf:f32[200,32,32,64] kg:f32[1,1,1,64] kh:f32[200,32,32,64] ki:bool[200,32,32,64]
      kj:f32[200,32,32,64] kk:f32[1,1,1,64] kl:f32[200,32,32,64] km:f32[200,32,32,3]
      kn:f32[1,1,1,64] ko:f32[1,1,1,64] kp:f32[64] kq:f32[200,32,32,64] kr:f32[64]
      ks:f32[1,1,1,64] kt:f32[200,32,32,64] ku:f32[1,1,1,64] kv:f32[1,1,1,64] kw:f32[64]
      kx:f32[200,32,32,64] ky:f32[64] kz:f32[1,1,1,64] la:f32[200,32,32,64] lb:f32[1,1,1,64]
      lc:f32[1,1,1,64] ld:f32[64] le:f32[200,32,32,64] lf:f32[64] lg:f32[1,1,1,64]
      lh:f32[200,32,32,64] li:f32[1,1,1,64] lj:f32[1,1,1,64] lk:f32[64] ll:f32[200,32,32,64]
      lm:f32[64] ln:f32[1,1,1,64] lo:f32[200,32,32,64] lp:f32[1,1,1,64] lq:f32[1,1,1,64]
      lr:f32[64] ls:f32[200,32,32,64] lt:f32[64] lu:f32[1,1,1,64] lv:f32[200,32,32,64]
      lw:f32[1,1,1,128] lx:f32[1,1,1,128] ly:f32[128] lz:f32[200,16,16,128] ma:f32[128]
      mb:f32[1,1,1,128] mc:f32[1,1,1,128] md:f32[200,16,16,128] me:bool[200,16,16,128]
      mf:f32[200,16,16,128] mg:f32[1,1,1,128] mh:f32[200,16,16,128] mi:f32[1,1,1,128]
      mj:f32[1,1,1,128] mk:f32[128] ml:f32[200,16,16,128] mm:f32[128] mn:f32[1,1,1,128]
      mo:f32[200,16,16,128] mp:f32[1,1,1,128] mq:f32[1,1,1,128] mr:f32[128] ms:f32[200,16,16,128]
      mt:f32[128] mu:f32[1,1,1,128] mv:f32[200,16,16,128] mw:f32[1,1,1,128] mx:f32[1,1,1,128]
      my:f32[128] mz:f32[200,16,16,128] na:f32[128] nb:f32[1,1,1,128] nc:f32[200,16,16,128]
      nd:f32[1,1,1,128] ne:f32[1,1,1,128] nf:f32[128] ng:f32[200,16,16,128] nh:f32[128]
      ni:f32[1,1,1,128] nj:f32[200,16,16,128] nk:f32[1,1,1,256] nl:f32[1,1,1,256]
      nm:f32[256] nn:f32[200,8,8,256] no:f32[256] np:f32[1,1,1,256] nq:f32[1,1,1,256]
      nr:f32[200,8,8,256] ns:bool[200,8,8,256] nt:f32[200,8,8,256] nu:f32[1,1,1,256]
      nv:f32[200,8,8,256] nw:f32[1,1,1,256] nx:f32[1,1,1,256] ny:f32[256] nz:f32[200,8,8,256]
      oa:f32[256] ob:f32[1,1,1,256] oc:f32[200,8,8,256] od:f32[1,1,1,256] oe:f32[1,1,1,256]
      of:f32[256] og:f32[200,8,8,256] oh:f32[256] oi:f32[1,1,1,256] oj:f32[200,8,8,256]
      ok:f32[1,1,1,256] ol:f32[1,1,1,256] om:f32[256] on:f32[200,8,8,256] oo:f32[256]
      op:f32[1,1,1,256] oq:f32[200,8,8,256] or:f32[1,1,1,256] os:f32[1,1,1,256] ot:f32[256]
      ou:f32[200,8,8,256] ov:f32[256] ow:f32[1,1,1,256] ox:f32[200,8,8,256] oy:f32[1,1,1,512]
      oz:f32[1,1,1,512] pa:f32[512] pb:f32[200,4,4,512] pc:f32[512] pd:f32[1,1,1,512]
      pe:f32[1,1,1,512] pf:f32[200,4,4,512] pg:bool[200,4,4,512] ph:f32[200,4,4,512]
      pi:f32[1,1,1,512] pj:f32[200,4,4,512] pk:f32[1,1,1,512] pl:f32[1,1,1,512] pm:f32[512]
      pn:f32[200,4,4,512] po:f32[512] pp:f32[1,1,1,512] pq:f32[200,4,4,512] pr:f32[1,1,1,512]
      ps:f32[1,1,1,512] pt:f32[512] pu:f32[200,4,4,512] pv:f32[512] pw:f32[1,1,1,512]
      px:f32[200,4,4,512] py:f32[1,1,1,512] pz:f32[1,1,1,512] qa:f32[512] qb:f32[200,4,4,512]
      qc:f32[512] qd:f32[1,1,1,512] qe:f32[200,4,4,512] qf:f32[1,1,1,512] qg:f32[1,1,1,512]
      qh:f32[512] qi:f32[200,4,4,512] qj:f32[512] qk:f32[1,1,1,512] ql:f32[200,512]
      qm:f32[] qn:f32[] qo:f32[] qp:f32[] qq:f32[] qr:f32[] qs:f32[] qt:f32[] qu:f32[]
      qv:f32[] qw:f32[] qx:f32[] qy:f32[] qz:f32[] ra:f32[] rb:f32[] rc:f32[] rd:f32[]
      re:f32[] rf:f32[] rg:f32[] rh:f32[] ri:f32[] rj:f32[] rk:f32[] rl:f32[] rm:f32[]
      rn:f32[] ro:f32[] rp:f32[] rq:f32[] rr:f32[] rs:f32[] rt:f32[] ru:f32[] rv:f32[]
      rw:f32[] rx:f32[] ry:f32[] rz:f32[] = xla_call[
      call_jaxpr={ lambda ; sa:f32[200,32,32,3] sb:i32[200] sc:f32[100] sd:f32[512,100]
          se:f32[64] sf:f32[64] sg:f32[64] sh:f32[64] si:f32[3,3,64,64] sj:f32[3,3,64,64]
          sk:f32[64] sl:f32[64] sm:f32[64] sn:f32[64] so:f32[3,3,64,64] sp:f32[3,3,64,64]
          sq:f32[128] sr:f32[128] ss:f32[128] st:f32[128] su:f32[3,3,64,128] sv:f32[3,3,128,128]
          sw:f32[1,1,64,128] sx:f32[128] sy:f32[128] sz:f32[128] ta:f32[128] tb:f32[128]
          tc:f32[128] td:f32[3,3,128,128] te:f32[3,3,128,128] tf:f32[256] tg:f32[256]
          th:f32[256] ti:f32[256] tj:f32[3,3,128,256] tk:f32[3,3,256,256] tl:f32[1,1,128,256]
          tm:f32[256] tn:f32[256] to:f32[256] tp:f32[256] tq:f32[256] tr:f32[256]
          ts:f32[3,3,256,256] tt:f32[3,3,256,256] tu:f32[512] tv:f32[512] tw:f32[512]
          tx:f32[512] ty:f32[3,3,256,512] tz:f32[3,3,512,512] ua:f32[1,1,256,512]
          ub:f32[512] uc:f32[512] ud:f32[512] ue:f32[512] uf:f32[512] ug:f32[512]
          uh:f32[3,3,512,512] ui:f32[3,3,512,512] uj:f32[64] uk:f32[64] ul:f32[3,3,3,64]
          um:f32[64] un:f32[64] uo:f32[64] up:f32[64] uq:f32[64] ur:f32[64] us:f32[64]
          ut:f32[64] uu:f32[128] uv:f32[128] uw:f32[128] ux:f32[128] uy:f32[128]
          uz:f32[128] va:f32[128] vb:f32[128] vc:f32[128] vd:f32[128] ve:f32[256]
          vf:f32[256] vg:f32[256] vh:f32[256] vi:f32[256] vj:f32[256] vk:f32[256]
          vl:f32[256] vm:f32[256] vn:f32[256] vo:f32[512] vp:f32[512] vq:f32[512]
          vr:f32[512] vs:f32[512] vt:f32[512] vu:f32[512] vv:f32[512] vw:f32[512]
          vx:f32[512] vy:f32[64] vz:f32[64]. let
          wa:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 3)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 3, 64)
            window_strides=(1, 1)
          ] sa ul
          wb:f32[64] = reduce_sum[axes=(0, 1, 2)] wa
          wc:f32[64] = div wb 204800.0
          wd:f32[200,32,32,64] = integer_pow[y=2] wa
          we:f32[200,32,32,64] = integer_pow[y=1] wa
          wf:f32[200,32,32,64] = mul 2.0 we
          wg:f32[64] = reduce_sum[axes=(0, 1, 2)] wd
          wh:f32[64] = div wg 204800.0
          wi:f32[64] = integer_pow[y=2] wc
          wj:f32[64] = integer_pow[y=1] wc
          wk:f32[64] = mul 2.0 wj
          wl:f32[64] = sub wh wi
          wm:f32[64] = max 0.0 wl
          wn:bool[64] = eq wl wm
          wo:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          wp:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 0.0
          wq:f32[64] = select_n wn wp wo
          wr:bool[64] = eq 0.0 wm
          ws:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 2.0
          wt:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          wu:f32[64] = select_n wr wt ws
          wv:f32[64] = div wq wu
          ww:f32[64] = mul 0.8999999761581421 vy
          wx:f32[64] = mul 0.10000000149011612 wc
          wy:f32[64] = add ww wx
          wz:f32[64] = mul 0.8999999761581421 vz
          xa:f32[64] = mul 0.10000000149011612 wm
          xb:f32[64] = add wz xa
          xc:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] wc
          xd:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] wm
          xe:f32[200,32,32,64] = sub wa xc
          xf:f32[1,1,1,64] = add xd 9.999999747378752e-06
          xg:f32[1,1,1,64] = rsqrt xf
          xh:f32[1,1,1,64] = div xg xf
          xi:f32[1,1,1,64] = mul -0.5 xh
          xj:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] uk
          xk:f32[1,1,1,64] = mul xg xj
          xl:f32[200,32,32,64] = mul xe xk
          xm:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] uj
          xn:f32[200,32,32,64] = add xl xm
          xo:f32[200,32,32,64] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; xp:f32[200,32,32,64]. let
                xq:f32[200,32,32,64] = xla_call[
                  call_jaxpr={ lambda ; xr:f32[200,32,32,64]. let
                      xs:f32[200,32,32,64] = max xr 0.0
                    in (xs,) }
                  name=relu
                ] xp
              in (xq,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5e040>
            num_consts=0
          ] xn
          xt:bool[200,32,32,64] = gt xn 0.0
          xu:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          xv:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] xo si
          xw:f32[64] = reduce_sum[axes=(0, 1, 2)] xv
          xx:f32[64] = div xw 204800.0
          xy:f32[200,32,32,64] = integer_pow[y=2] xv
          xz:f32[200,32,32,64] = integer_pow[y=1] xv
          ya:f32[200,32,32,64] = mul 2.0 xz
          yb:f32[64] = reduce_sum[axes=(0, 1, 2)] xy
          yc:f32[64] = div yb 204800.0
          yd:f32[64] = integer_pow[y=2] xx
          ye:f32[64] = integer_pow[y=1] xx
          yf:f32[64] = mul 2.0 ye
          yg:f32[64] = sub yc yd
          yh:f32[64] = max 0.0 yg
          yi:bool[64] = eq yg yh
          yj:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          yk:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 0.0
          yl:f32[64] = select_n yi yk yj
          ym:bool[64] = eq 0.0 yh
          yn:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 2.0
          yo:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          yp:f32[64] = select_n ym yo yn
          yq:f32[64] = div yl yp
          yr:f32[64] = mul 0.8999999761581421 um
          ys:f32[64] = mul 0.10000000149011612 xx
          yt:f32[64] = add yr ys
          yu:f32[64] = mul 0.8999999761581421 un
          yv:f32[64] = mul 0.10000000149011612 yh
          yw:f32[64] = add yu yv
          yx:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] xx
          yy:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] yh
          yz:f32[200,32,32,64] = sub xv yx
          za:f32[1,1,1,64] = add yy 9.999999747378752e-06
          zb:f32[1,1,1,64] = rsqrt za
          zc:f32[1,1,1,64] = div zb za
          zd:f32[1,1,1,64] = mul -0.5 zc
          ze:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sf
          zf:f32[1,1,1,64] = mul zb ze
          zg:f32[200,32,32,64] = mul yz zf
          zh:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] se
          zi:f32[200,32,32,64] = add zg zh
          zj:f32[200,32,32,64] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; zk:f32[200,32,32,64]. let
                zl:f32[200,32,32,64] = xla_call[
                  call_jaxpr={ lambda ; zm:f32[200,32,32,64]. let
                      zn:f32[200,32,32,64] = max zm 0.0
                    in (zn,) }
                  name=relu
                ] zk
              in (zl,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5e430>
            num_consts=0
          ] zi
          zo:bool[200,32,32,64] = gt zi 0.0
          zp:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          zq:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] zj sj
          zr:f32[64] = reduce_sum[axes=(0, 1, 2)] zq
          zs:f32[64] = div zr 204800.0
          zt:f32[200,32,32,64] = integer_pow[y=2] zq
          zu:f32[200,32,32,64] = integer_pow[y=1] zq
          zv:f32[200,32,32,64] = mul 2.0 zu
          zw:f32[64] = reduce_sum[axes=(0, 1, 2)] zt
          zx:f32[64] = div zw 204800.0
          zy:f32[64] = integer_pow[y=2] zs
          zz:f32[64] = integer_pow[y=1] zs
          baa:f32[64] = mul 2.0 zz
          bab:f32[64] = sub zx zy
          bac:f32[64] = max 0.0 bab
          bad:bool[64] = eq bab bac
          bae:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          baf:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 0.0
          bag:f32[64] = select_n bad baf bae
          bah:bool[64] = eq 0.0 bac
          bai:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 2.0
          baj:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          bak:f32[64] = select_n bah baj bai
          bal:f32[64] = div bag bak
          bam:f32[64] = mul 0.8999999761581421 uo
          ban:f32[64] = mul 0.10000000149011612 zs
          bao:f32[64] = add bam ban
          bap:f32[64] = mul 0.8999999761581421 up
          baq:f32[64] = mul 0.10000000149011612 bac
          bar:f32[64] = add bap baq
          bas:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] zs
          bat:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bac
          bau:f32[200,32,32,64] = sub zq bas
          bav:f32[1,1,1,64] = add bat 9.999999747378752e-06
          baw:f32[1,1,1,64] = rsqrt bav
          bax:f32[1,1,1,64] = div baw bav
          bay:f32[1,1,1,64] = mul -0.5 bax
          baz:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sh
          bba:f32[1,1,1,64] = mul baw baz
          bbb:f32[200,32,32,64] = mul bau bba
          bbc:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sg
          bbd:f32[200,32,32,64] = add bbb bbc
          bbe:f32[200,32,32,64] = add xo bbd
          bbf:f32[200,32,32,64] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bbg:f32[200,32,32,64]. let
                bbh:f32[200,32,32,64] = xla_call[
                  call_jaxpr={ lambda ; bbi:f32[200,32,32,64]. let
                      bbj:f32[200,32,32,64] = max bbi 0.0
                    in (bbj,) }
                  name=relu
                ] bbg
              in (bbh,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5e3a0>
            num_consts=0
          ] bbe
          bbk:bool[200,32,32,64] = gt bbe 0.0
          bbl:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          bbm:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] bbf so
          bbn:f32[64] = reduce_sum[axes=(0, 1, 2)] bbm
          bbo:f32[64] = div bbn 204800.0
          bbp:f32[200,32,32,64] = integer_pow[y=2] bbm
          bbq:f32[200,32,32,64] = integer_pow[y=1] bbm
          bbr:f32[200,32,32,64] = mul 2.0 bbq
          bbs:f32[64] = reduce_sum[axes=(0, 1, 2)] bbp
          bbt:f32[64] = div bbs 204800.0
          bbu:f32[64] = integer_pow[y=2] bbo
          bbv:f32[64] = integer_pow[y=1] bbo
          bbw:f32[64] = mul 2.0 bbv
          bbx:f32[64] = sub bbt bbu
          bby:f32[64] = max 0.0 bbx
          bbz:bool[64] = eq bbx bby
          bca:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          bcb:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 0.0
          bcc:f32[64] = select_n bbz bcb bca
          bcd:bool[64] = eq 0.0 bby
          bce:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 2.0
          bcf:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          bcg:f32[64] = select_n bcd bcf bce
          bch:f32[64] = div bcc bcg
          bci:f32[64] = mul 0.8999999761581421 uq
          bcj:f32[64] = mul 0.10000000149011612 bbo
          bck:f32[64] = add bci bcj
          bcl:f32[64] = mul 0.8999999761581421 ur
          bcm:f32[64] = mul 0.10000000149011612 bby
          bcn:f32[64] = add bcl bcm
          bco:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bbo
          bcp:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bby
          bcq:f32[200,32,32,64] = sub bbm bco
          bcr:f32[1,1,1,64] = add bcp 9.999999747378752e-06
          bcs:f32[1,1,1,64] = rsqrt bcr
          bct:f32[1,1,1,64] = div bcs bcr
          bcu:f32[1,1,1,64] = mul -0.5 bct
          bcv:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sl
          bcw:f32[1,1,1,64] = mul bcs bcv
          bcx:f32[200,32,32,64] = mul bcq bcw
          bcy:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sk
          bcz:f32[200,32,32,64] = add bcx bcy
          bda:f32[200,32,32,64] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bdb:f32[200,32,32,64]. let
                bdc:f32[200,32,32,64] = xla_call[
                  call_jaxpr={ lambda ; bdd:f32[200,32,32,64]. let
                      bde:f32[200,32,32,64] = max bdd 0.0
                    in (bde,) }
                  name=relu
                ] bdb
              in (bdc,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5e5e0>
            num_consts=0
          ] bcz
          bdf:bool[200,32,32,64] = gt bcz 0.0
          bdg:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          bdh:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] bda sp
          bdi:f32[64] = reduce_sum[axes=(0, 1, 2)] bdh
          bdj:f32[64] = div bdi 204800.0
          bdk:f32[200,32,32,64] = integer_pow[y=2] bdh
          bdl:f32[200,32,32,64] = integer_pow[y=1] bdh
          bdm:f32[200,32,32,64] = mul 2.0 bdl
          bdn:f32[64] = reduce_sum[axes=(0, 1, 2)] bdk
          bdo:f32[64] = div bdn 204800.0
          bdp:f32[64] = integer_pow[y=2] bdj
          bdq:f32[64] = integer_pow[y=1] bdj
          bdr:f32[64] = mul 2.0 bdq
          bds:f32[64] = sub bdo bdp
          bdt:f32[64] = max 0.0 bds
          bdu:bool[64] = eq bds bdt
          bdv:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          bdw:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 0.0
          bdx:f32[64] = select_n bdu bdw bdv
          bdy:bool[64] = eq 0.0 bdt
          bdz:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 2.0
          bea:f32[64] = broadcast_in_dim[broadcast_dimensions=() shape=(64,)] 1.0
          beb:f32[64] = select_n bdy bea bdz
          bec:f32[64] = div bdx beb
          bed:f32[64] = mul 0.8999999761581421 us
          bee:f32[64] = mul 0.10000000149011612 bdj
          bef:f32[64] = add bed bee
          beg:f32[64] = mul 0.8999999761581421 ut
          beh:f32[64] = mul 0.10000000149011612 bdt
          bei:f32[64] = add beg beh
          bej:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bdj
          bek:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bdt
          bel:f32[200,32,32,64] = sub bdh bej
          bem:f32[1,1,1,64] = add bek 9.999999747378752e-06
          ben:f32[1,1,1,64] = rsqrt bem
          beo:f32[1,1,1,64] = div ben bem
          bep:f32[1,1,1,64] = mul -0.5 beo
          beq:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sn
          ber:f32[1,1,1,64] = mul ben beq
          bes:f32[200,32,32,64] = mul bel ber
          bet:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] sm
          beu:f32[200,32,32,64] = add bes bet
          bev:f32[200,32,32,64] = add bbf beu
          bew:f32[200,32,32,64] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bex:f32[200,32,32,64]. let
                bey:f32[200,32,32,64] = xla_call[
                  call_jaxpr={ lambda ; bez:f32[200,32,32,64]. let
                      bfa:f32[200,32,32,64] = max bez 0.0
                    in (bfa,) }
                  name=relu
                ] bex
              in (bey,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5e820>
            num_consts=0
          ] bev
          bfb:bool[200,32,32,64] = gt bev 0.0
          bfc:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          bfd:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 128)
            window_strides=(2, 2)
          ] bew su
          bfe:f32[128] = reduce_sum[axes=(0, 1, 2)] bfd
          bff:f32[128] = div bfe 51200.0
          bfg:f32[200,16,16,128] = integer_pow[y=2] bfd
          bfh:f32[200,16,16,128] = integer_pow[y=1] bfd
          bfi:f32[200,16,16,128] = mul 2.0 bfh
          bfj:f32[128] = reduce_sum[axes=(0, 1, 2)] bfg
          bfk:f32[128] = div bfj 51200.0
          bfl:f32[128] = integer_pow[y=2] bff
          bfm:f32[128] = integer_pow[y=1] bff
          bfn:f32[128] = mul 2.0 bfm
          bfo:f32[128] = sub bfk bfl
          bfp:f32[128] = max 0.0 bfo
          bfq:bool[128] = eq bfo bfp
          bfr:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bfs:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 0.0
          bft:f32[128] = select_n bfq bfs bfr
          bfu:bool[128] = eq 0.0 bfp
          bfv:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 2.0
          bfw:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bfx:f32[128] = select_n bfu bfw bfv
          bfy:f32[128] = div bft bfx
          bfz:f32[128] = mul 0.8999999761581421 uu
          bga:f32[128] = mul 0.10000000149011612 bff
          bgb:f32[128] = add bfz bga
          bgc:f32[128] = mul 0.8999999761581421 uv
          bgd:f32[128] = mul 0.10000000149011612 bfp
          bge:f32[128] = add bgc bgd
          bgf:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bff
          bgg:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bfp
          bgh:f32[200,16,16,128] = sub bfd bgf
          bgi:f32[1,1,1,128] = add bgg 9.999999747378752e-06
          bgj:f32[1,1,1,128] = rsqrt bgi
          bgk:f32[1,1,1,128] = div bgj bgi
          bgl:f32[1,1,1,128] = mul -0.5 bgk
          bgm:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] sr
          bgn:f32[1,1,1,128] = mul bgj bgm
          bgo:f32[200,16,16,128] = mul bgh bgn
          bgp:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] sq
          bgq:f32[200,16,16,128] = add bgo bgp
          bgr:f32[200,16,16,128] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bgs:f32[200,16,16,128]. let
                bgt:f32[200,16,16,128] = xla_call[
                  call_jaxpr={ lambda ; bgu:f32[200,16,16,128]. let
                      bgv:f32[200,16,16,128] = max bgu 0.0
                    in (bgv,) }
                  name=relu
                ] bgs
              in (bgt,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5eca0>
            num_consts=0
          ] bgq
          bgw:bool[200,16,16,128] = gt bgq 0.0
          bgx:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          bgy:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 128)
            window_strides=(1, 1)
          ] bgr sv
          bgz:f32[128] = reduce_sum[axes=(0, 1, 2)] bgy
          bha:f32[128] = div bgz 51200.0
          bhb:f32[200,16,16,128] = integer_pow[y=2] bgy
          bhc:f32[200,16,16,128] = integer_pow[y=1] bgy
          bhd:f32[200,16,16,128] = mul 2.0 bhc
          bhe:f32[128] = reduce_sum[axes=(0, 1, 2)] bhb
          bhf:f32[128] = div bhe 51200.0
          bhg:f32[128] = integer_pow[y=2] bha
          bhh:f32[128] = integer_pow[y=1] bha
          bhi:f32[128] = mul 2.0 bhh
          bhj:f32[128] = sub bhf bhg
          bhk:f32[128] = max 0.0 bhj
          bhl:bool[128] = eq bhj bhk
          bhm:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bhn:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 0.0
          bho:f32[128] = select_n bhl bhn bhm
          bhp:bool[128] = eq 0.0 bhk
          bhq:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 2.0
          bhr:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bhs:f32[128] = select_n bhp bhr bhq
          bht:f32[128] = div bho bhs
          bhu:f32[128] = mul 0.8999999761581421 uw
          bhv:f32[128] = mul 0.10000000149011612 bha
          bhw:f32[128] = add bhu bhv
          bhx:f32[128] = mul 0.8999999761581421 ux
          bhy:f32[128] = mul 0.10000000149011612 bhk
          bhz:f32[128] = add bhx bhy
          bia:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bha
          bib:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bhk
          bic:f32[200,16,16,128] = sub bgy bia
          bid:f32[1,1,1,128] = add bib 9.999999747378752e-06
          bie:f32[1,1,1,128] = rsqrt bid
          bif:f32[1,1,1,128] = div bie bid
          big:f32[1,1,1,128] = mul -0.5 bif
          bih:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] st
          bii:f32[1,1,1,128] = mul bie bih
          bij:f32[200,16,16,128] = mul bic bii
          bik:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] ss
          bil:f32[200,16,16,128] = add bij bik
          bim:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((0, 0), (0, 0))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(1, 1, 64, 128)
            window_strides=(2, 2)
          ] bew sw
          bin:f32[128] = reduce_sum[axes=(0, 1, 2)] bim
          bio:f32[128] = div bin 51200.0
          bip:f32[200,16,16,128] = integer_pow[y=2] bim
          biq:f32[200,16,16,128] = integer_pow[y=1] bim
          bir:f32[200,16,16,128] = mul 2.0 biq
          bis:f32[128] = reduce_sum[axes=(0, 1, 2)] bip
          bit:f32[128] = div bis 51200.0
          biu:f32[128] = integer_pow[y=2] bio
          biv:f32[128] = integer_pow[y=1] bio
          biw:f32[128] = mul 2.0 biv
          bix:f32[128] = sub bit biu
          biy:f32[128] = max 0.0 bix
          biz:bool[128] = eq bix biy
          bja:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bjb:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 0.0
          bjc:f32[128] = select_n biz bjb bja
          bjd:bool[128] = eq 0.0 biy
          bje:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 2.0
          bjf:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bjg:f32[128] = select_n bjd bjf bje
          bjh:f32[128] = div bjc bjg
          bji:f32[128] = mul 0.8999999761581421 uy
          bjj:f32[128] = mul 0.10000000149011612 bio
          bjk:f32[128] = add bji bjj
          bjl:f32[128] = mul 0.8999999761581421 uz
          bjm:f32[128] = mul 0.10000000149011612 biy
          bjn:f32[128] = add bjl bjm
          bjo:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bio
          bjp:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] biy
          bjq:f32[200,16,16,128] = sub bim bjo
          bjr:f32[1,1,1,128] = add bjp 9.999999747378752e-06
          bjs:f32[1,1,1,128] = rsqrt bjr
          bjt:f32[1,1,1,128] = div bjs bjr
          bju:f32[1,1,1,128] = mul -0.5 bjt
          bjv:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] sy
          bjw:f32[1,1,1,128] = mul bjs bjv
          bjx:f32[200,16,16,128] = mul bjq bjw
          bjy:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] sx
          bjz:f32[200,16,16,128] = add bjx bjy
          bka:f32[200,16,16,128] = add bjz bil
          bkb:f32[200,16,16,128] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bkc:f32[200,16,16,128]. let
                bkd:f32[200,16,16,128] = xla_call[
                  call_jaxpr={ lambda ; bke:f32[200,16,16,128]. let
                      bkf:f32[200,16,16,128] = max bke 0.0
                    in (bkf,) }
                  name=relu
                ] bkc
              in (bkd,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5ef70>
            num_consts=0
          ] bka
          bkg:bool[200,16,16,128] = gt bka 0.0
          bkh:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          bki:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 128)
            window_strides=(1, 1)
          ] bkb td
          bkj:f32[128] = reduce_sum[axes=(0, 1, 2)] bki
          bkk:f32[128] = div bkj 51200.0
          bkl:f32[200,16,16,128] = integer_pow[y=2] bki
          bkm:f32[200,16,16,128] = integer_pow[y=1] bki
          bkn:f32[200,16,16,128] = mul 2.0 bkm
          bko:f32[128] = reduce_sum[axes=(0, 1, 2)] bkl
          bkp:f32[128] = div bko 51200.0
          bkq:f32[128] = integer_pow[y=2] bkk
          bkr:f32[128] = integer_pow[y=1] bkk
          bks:f32[128] = mul 2.0 bkr
          bkt:f32[128] = sub bkp bkq
          bku:f32[128] = max 0.0 bkt
          bkv:bool[128] = eq bkt bku
          bkw:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bkx:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 0.0
          bky:f32[128] = select_n bkv bkx bkw
          bkz:bool[128] = eq 0.0 bku
          bla:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 2.0
          blb:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          blc:f32[128] = select_n bkz blb bla
          bld:f32[128] = div bky blc
          ble:f32[128] = mul 0.8999999761581421 va
          blf:f32[128] = mul 0.10000000149011612 bkk
          blg:f32[128] = add ble blf
          blh:f32[128] = mul 0.8999999761581421 vb
          bli:f32[128] = mul 0.10000000149011612 bku
          blj:f32[128] = add blh bli
          blk:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bkk
          bll:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bku
          blm:f32[200,16,16,128] = sub bki blk
          bln:f32[1,1,1,128] = add bll 9.999999747378752e-06
          blo:f32[1,1,1,128] = rsqrt bln
          blp:f32[1,1,1,128] = div blo bln
          blq:f32[1,1,1,128] = mul -0.5 blp
          blr:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] ta
          bls:f32[1,1,1,128] = mul blo blr
          blt:f32[200,16,16,128] = mul blm bls
          blu:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] sz
          blv:f32[200,16,16,128] = add blt blu
          blw:f32[200,16,16,128] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; blx:f32[200,16,16,128]. let
                bly:f32[200,16,16,128] = xla_call[
                  call_jaxpr={ lambda ; blz:f32[200,16,16,128]. let
                      bma:f32[200,16,16,128] = max blz 0.0
                    in (bma,) }
                  name=relu
                ] blx
              in (bly,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5cf5e940>
            num_consts=0
          ] blv
          bmb:bool[200,16,16,128] = gt blv 0.0
          bmc:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          bmd:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 128)
            window_strides=(1, 1)
          ] blw te
          bme:f32[128] = reduce_sum[axes=(0, 1, 2)] bmd
          bmf:f32[128] = div bme 51200.0
          bmg:f32[200,16,16,128] = integer_pow[y=2] bmd
          bmh:f32[200,16,16,128] = integer_pow[y=1] bmd
          bmi:f32[200,16,16,128] = mul 2.0 bmh
          bmj:f32[128] = reduce_sum[axes=(0, 1, 2)] bmg
          bmk:f32[128] = div bmj 51200.0
          bml:f32[128] = integer_pow[y=2] bmf
          bmm:f32[128] = integer_pow[y=1] bmf
          bmn:f32[128] = mul 2.0 bmm
          bmo:f32[128] = sub bmk bml
          bmp:f32[128] = max 0.0 bmo
          bmq:bool[128] = eq bmo bmp
          bmr:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bms:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 0.0
          bmt:f32[128] = select_n bmq bms bmr
          bmu:bool[128] = eq 0.0 bmp
          bmv:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 2.0
          bmw:f32[128] = broadcast_in_dim[broadcast_dimensions=() shape=(128,)] 1.0
          bmx:f32[128] = select_n bmu bmw bmv
          bmy:f32[128] = div bmt bmx
          bmz:f32[128] = mul 0.8999999761581421 vc
          bna:f32[128] = mul 0.10000000149011612 bmf
          bnb:f32[128] = add bmz bna
          bnc:f32[128] = mul 0.8999999761581421 vd
          bnd:f32[128] = mul 0.10000000149011612 bmp
          bne:f32[128] = add bnc bnd
          bnf:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bmf
          bng:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bmp
          bnh:f32[200,16,16,128] = sub bmd bnf
          bni:f32[1,1,1,128] = add bng 9.999999747378752e-06
          bnj:f32[1,1,1,128] = rsqrt bni
          bnk:f32[1,1,1,128] = div bnj bni
          bnl:f32[1,1,1,128] = mul -0.5 bnk
          bnm:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] tc
          bnn:f32[1,1,1,128] = mul bnj bnm
          bno:f32[200,16,16,128] = mul bnh bnn
          bnp:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] tb
          bnq:f32[200,16,16,128] = add bno bnp
          bnr:f32[200,16,16,128] = add bkb bnq
          bns:f32[200,16,16,128] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bnt:f32[200,16,16,128]. let
                bnu:f32[200,16,16,128] = xla_call[
                  call_jaxpr={ lambda ; bnv:f32[200,16,16,128]. let
                      bnw:f32[200,16,16,128] = max bnv 0.0
                    in (bnw,) }
                  name=relu
                ] bnt
              in (bnu,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5d4de9d0>
            num_consts=0
          ] bnr
          bnx:bool[200,16,16,128] = gt bnr 0.0
          bny:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          bnz:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 256)
            window_strides=(2, 2)
          ] bns tj
          boa:f32[256] = reduce_sum[axes=(0, 1, 2)] bnz
          bob:f32[256] = div boa 12800.0
          boc:f32[200,8,8,256] = integer_pow[y=2] bnz
          bod:f32[200,8,8,256] = integer_pow[y=1] bnz
          boe:f32[200,8,8,256] = mul 2.0 bod
          bof:f32[256] = reduce_sum[axes=(0, 1, 2)] boc
          bog:f32[256] = div bof 12800.0
          boh:f32[256] = integer_pow[y=2] bob
          boi:f32[256] = integer_pow[y=1] bob
          boj:f32[256] = mul 2.0 boi
          bok:f32[256] = sub bog boh
          bol:f32[256] = max 0.0 bok
          bom:bool[256] = eq bok bol
          bon:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          boo:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 0.0
          bop:f32[256] = select_n bom boo bon
          boq:bool[256] = eq 0.0 bol
          bor:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 2.0
          bos:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bot:f32[256] = select_n boq bos bor
          bou:f32[256] = div bop bot
          bov:f32[256] = mul 0.8999999761581421 ve
          bow:f32[256] = mul 0.10000000149011612 bob
          box:f32[256] = add bov bow
          boy:f32[256] = mul 0.8999999761581421 vf
          boz:f32[256] = mul 0.10000000149011612 bol
          bpa:f32[256] = add boy boz
          bpb:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bob
          bpc:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bol
          bpd:f32[200,8,8,256] = sub bnz bpb
          bpe:f32[1,1,1,256] = add bpc 9.999999747378752e-06
          bpf:f32[1,1,1,256] = rsqrt bpe
          bpg:f32[1,1,1,256] = div bpf bpe
          bph:f32[1,1,1,256] = mul -0.5 bpg
          bpi:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tg
          bpj:f32[1,1,1,256] = mul bpf bpi
          bpk:f32[200,8,8,256] = mul bpd bpj
          bpl:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tf
          bpm:f32[200,8,8,256] = add bpk bpl
          bpn:f32[200,8,8,256] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bpo:f32[200,8,8,256]. let
                bpp:f32[200,8,8,256] = xla_call[
                  call_jaxpr={ lambda ; bpq:f32[200,8,8,256]. let
                      bpr:f32[200,8,8,256] = max bpq 0.0
                    in (bpr,) }
                  name=relu
                ] bpo
              in (bpp,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3d309f4430>
            num_consts=0
          ] bpm
          bps:bool[200,8,8,256] = gt bpm 0.0
          bpt:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          bpu:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 256)
            window_strides=(1, 1)
          ] bpn tk
          bpv:f32[256] = reduce_sum[axes=(0, 1, 2)] bpu
          bpw:f32[256] = div bpv 12800.0
          bpx:f32[200,8,8,256] = integer_pow[y=2] bpu
          bpy:f32[200,8,8,256] = integer_pow[y=1] bpu
          bpz:f32[200,8,8,256] = mul 2.0 bpy
          bqa:f32[256] = reduce_sum[axes=(0, 1, 2)] bpx
          bqb:f32[256] = div bqa 12800.0
          bqc:f32[256] = integer_pow[y=2] bpw
          bqd:f32[256] = integer_pow[y=1] bpw
          bqe:f32[256] = mul 2.0 bqd
          bqf:f32[256] = sub bqb bqc
          bqg:f32[256] = max 0.0 bqf
          bqh:bool[256] = eq bqf bqg
          bqi:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bqj:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 0.0
          bqk:f32[256] = select_n bqh bqj bqi
          bql:bool[256] = eq 0.0 bqg
          bqm:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 2.0
          bqn:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bqo:f32[256] = select_n bql bqn bqm
          bqp:f32[256] = div bqk bqo
          bqq:f32[256] = mul 0.8999999761581421 vg
          bqr:f32[256] = mul 0.10000000149011612 bpw
          bqs:f32[256] = add bqq bqr
          bqt:f32[256] = mul 0.8999999761581421 vh
          bqu:f32[256] = mul 0.10000000149011612 bqg
          bqv:f32[256] = add bqt bqu
          bqw:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bpw
          bqx:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bqg
          bqy:f32[200,8,8,256] = sub bpu bqw
          bqz:f32[1,1,1,256] = add bqx 9.999999747378752e-06
          bra:f32[1,1,1,256] = rsqrt bqz
          brb:f32[1,1,1,256] = div bra bqz
          brc:f32[1,1,1,256] = mul -0.5 brb
          brd:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] ti
          bre:f32[1,1,1,256] = mul bra brd
          brf:f32[200,8,8,256] = mul bqy bre
          brg:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] th
          brh:f32[200,8,8,256] = add brf brg
          bri:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((0, 0), (0, 0))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(1, 1, 128, 256)
            window_strides=(2, 2)
          ] bns tl
          brj:f32[256] = reduce_sum[axes=(0, 1, 2)] bri
          brk:f32[256] = div brj 12800.0
          brl:f32[200,8,8,256] = integer_pow[y=2] bri
          brm:f32[200,8,8,256] = integer_pow[y=1] bri
          brn:f32[200,8,8,256] = mul 2.0 brm
          bro:f32[256] = reduce_sum[axes=(0, 1, 2)] brl
          brp:f32[256] = div bro 12800.0
          brq:f32[256] = integer_pow[y=2] brk
          brr:f32[256] = integer_pow[y=1] brk
          brs:f32[256] = mul 2.0 brr
          brt:f32[256] = sub brp brq
          bru:f32[256] = max 0.0 brt
          brv:bool[256] = eq brt bru
          brw:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          brx:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 0.0
          bry:f32[256] = select_n brv brx brw
          brz:bool[256] = eq 0.0 bru
          bsa:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 2.0
          bsb:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bsc:f32[256] = select_n brz bsb bsa
          bsd:f32[256] = div bry bsc
          bse:f32[256] = mul 0.8999999761581421 vi
          bsf:f32[256] = mul 0.10000000149011612 brk
          bsg:f32[256] = add bse bsf
          bsh:f32[256] = mul 0.8999999761581421 vj
          bsi:f32[256] = mul 0.10000000149011612 bru
          bsj:f32[256] = add bsh bsi
          bsk:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] brk
          bsl:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bru
          bsm:f32[200,8,8,256] = sub bri bsk
          bsn:f32[1,1,1,256] = add bsl 9.999999747378752e-06
          bso:f32[1,1,1,256] = rsqrt bsn
          bsp:f32[1,1,1,256] = div bso bsn
          bsq:f32[1,1,1,256] = mul -0.5 bsp
          bsr:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tn
          bss:f32[1,1,1,256] = mul bso bsr
          bst:f32[200,8,8,256] = mul bsm bss
          bsu:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tm
          bsv:f32[200,8,8,256] = add bst bsu
          bsw:f32[200,8,8,256] = add bsv brh
          bsx:f32[200,8,8,256] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bsy:f32[200,8,8,256]. let
                bsz:f32[200,8,8,256] = xla_call[
                  call_jaxpr={ lambda ; bta:f32[200,8,8,256]. let
                      btb:f32[200,8,8,256] = max bta 0.0
                    in (btb,) }
                  name=relu
                ] bsy
              in (bsz,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5d45aca0>
            num_consts=0
          ] bsw
          btc:bool[200,8,8,256] = gt bsw 0.0
          btd:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          bte:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 256)
            window_strides=(1, 1)
          ] bsx ts
          btf:f32[256] = reduce_sum[axes=(0, 1, 2)] bte
          btg:f32[256] = div btf 12800.0
          bth:f32[200,8,8,256] = integer_pow[y=2] bte
          bti:f32[200,8,8,256] = integer_pow[y=1] bte
          btj:f32[200,8,8,256] = mul 2.0 bti
          btk:f32[256] = reduce_sum[axes=(0, 1, 2)] bth
          btl:f32[256] = div btk 12800.0
          btm:f32[256] = integer_pow[y=2] btg
          btn:f32[256] = integer_pow[y=1] btg
          bto:f32[256] = mul 2.0 btn
          btp:f32[256] = sub btl btm
          btq:f32[256] = max 0.0 btp
          btr:bool[256] = eq btp btq
          bts:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          btt:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 0.0
          btu:f32[256] = select_n btr btt bts
          btv:bool[256] = eq 0.0 btq
          btw:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 2.0
          btx:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bty:f32[256] = select_n btv btx btw
          btz:f32[256] = div btu bty
          bua:f32[256] = mul 0.8999999761581421 vk
          bub:f32[256] = mul 0.10000000149011612 btg
          buc:f32[256] = add bua bub
          bud:f32[256] = mul 0.8999999761581421 vl
          bue:f32[256] = mul 0.10000000149011612 btq
          buf:f32[256] = add bud bue
          bug:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] btg
          buh:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] btq
          bui:f32[200,8,8,256] = sub bte bug
          buj:f32[1,1,1,256] = add buh 9.999999747378752e-06
          buk:f32[1,1,1,256] = rsqrt buj
          bul:f32[1,1,1,256] = div buk buj
          bum:f32[1,1,1,256] = mul -0.5 bul
          bun:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tp
          buo:f32[1,1,1,256] = mul buk bun
          bup:f32[200,8,8,256] = mul bui buo
          buq:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] to
          bur:f32[200,8,8,256] = add bup buq
          bus:f32[200,8,8,256] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; but:f32[200,8,8,256]. let
                buu:f32[200,8,8,256] = xla_call[
                  call_jaxpr={ lambda ; buv:f32[200,8,8,256]. let
                      buw:f32[200,8,8,256] = max buv 0.0
                    in (buw,) }
                  name=relu
                ] but
              in (buu,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3d309d2430>
            num_consts=0
          ] bur
          bux:bool[200,8,8,256] = gt bur 0.0
          buy:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          buz:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 256)
            window_strides=(1, 1)
          ] bus tt
          bva:f32[256] = reduce_sum[axes=(0, 1, 2)] buz
          bvb:f32[256] = div bva 12800.0
          bvc:f32[200,8,8,256] = integer_pow[y=2] buz
          bvd:f32[200,8,8,256] = integer_pow[y=1] buz
          bve:f32[200,8,8,256] = mul 2.0 bvd
          bvf:f32[256] = reduce_sum[axes=(0, 1, 2)] bvc
          bvg:f32[256] = div bvf 12800.0
          bvh:f32[256] = integer_pow[y=2] bvb
          bvi:f32[256] = integer_pow[y=1] bvb
          bvj:f32[256] = mul 2.0 bvi
          bvk:f32[256] = sub bvg bvh
          bvl:f32[256] = max 0.0 bvk
          bvm:bool[256] = eq bvk bvl
          bvn:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bvo:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 0.0
          bvp:f32[256] = select_n bvm bvo bvn
          bvq:bool[256] = eq 0.0 bvl
          bvr:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 2.0
          bvs:f32[256] = broadcast_in_dim[broadcast_dimensions=() shape=(256,)] 1.0
          bvt:f32[256] = select_n bvq bvs bvr
          bvu:f32[256] = div bvp bvt
          bvv:f32[256] = mul 0.8999999761581421 vm
          bvw:f32[256] = mul 0.10000000149011612 bvb
          bvx:f32[256] = add bvv bvw
          bvy:f32[256] = mul 0.8999999761581421 vn
          bvz:f32[256] = mul 0.10000000149011612 bvl
          bwa:f32[256] = add bvy bvz
          bwb:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bvb
          bwc:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] bvl
          bwd:f32[200,8,8,256] = sub buz bwb
          bwe:f32[1,1,1,256] = add bwc 9.999999747378752e-06
          bwf:f32[1,1,1,256] = rsqrt bwe
          bwg:f32[1,1,1,256] = div bwf bwe
          bwh:f32[1,1,1,256] = mul -0.5 bwg
          bwi:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tr
          bwj:f32[1,1,1,256] = mul bwf bwi
          bwk:f32[200,8,8,256] = mul bwd bwj
          bwl:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tq
          bwm:f32[200,8,8,256] = add bwk bwl
          bwn:f32[200,8,8,256] = add bsx bwm
          bwo:f32[200,8,8,256] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; bwp:f32[200,8,8,256]. let
                bwq:f32[200,8,8,256] = xla_call[
                  call_jaxpr={ lambda ; bwr:f32[200,8,8,256]. let
                      bws:f32[200,8,8,256] = max bwr 0.0
                    in (bws,) }
                  name=relu
                ] bwp
              in (bwq,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5d45adc0>
            num_consts=0
          ] bwn
          bwt:bool[200,8,8,256] = gt bwn 0.0
          bwu:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          bwv:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 512)
            window_strides=(2, 2)
          ] bwo ty
          bww:f32[512] = reduce_sum[axes=(0, 1, 2)] bwv
          bwx:f32[512] = div bww 3200.0
          bwy:f32[200,4,4,512] = integer_pow[y=2] bwv
          bwz:f32[200,4,4,512] = integer_pow[y=1] bwv
          bxa:f32[200,4,4,512] = mul 2.0 bwz
          bxb:f32[512] = reduce_sum[axes=(0, 1, 2)] bwy
          bxc:f32[512] = div bxb 3200.0
          bxd:f32[512] = integer_pow[y=2] bwx
          bxe:f32[512] = integer_pow[y=1] bwx
          bxf:f32[512] = mul 2.0 bxe
          bxg:f32[512] = sub bxc bxd
          bxh:f32[512] = max 0.0 bxg
          bxi:bool[512] = eq bxg bxh
          bxj:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          bxk:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 0.0
          bxl:f32[512] = select_n bxi bxk bxj
          bxm:bool[512] = eq 0.0 bxh
          bxn:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 2.0
          bxo:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          bxp:f32[512] = select_n bxm bxo bxn
          bxq:f32[512] = div bxl bxp
          bxr:f32[512] = mul 0.8999999761581421 vo
          bxs:f32[512] = mul 0.10000000149011612 bwx
          bxt:f32[512] = add bxr bxs
          bxu:f32[512] = mul 0.8999999761581421 vp
          bxv:f32[512] = mul 0.10000000149011612 bxh
          bxw:f32[512] = add bxu bxv
          bxx:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] bwx
          bxy:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] bxh
          bxz:f32[200,4,4,512] = sub bwv bxx
          bya:f32[1,1,1,512] = add bxy 9.999999747378752e-06
          byb:f32[1,1,1,512] = rsqrt bya
          byc:f32[1,1,1,512] = div byb bya
          byd:f32[1,1,1,512] = mul -0.5 byc
          bye:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] tv
          byf:f32[1,1,1,512] = mul byb bye
          byg:f32[200,4,4,512] = mul bxz byf
          byh:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] tu
          byi:f32[200,4,4,512] = add byg byh
          byj:f32[200,4,4,512] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; byk:f32[200,4,4,512]. let
                byl:f32[200,4,4,512] = xla_call[
                  call_jaxpr={ lambda ; bym:f32[200,4,4,512]. let
                      byn:f32[200,4,4,512] = max bym 0.0
                    in (byn,) }
                  name=relu
                ] byk
              in (byl,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5d4de8b0>
            num_consts=0
          ] byi
          byo:bool[200,4,4,512] = gt byi 0.0
          byp:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          byq:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 512, 512)
            window_strides=(1, 1)
          ] byj tz
          byr:f32[512] = reduce_sum[axes=(0, 1, 2)] byq
          bys:f32[512] = div byr 3200.0
          byt:f32[200,4,4,512] = integer_pow[y=2] byq
          byu:f32[200,4,4,512] = integer_pow[y=1] byq
          byv:f32[200,4,4,512] = mul 2.0 byu
          byw:f32[512] = reduce_sum[axes=(0, 1, 2)] byt
          byx:f32[512] = div byw 3200.0
          byy:f32[512] = integer_pow[y=2] bys
          byz:f32[512] = integer_pow[y=1] bys
          bza:f32[512] = mul 2.0 byz
          bzb:f32[512] = sub byx byy
          bzc:f32[512] = max 0.0 bzb
          bzd:bool[512] = eq bzb bzc
          bze:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          bzf:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 0.0
          bzg:f32[512] = select_n bzd bzf bze
          bzh:bool[512] = eq 0.0 bzc
          bzi:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 2.0
          bzj:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          bzk:f32[512] = select_n bzh bzj bzi
          bzl:f32[512] = div bzg bzk
          bzm:f32[512] = mul 0.8999999761581421 vq
          bzn:f32[512] = mul 0.10000000149011612 bys
          bzo:f32[512] = add bzm bzn
          bzp:f32[512] = mul 0.8999999761581421 vr
          bzq:f32[512] = mul 0.10000000149011612 bzc
          bzr:f32[512] = add bzp bzq
          bzs:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] bys
          bzt:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] bzc
          bzu:f32[200,4,4,512] = sub byq bzs
          bzv:f32[1,1,1,512] = add bzt 9.999999747378752e-06
          bzw:f32[1,1,1,512] = rsqrt bzv
          bzx:f32[1,1,1,512] = div bzw bzv
          bzy:f32[1,1,1,512] = mul -0.5 bzx
          bzz:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] tx
          caa:f32[1,1,1,512] = mul bzw bzz
          cab:f32[200,4,4,512] = mul bzu caa
          cac:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] tw
          cad:f32[200,4,4,512] = add cab cac
          cae:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((0, 0), (0, 0))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(1, 1, 256, 512)
            window_strides=(2, 2)
          ] bwo ua
          caf:f32[512] = reduce_sum[axes=(0, 1, 2)] cae
          cag:f32[512] = div caf 3200.0
          cah:f32[200,4,4,512] = integer_pow[y=2] cae
          cai:f32[200,4,4,512] = integer_pow[y=1] cae
          caj:f32[200,4,4,512] = mul 2.0 cai
          cak:f32[512] = reduce_sum[axes=(0, 1, 2)] cah
          cal:f32[512] = div cak 3200.0
          cam:f32[512] = integer_pow[y=2] cag
          can:f32[512] = integer_pow[y=1] cag
          cao:f32[512] = mul 2.0 can
          cap:f32[512] = sub cal cam
          caq:f32[512] = max 0.0 cap
          car:bool[512] = eq cap caq
          cas:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          cat:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 0.0
          cau:f32[512] = select_n car cat cas
          cav:bool[512] = eq 0.0 caq
          caw:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 2.0
          cax:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          cay:f32[512] = select_n cav cax caw
          caz:f32[512] = div cau cay
          cba:f32[512] = mul 0.8999999761581421 vs
          cbb:f32[512] = mul 0.10000000149011612 cag
          cbc:f32[512] = add cba cbb
          cbd:f32[512] = mul 0.8999999761581421 vt
          cbe:f32[512] = mul 0.10000000149011612 caq
          cbf:f32[512] = add cbd cbe
          cbg:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cag
          cbh:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] caq
          cbi:f32[200,4,4,512] = sub cae cbg
          cbj:f32[1,1,1,512] = add cbh 9.999999747378752e-06
          cbk:f32[1,1,1,512] = rsqrt cbj
          cbl:f32[1,1,1,512] = div cbk cbj
          cbm:f32[1,1,1,512] = mul -0.5 cbl
          cbn:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] uc
          cbo:f32[1,1,1,512] = mul cbk cbn
          cbp:f32[200,4,4,512] = mul cbi cbo
          cbq:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ub
          cbr:f32[200,4,4,512] = add cbp cbq
          cbs:f32[200,4,4,512] = add cbr cad
          cbt:f32[200,4,4,512] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; cbu:f32[200,4,4,512]. let
                cbv:f32[200,4,4,512] = xla_call[
                  call_jaxpr={ lambda ; cbw:f32[200,4,4,512]. let
                      cbx:f32[200,4,4,512] = max cbw 0.0
                    in (cbx,) }
                  name=relu
                ] cbu
              in (cbv,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3d30a48af0>
            num_consts=0
          ] cbs
          cby:bool[200,4,4,512] = gt cbs 0.0
          cbz:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cca:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 512, 512)
            window_strides=(1, 1)
          ] cbt uh
          ccb:f32[512] = reduce_sum[axes=(0, 1, 2)] cca
          ccc:f32[512] = div ccb 3200.0
          ccd:f32[200,4,4,512] = integer_pow[y=2] cca
          cce:f32[200,4,4,512] = integer_pow[y=1] cca
          ccf:f32[200,4,4,512] = mul 2.0 cce
          ccg:f32[512] = reduce_sum[axes=(0, 1, 2)] ccd
          cch:f32[512] = div ccg 3200.0
          cci:f32[512] = integer_pow[y=2] ccc
          ccj:f32[512] = integer_pow[y=1] ccc
          cck:f32[512] = mul 2.0 ccj
          ccl:f32[512] = sub cch cci
          ccm:f32[512] = max 0.0 ccl
          ccn:bool[512] = eq ccl ccm
          cco:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          ccp:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 0.0
          ccq:f32[512] = select_n ccn ccp cco
          ccr:bool[512] = eq 0.0 ccm
          ccs:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 2.0
          cct:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          ccu:f32[512] = select_n ccr cct ccs
          ccv:f32[512] = div ccq ccu
          ccw:f32[512] = mul 0.8999999761581421 vu
          ccx:f32[512] = mul 0.10000000149011612 ccc
          ccy:f32[512] = add ccw ccx
          ccz:f32[512] = mul 0.8999999761581421 vv
          cda:f32[512] = mul 0.10000000149011612 ccm
          cdb:f32[512] = add ccz cda
          cdc:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ccc
          cdd:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ccm
          cde:f32[200,4,4,512] = sub cca cdc
          cdf:f32[1,1,1,512] = add cdd 9.999999747378752e-06
          cdg:f32[1,1,1,512] = rsqrt cdf
          cdh:f32[1,1,1,512] = div cdg cdf
          cdi:f32[1,1,1,512] = mul -0.5 cdh
          cdj:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ue
          cdk:f32[1,1,1,512] = mul cdg cdj
          cdl:f32[200,4,4,512] = mul cde cdk
          cdm:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ud
          cdn:f32[200,4,4,512] = add cdl cdm
          cdo:f32[200,4,4,512] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; cdp:f32[200,4,4,512]. let
                cdq:f32[200,4,4,512] = xla_call[
                  call_jaxpr={ lambda ; cdr:f32[200,4,4,512]. let
                      cds:f32[200,4,4,512] = max cdr 0.0
                    in (cds,) }
                  name=relu
                ] cdp
              in (cdq,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3a5d45af70>
            num_consts=0
          ] cdn
          cdt:bool[200,4,4,512] = gt cdn 0.0
          cdu:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cdv:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 512, 512)
            window_strides=(1, 1)
          ] cdo ui
          cdw:f32[512] = reduce_sum[axes=(0, 1, 2)] cdv
          cdx:f32[512] = div cdw 3200.0
          cdy:f32[200,4,4,512] = integer_pow[y=2] cdv
          cdz:f32[200,4,4,512] = integer_pow[y=1] cdv
          cea:f32[200,4,4,512] = mul 2.0 cdz
          ceb:f32[512] = reduce_sum[axes=(0, 1, 2)] cdy
          cec:f32[512] = div ceb 3200.0
          ced:f32[512] = integer_pow[y=2] cdx
          cee:f32[512] = integer_pow[y=1] cdx
          cef:f32[512] = mul 2.0 cee
          ceg:f32[512] = sub cec ced
          ceh:f32[512] = max 0.0 ceg
          cei:bool[512] = eq ceg ceh
          cej:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          cek:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 0.0
          cel:f32[512] = select_n cei cek cej
          cem:bool[512] = eq 0.0 ceh
          cen:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 2.0
          ceo:f32[512] = broadcast_in_dim[broadcast_dimensions=() shape=(512,)] 1.0
          cep:f32[512] = select_n cem ceo cen
          ceq:f32[512] = div cel cep
          cer:f32[512] = mul 0.8999999761581421 vw
          ces:f32[512] = mul 0.10000000149011612 cdx
          cet:f32[512] = add cer ces
          ceu:f32[512] = mul 0.8999999761581421 vx
          cev:f32[512] = mul 0.10000000149011612 ceh
          cew:f32[512] = add ceu cev
          cex:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cdx
          cey:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ceh
          cez:f32[200,4,4,512] = sub cdv cex
          cfa:f32[1,1,1,512] = add cey 9.999999747378752e-06
          cfb:f32[1,1,1,512] = rsqrt cfa
          cfc:f32[1,1,1,512] = div cfb cfa
          cfd:f32[1,1,1,512] = mul -0.5 cfc
          cfe:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ug
          cff:f32[1,1,1,512] = mul cfb cfe
          cfg:f32[200,4,4,512] = mul cez cff
          cfh:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] uf
          cfi:f32[200,4,4,512] = add cfg cfh
          cfj:f32[200,4,4,512] = add cbt cfi
          cfk:f32[200,4,4,512] = custom_jvp_call_jaxpr[
            fun_jaxpr={ lambda ; cfl:f32[200,4,4,512]. let
                cfm:f32[200,4,4,512] = xla_call[
                  call_jaxpr={ lambda ; cfn:f32[200,4,4,512]. let
                      cfo:f32[200,4,4,512] = max cfn 0.0
                    in (cfo,) }
                  name=relu
                ] cfl
              in (cfm,) }
            jvp_jaxpr_thunk=<function _memoize.<locals>.memoized at 0x7f3d309f44c0>
            num_consts=0
          ] cfj
          cfp:bool[200,4,4,512] = gt cfj 0.0
          cfq:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cfr:f32[200,512] = reduce_sum[axes=(1, 2)] cfk
          cfs:f32[200,512] = div cfr 16.0
          cft:f32[200,100] = dot_general[
            dimension_numbers=(((1,), (0,)), ((), ()))
            precision=None
            preferred_element_type=None
          ] cfs sd
          cfu:f32[1,100] = reshape[dimensions=None new_sizes=(1, 100)] sc
          cfv:f32[200,100] = add cft cfu
          cfw:f32[200,100] = xla_call[
            call_jaxpr={ lambda ; cfx:i32[200]. let
                cfy:i32[200,1] = broadcast_in_dim[
                  broadcast_dimensions=(0,)
                  shape=(200, 1)
                ] cfx
                cfz:i32[1,100] = iota[dimension=1 dtype=int32 shape=(1, 100)] 
                cga:bool[200,100] = eq cfy cfz
                cgb:f32[200,100] = convert_element_type[
                  new_dtype=float32
                  weak_type=False
                ] cga
              in (cgb,) }
            name=_one_hot
          ] sb
          cgc:f32[200,100] cgd:f32[200,1] cge:f32[200,100] = xla_call[
            call_jaxpr={ lambda ; cgf:f32[200,100]. let
                cgg:f32[200] = reduce_max[axes=(1,)] cgf
                cgh:f32[200,1] = reshape[dimensions=None new_sizes=(200, 1)] cgg
                cgi:bool[200,100] = eq cgf cgh
                cgj:f32[200,100] = convert_element_type[
                  new_dtype=float32
                  weak_type=False
                ] cgi
                _:f32[200] = reduce_sum[axes=(1,)] cgj
                cgk:f32[200,1] = broadcast_in_dim[
                  broadcast_dimensions=(0,)
                  shape=(200, 1)
                ] cgg
                cgl:f32[200,1] = stop_gradient cgk
                cgm:f32[200,100] = sub cgf cgl
                cgn:f32[200,100] = exp cgm
                cgo:f32[200] = reduce_sum[axes=(1,)] cgn
                cgp:f32[200,1] = broadcast_in_dim[
                  broadcast_dimensions=(0,)
                  shape=(200, 1)
                ] cgo
                cgq:f32[200,1] = log cgp
                cgr:f32[200,100] = sub cgm cgq
              in (cgr, cgp, cgn) }
            name=log_softmax
          ] cfv
          cgs:f32[200,100] = mul cfw cgc
          cgt:f32[200] = reduce_sum[axes=(1,)] cgs
          cgu:f32[200] = neg cgt
          cgv:i32[200] = argmax[axes=(1,) index_dtype=int32] cfv
          cgw:bool[200] = eq cgv sb
          cgx:i32[200] = convert_element_type[new_dtype=int32 weak_type=True] cgw
          cgy:i32[200] = sub 1 cgx
          cgz:i32[200] = convert_element_type[new_dtype=int32 weak_type=False] cgw
          cha:i32[] = reduce_sum[axes=(0,)] cgz
          chb:i32[200] = convert_element_type[new_dtype=int32 weak_type=False] cgy
          chc:i32[] = reduce_sum[axes=(0,)] chb
          chd:f32[] = reduce_sum[axes=(0,)] cgu
        in (chd, cha, chc, chd, yt, yw, bao, bar, bck, bcn, bef, bei, bgb, bge, bhw,
          bhz, bjk, bjn, blg, blj, bnb, bne, box, bpa, bqs, bqv, bsg, bsj, buc, buf,
          bvx, bwa, bxt, bxw, bzo, bzr, cbc, cbf, ccy, cdb, cet, cew, wy, xb, cfw,
          cgd, cge, cfp, cfq, cff, cez, cdt, cdu, cdk, cde, cby, cbz, cbo, cbi, bwt,
          bwu, bwj, bwd, bux, buy, buo, bui, btc, btd, bss, bsm, bnx, bny, bnn, bnh,
          bmb, bmc, bls, blm, bkg, bkh, bjw, bjq, bfb, bfc, ber, bel, bdf, bdg, bcw,
          bcq, bbk, bbl, bba, bau, zo, zp, zf, yz, xt, xu, xk, xe, sa, xj, xg, wv,
          wf, wk, xi, xo, ze, zb, yq, ya, yf, zd, zj, baz, baw, bal, zv, baa, bay,
          bbf, bcv, bcs, bch, bbr, bbw, bcu, bda, beq, ben, bec, bdm, bdr, bep, bew,
          bjv, bjs, bjh, bir, biw, bju, bii, bic, bgw, bgx, bgn, bgh, bgm, bgj, bfy,
          bfi, bfn, bgl, bgr, bih, bie, bht, bhd, bhi, big, bkb, blr, blo, bld, bkn,
          bks, blq, blw, bnm, bnj, bmy, bmi, bmn, bnl, bns, bsr, bso, bsd, brn, brs,
          bsq, bre, bqy, bps, bpt, bpj, bpd, bpi, bpf, bou, boe, boj, bph, bpn, brd,
          bra, bqp, bpz, bqe, brc, bsx, bun, buk, btz, btj, bto, bum, bus, bwi, bwf,
          bvu, bve, bvj, bwh, bwo, cbn, cbk, caz, caj, cao, cbm, caa, bzu, byo, byp,
          byf, bxz, bye, byb, bxq, bxa, bxf, byd, byj, bzz, bzw, bzl, byv, bza, bzy,
          cbt, cdj, cdg, ccv, ccf, cck, cdi, cdo, cfe, cfb, ceq, cea, cef, cfd, cfs,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612,
          0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612) }
      name=batched_loss_fn
    ] gm gn b c d e f g h i j k l m n o p q r s t u v w x y z ba bb bc bd be bf bg
      bh bi bj bk bl bm bn bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd ce cf
      cg ch ci cj ck ey ez fa fb fc fd fe ff fg fh fi fj fk fl fm fn fo fp fq fr
      fs ft fu fv fw fx fy fz ga gb gc gd ge gf gg gh gi gj gk gl
    che:f32[100] chf:f32[512,100] chg:f32[64] chh:f32[64] chi:f32[64] chj:f32[64]
      chk:f32[3,3,64,64] chl:f32[3,3,64,64] chm:f32[64] chn:f32[64] cho:f32[64] chp:f32[64]
      chq:f32[3,3,64,64] chr:f32[3,3,64,64] chs:f32[128] cht:f32[128] chu:f32[128]
      chv:f32[128] chw:f32[3,3,64,128] chx:f32[3,3,128,128] chy:f32[1,1,64,128] chz:f32[128]
      cia:f32[128] cib:f32[128] cic:f32[128] cid:f32[128] cie:f32[128] cif:f32[3,3,128,128]
      cig:f32[3,3,128,128] cih:f32[256] cii:f32[256] cij:f32[256] cik:f32[256] cil:f32[3,3,128,256]
      cim:f32[3,3,256,256] cin:f32[1,1,128,256] cio:f32[256] cip:f32[256] ciq:f32[256]
      cir:f32[256] cis:f32[256] cit:f32[256] ciu:f32[3,3,256,256] civ:f32[3,3,256,256]
      ciw:f32[512] cix:f32[512] ciy:f32[512] ciz:f32[512] cja:f32[3,3,256,512] cjb:f32[3,3,512,512]
      cjc:f32[1,1,256,512] cjd:f32[512] cje:f32[512] cjf:f32[512] cjg:f32[512] cjh:f32[512]
      cji:f32[512] cjj:f32[3,3,512,512] cjk:f32[3,3,512,512] cjl:f32[64] cjm:f32[64]
      cjn:f32[3,3,3,64] = xla_call[
      call_jaxpr={ lambda ; cjo:f32[200,100] cjp:f32[200,1] cjq:f32[200,100] cjr:bool[200,4,4,512]
          cjs:f32[200,4,4,512] cjt:f32[1,1,1,512] cju:f32[200,4,4,512] cjv:bool[200,4,4,512]
          cjw:f32[200,4,4,512] cjx:f32[1,1,1,512] cjy:f32[200,4,4,512] cjz:bool[200,4,4,512]
          cka:f32[200,4,4,512] ckb:f32[1,1,1,512] ckc:f32[200,4,4,512] ckd:bool[200,8,8,256]
          cke:f32[200,8,8,256] ckf:f32[1,1,1,256] ckg:f32[200,8,8,256] ckh:bool[200,8,8,256]
          cki:f32[200,8,8,256] ckj:f32[1,1,1,256] ckk:f32[200,8,8,256] ckl:bool[200,8,8,256]
          ckm:f32[200,8,8,256] ckn:f32[1,1,1,256] cko:f32[200,8,8,256] ckp:bool[200,16,16,128]
          ckq:f32[200,16,16,128] ckr:f32[1,1,1,128] cks:f32[200,16,16,128] ckt:bool[200,16,16,128]
          cku:f32[200,16,16,128] ckv:f32[1,1,1,128] ckw:f32[200,16,16,128] ckx:bool[200,16,16,128]
          cky:f32[200,16,16,128] ckz:f32[1,1,1,128] cla:f32[200,16,16,128] clb:bool[200,32,32,64]
          clc:f32[200,32,32,64] cld:f32[1,1,1,64] cle:f32[200,32,32,64] clf:bool[200,32,32,64]
          clg:f32[200,32,32,64] clh:f32[1,1,1,64] cli:f32[200,32,32,64] clj:bool[200,32,32,64]
          clk:f32[200,32,32,64] cll:f32[1,1,1,64] clm:f32[200,32,32,64] cln:bool[200,32,32,64]
          clo:f32[200,32,32,64] clp:f32[1,1,1,64] clq:f32[200,32,32,64] clr:bool[200,32,32,64]
          cls:f32[200,32,32,64] clt:f32[1,1,1,64] clu:f32[200,32,32,64] clv:f32[200,32,32,3]
          clw:f32[1,1,1,64] clx:f32[1,1,1,64] cly:f32[64] clz:f32[200,32,32,64] cma:f32[64]
          cmb:f32[1,1,1,64] cmc:f32[3,3,64,64] cmd:f32[200,32,32,64] cme:f32[1,1,1,64]
          cmf:f32[1,1,1,64] cmg:f32[64] cmh:f32[200,32,32,64] cmi:f32[64] cmj:f32[1,1,1,64]
          cmk:f32[3,3,64,64] cml:f32[200,32,32,64] cmm:f32[1,1,1,64] cmn:f32[1,1,1,64]
          cmo:f32[64] cmp:f32[200,32,32,64] cmq:f32[64] cmr:f32[1,1,1,64] cms:f32[3,3,64,64]
          cmt:f32[200,32,32,64] cmu:f32[1,1,1,64] cmv:f32[1,1,1,64] cmw:f32[64] cmx:f32[200,32,32,64]
          cmy:f32[64] cmz:f32[1,1,1,64] cna:f32[3,3,64,64] cnb:f32[200,32,32,64]
          cnc:f32[1,1,1,64] cnd:f32[1,1,1,64] cne:f32[64] cnf:f32[200,32,32,64] cng:f32[64]
          cnh:f32[1,1,1,64] cni:f32[1,1,64,128] cnj:f32[200,32,32,64] cnk:f32[1,1,1,128]
          cnl:f32[1,1,1,128] cnm:f32[128] cnn:f32[200,16,16,128] cno:f32[128] cnp:f32[1,1,1,128]
          cnq:f32[1,1,1,128] cnr:f32[200,16,16,128] cns:bool[200,16,16,128] cnt:f32[200,16,16,128]
          cnu:f32[1,1,1,128] cnv:f32[200,16,16,128] cnw:f32[3,3,64,128] cnx:f32[1,1,1,128]
          cny:f32[1,1,1,128] cnz:f32[128] coa:f32[200,16,16,128] cob:f32[128] coc:f32[1,1,1,128]
          cod:f32[3,3,128,128] coe:f32[200,16,16,128] cof:f32[1,1,1,128] cog:f32[1,1,1,128]
          coh:f32[128] coi:f32[200,16,16,128] coj:f32[128] cok:f32[1,1,1,128] col:f32[3,3,128,128]
          com:f32[200,16,16,128] con:f32[1,1,1,128] coo:f32[1,1,1,128] cop:f32[128]
          coq:f32[200,16,16,128] cor:f32[128] cos:f32[1,1,1,128] cot:f32[3,3,128,128]
          cou:f32[200,16,16,128] cov:f32[1,1,1,128] cow:f32[1,1,1,128] cox:f32[128]
          coy:f32[200,16,16,128] coz:f32[128] cpa:f32[1,1,1,128] cpb:f32[1,1,128,256]
          cpc:f32[200,16,16,128] cpd:f32[1,1,1,256] cpe:f32[1,1,1,256] cpf:f32[256]
          cpg:f32[200,8,8,256] cph:f32[256] cpi:f32[1,1,1,256] cpj:f32[1,1,1,256]
          cpk:f32[200,8,8,256] cpl:bool[200,8,8,256] cpm:f32[200,8,8,256] cpn:f32[1,1,1,256]
          cpo:f32[200,8,8,256] cpp:f32[3,3,128,256] cpq:f32[1,1,1,256] cpr:f32[1,1,1,256]
          cps:f32[256] cpt:f32[200,8,8,256] cpu:f32[256] cpv:f32[1,1,1,256] cpw:f32[3,3,256,256]
          cpx:f32[200,8,8,256] cpy:f32[1,1,1,256] cpz:f32[1,1,1,256] cqa:f32[256]
          cqb:f32[200,8,8,256] cqc:f32[256] cqd:f32[1,1,1,256] cqe:f32[3,3,256,256]
          cqf:f32[200,8,8,256] cqg:f32[1,1,1,256] cqh:f32[1,1,1,256] cqi:f32[256]
          cqj:f32[200,8,8,256] cqk:f32[256] cql:f32[1,1,1,256] cqm:f32[3,3,256,256]
          cqn:f32[200,8,8,256] cqo:f32[1,1,1,256] cqp:f32[1,1,1,256] cqq:f32[256]
          cqr:f32[200,8,8,256] cqs:f32[256] cqt:f32[1,1,1,256] cqu:f32[1,1,256,512]
          cqv:f32[200,8,8,256] cqw:f32[1,1,1,512] cqx:f32[1,1,1,512] cqy:f32[512]
          cqz:f32[200,4,4,512] cra:f32[512] crb:f32[1,1,1,512] crc:f32[1,1,1,512]
          crd:f32[200,4,4,512] cre:bool[200,4,4,512] crf:f32[200,4,4,512] crg:f32[1,1,1,512]
          crh:f32[200,4,4,512] cri:f32[3,3,256,512] crj:f32[1,1,1,512] crk:f32[1,1,1,512]
          crl:f32[512] crm:f32[200,4,4,512] crn:f32[512] cro:f32[1,1,1,512] crp:f32[3,3,512,512]
          crq:f32[200,4,4,512] crr:f32[1,1,1,512] crs:f32[1,1,1,512] crt:f32[512]
          cru:f32[200,4,4,512] crv:f32[512] crw:f32[1,1,1,512] crx:f32[3,3,512,512]
          cry:f32[200,4,4,512] crz:f32[1,1,1,512] csa:f32[1,1,1,512] csb:f32[512]
          csc:f32[200,4,4,512] csd:f32[512] cse:f32[1,1,1,512] csf:f32[3,3,512,512]
          csg:f32[200,4,4,512] csh:f32[1,1,1,512] csi:f32[1,1,1,512] csj:f32[512]
          csk:f32[200,4,4,512] csl:f32[512] csm:f32[1,1,1,512] csn:f32[512,100] cso:f32[200,512]
          csp:f32[] csq:f32[] csr:f32[] css:f32[] cst:f32[] csu:f32[] csv:f32[] csw:f32[]
          csx:f32[] csy:f32[] csz:f32[] cta:f32[] ctb:f32[] ctc:f32[] ctd:f32[] cte:f32[]
          ctf:f32[] ctg:f32[] cth:f32[] cti:f32[] ctj:f32[] ctk:f32[] ctl:f32[] ctm:f32[]
          ctn:f32[] cto:f32[] ctp:f32[] ctq:f32[] ctr:f32[] cts:f32[] ctt:f32[] ctu:f32[]
          ctv:f32[] ctw:f32[] ctx:f32[] cty:f32[] ctz:f32[] cua:f32[] cub:f32[] cuc:f32[]
          cud:f32[]. let
          cue:f32[200] = broadcast_in_dim[broadcast_dimensions=() shape=(200,)] cud
          cuf:f32[200] = neg cue
          cug:f32[200,100] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(200, 100)
          ] cuf
          cuh:f32[200,100] = mul cjo cug
          cui:f32[200,100] = xla_call[
            call_jaxpr={ lambda ; cuj:f32[200,1] cuk:f32[200,100] cul:f32[200,100]. let
                cum:f32[200,100] = neg cul
                cun:f32[200] = reduce_sum[axes=(1,)] cum
                cuo:f32[200,1] = reshape[dimensions=None new_sizes=(200, 1)] cun
                cup:f32[200,1] = div cuo cuj
                cuq:f32[200] = reduce_sum[axes=(1,)] cup
                cur:f32[200,100] = broadcast_in_dim[
                  broadcast_dimensions=(0,)
                  shape=(200, 100)
                ] cuq
                cus:f32[200,100] = mul cur cuk
                cut:f32[200,100] = add_any cul cus
              in (cut,) }
            name=log_softmax
          ] cjp cjq cuh
          cuu:f32[100] = reduce_sum[axes=(0,)] cui
          cuv:f32[1,100] = reshape[dimensions=None new_sizes=(1, 100)] cuu
          cuw:f32[100] = reshape[dimensions=None new_sizes=(100,)] cuv
          cux:f32[100,512] = dot_general[
            dimension_numbers=(((0,), (0,)), ((), ()))
            precision=None
            preferred_element_type=None
          ] cui cso
          cuy:f32[512,100] = transpose[permutation=(1, 0)] cux
          cuz:f32[200,512] = dot_general[
            dimension_numbers=(((1,), (1,)), ((), ()))
            precision=None
            preferred_element_type=None
          ] cui csn
          cva:f32[200,512] = div cuz 16.0
          cvb:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(0, 3)
            shape=(200, 4, 4, 512)
          ] cva
          cvc:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cvd:bool[200,4,4,512] = eq cjr True
          cve:f32[200,4,4,512] = select_n cvd cvc cvb
          cvf:f32[512] = reduce_sum[axes=(0, 1, 2)] cve
          cvg:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cvf
          cvh:f32[512] = reshape[dimensions=None new_sizes=(512,)] cvg
          cvi:f32[200,4,4,512] = mul cju cve
          cvj:f32[512] = reduce_sum[axes=(0, 1, 2)] cvi
          cvk:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cvj
          cvl:f32[200,4,4,512] = mul cve cjt
          cvm:f32[1,1,1,512] = mul csi cvk
          cvn:f32[1,1,1,512] = mul cvk csh
          cvo:f32[512] = reshape[dimensions=None new_sizes=(512,)] cvm
          cvp:f32[1,1,1,512] = mul cvn csm
          cvq:f32[512] = reshape[dimensions=None new_sizes=(512,)] cvp
          cvr:f32[512] = mul cvq csj
          cvs:f32[512] = neg cvr
          cvt:f32[512] = mul cvs csl
          cvu:f32[512] = div cvr 3200.0
          cvv:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] cvu
          cvw:f32[200,4,4,512] = mul cvv csk
          cvx:f32[200,4,4,512] = neg cvl
          cvy:f32[512] = reduce_sum[axes=(0, 1, 2)] cvx
          cvz:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cvy
          cwa:f32[200,4,4,512] = add_any cvw cvl
          cwb:f32[512] = reshape[dimensions=None new_sizes=(512,)] cvz
          cwc:f32[512] = add_any cvt cwb
          cwd:f32[512] = div cwc 3200.0
          cwe:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] cwd
          cwf:f32[200,4,4,512] = add_any cwa cwe
          cwg:f32[3,3,512,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 4, 4, 512)
            window_strides=(1, 1)
          ] csg cwf
          cwh:f32[3,3,512,512] = rev[dimensions=(0, 1)] csf
          cwi:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 512, 512)
            window_strides=(1, 1)
          ] cwf cwh
          cwj:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cwk:bool[200,4,4,512] = eq cjv True
          cwl:f32[200,4,4,512] = select_n cwk cwj cwi
          cwm:f32[512] = reduce_sum[axes=(0, 1, 2)] cwl
          cwn:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cwm
          cwo:f32[512] = reshape[dimensions=None new_sizes=(512,)] cwn
          cwp:f32[200,4,4,512] = mul cjy cwl
          cwq:f32[512] = reduce_sum[axes=(0, 1, 2)] cwp
          cwr:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cwq
          cws:f32[200,4,4,512] = mul cwl cjx
          cwt:f32[1,1,1,512] = mul csa cwr
          cwu:f32[1,1,1,512] = mul cwr crz
          cwv:f32[512] = reshape[dimensions=None new_sizes=(512,)] cwt
          cww:f32[1,1,1,512] = mul cwu cse
          cwx:f32[512] = reshape[dimensions=None new_sizes=(512,)] cww
          cwy:f32[512] = mul cwx csb
          cwz:f32[512] = neg cwy
          cxa:f32[512] = mul cwz csd
          cxb:f32[512] = div cwy 3200.0
          cxc:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] cxb
          cxd:f32[200,4,4,512] = mul cxc csc
          cxe:f32[200,4,4,512] = neg cws
          cxf:f32[512] = reduce_sum[axes=(0, 1, 2)] cxe
          cxg:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cxf
          cxh:f32[200,4,4,512] = add_any cxd cws
          cxi:f32[512] = reshape[dimensions=None new_sizes=(512,)] cxg
          cxj:f32[512] = add_any cxa cxi
          cxk:f32[512] = div cxj 3200.0
          cxl:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] cxk
          cxm:f32[200,4,4,512] = add_any cxh cxl
          cxn:f32[3,3,512,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 4, 4, 512)
            window_strides=(1, 1)
          ] cry cxm
          cxo:f32[3,3,512,512] = rev[dimensions=(0, 1)] crx
          cxp:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 512, 512)
            window_strides=(1, 1)
          ] cxm cxo
          cxq:f32[200,4,4,512] = add_any cve cxp
          cxr:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cxs:bool[200,4,4,512] = eq cjz True
          cxt:f32[200,4,4,512] = select_n cxs cxr cxq
          cxu:f32[512] = reduce_sum[axes=(0, 1, 2)] cxt
          cxv:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cxu
          cxw:f32[512] = reshape[dimensions=None new_sizes=(512,)] cxv
          cxx:f32[200,4,4,512] = mul crd cxt
          cxy:f32[512] = reduce_sum[axes=(0, 1, 2)] cxx
          cxz:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cxy
          cya:f32[200,4,4,512] = mul cxt crc
          cyb:f32[1,1,1,512] = mul crs cxz
          cyc:f32[1,1,1,512] = mul cxz crr
          cyd:f32[512] = reshape[dimensions=None new_sizes=(512,)] cyb
          cye:f32[1,1,1,512] = mul cyc crw
          cyf:f32[512] = reshape[dimensions=None new_sizes=(512,)] cye
          cyg:f32[512] = mul cyf crt
          cyh:f32[512] = neg cyg
          cyi:f32[512] = mul cyh crv
          cyj:f32[512] = div cyg 3200.0
          cyk:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] cyj
          cyl:f32[200,4,4,512] = mul cyk cru
          cym:f32[200,4,4,512] = neg cya
          cyn:f32[512] = reduce_sum[axes=(0, 1, 2)] cym
          cyo:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] cyn
          cyp:f32[200,4,4,512] = add_any cyl cya
          cyq:f32[512] = reshape[dimensions=None new_sizes=(512,)] cyo
          cyr:f32[512] = add_any cyi cyq
          cys:f32[512] = div cyr 3200.0
          cyt:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] cys
          cyu:f32[200,4,4,512] = add_any cyp cyt
          cyv:f32[3,3,512,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 4, 4, 512)
            window_strides=(1, 1)
          ] crq cyu
          cyw:f32[3,3,512,512] = rev[dimensions=(0, 1)] crp
          cyx:f32[200,4,4,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 512, 512)
            window_strides=(1, 1)
          ] cyu cyw
          cyy:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 4, 4, 512)
          ] 0.0
          cyz:bool[200,4,4,512] = eq cre True
          cza:f32[200,4,4,512] = select_n cyz cyy cyx
          czb:f32[512] = reduce_sum[axes=(0, 1, 2)] cza
          czc:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] czb
          czd:f32[512] = reshape[dimensions=None new_sizes=(512,)] czc
          cze:f32[200,4,4,512] = mul crh cza
          czf:f32[512] = reduce_sum[axes=(0, 1, 2)] cze
          czg:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] czf
          czh:f32[200,4,4,512] = mul cza crg
          czi:f32[1,1,1,512] = mul crk czg
          czj:f32[1,1,1,512] = mul czg crj
          czk:f32[512] = reshape[dimensions=None new_sizes=(512,)] czi
          czl:f32[1,1,1,512] = mul czj cro
          czm:f32[512] = reshape[dimensions=None new_sizes=(512,)] czl
          czn:f32[512] = mul czm crl
          czo:f32[512] = neg czn
          czp:f32[512] = mul czo crn
          czq:f32[512] = div czn 3200.0
          czr:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] czq
          czs:f32[200,4,4,512] = mul czr crm
          czt:f32[200,4,4,512] = neg czh
          czu:f32[512] = reduce_sum[axes=(0, 1, 2)] czt
          czv:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] czu
          czw:f32[200,4,4,512] = add_any czs czh
          czx:f32[512] = reshape[dimensions=None new_sizes=(512,)] czv
          czy:f32[512] = add_any czp czx
          czz:f32[512] = div czy 3200.0
          daa:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] czz
          dab:f32[200,4,4,512] = add_any czw daa
          dac:f32[3,3,256,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 0), (1, 0))
            precision=None
            preferred_element_type=None
            rhs_dilation=(2, 2)
            rhs_shape=(200, 4, 4, 512)
            window_strides=(1, 1)
          ] cqv dab
          dad:f32[3,3,256,512] = rev[dimensions=(0, 1)] cri
          dae:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(2, 2)
            lhs_shape=(200, 4, 4, 512)
            padding=((1, 2), (1, 2))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 512)
            window_strides=(1, 1)
          ] dab dad
          daf:f32[512] = reduce_sum[axes=(0, 1, 2)] cxt
          dag:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] daf
          dah:f32[512] = reshape[dimensions=None new_sizes=(512,)] dag
          dai:f32[200,4,4,512] = mul ckc cxt
          daj:f32[512] = reduce_sum[axes=(0, 1, 2)] dai
          dak:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] daj
          dal:f32[200,4,4,512] = mul cxt ckb
          dam:f32[1,1,1,512] = mul cqx dak
          dan:f32[1,1,1,512] = mul dak cqw
          dao:f32[512] = reshape[dimensions=None new_sizes=(512,)] dam
          dap:f32[1,1,1,512] = mul dan crb
          daq:f32[512] = reshape[dimensions=None new_sizes=(512,)] dap
          dar:f32[512] = mul daq cqy
          das:f32[512] = neg dar
          dat:f32[512] = mul das cra
          dau:f32[512] = div dar 3200.0
          dav:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] dau
          daw:f32[200,4,4,512] = mul dav cqz
          dax:f32[200,4,4,512] = neg dal
          day:f32[512] = reduce_sum[axes=(0, 1, 2)] dax
          daz:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] day
          dba:f32[200,4,4,512] = add_any daw dal
          dbb:f32[512] = reshape[dimensions=None new_sizes=(512,)] daz
          dbc:f32[512] = add_any dat dbb
          dbd:f32[512] = div dbc 3200.0
          dbe:f32[200,4,4,512] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 4, 4, 512)
          ] dbd
          dbf:f32[200,4,4,512] = add_any dba dbe
          dbg:f32[1,1,256,512] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((0, -1), (0, -1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(2, 2)
            rhs_shape=(200, 4, 4, 512)
            window_strides=(1, 1)
          ] cqv dbf
          dbh:f32[1,1,256,512] = rev[dimensions=(0, 1)] cqu
          dbi:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(2, 2)
            lhs_shape=(200, 4, 4, 512)
            padding=((0, 1), (0, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(1, 1, 256, 512)
            window_strides=(1, 1)
          ] dbf dbh
          dbj:f32[200,8,8,256] = add_any dae dbi
          dbk:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          dbl:bool[200,8,8,256] = eq ckd True
          dbm:f32[200,8,8,256] = select_n dbl dbk dbj
          dbn:f32[256] = reduce_sum[axes=(0, 1, 2)] dbm
          dbo:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dbn
          dbp:f32[256] = reshape[dimensions=None new_sizes=(256,)] dbo
          dbq:f32[200,8,8,256] = mul ckg dbm
          dbr:f32[256] = reduce_sum[axes=(0, 1, 2)] dbq
          dbs:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dbr
          dbt:f32[200,8,8,256] = mul dbm ckf
          dbu:f32[1,1,1,256] = mul cqp dbs
          dbv:f32[1,1,1,256] = mul dbs cqo
          dbw:f32[256] = reshape[dimensions=None new_sizes=(256,)] dbu
          dbx:f32[1,1,1,256] = mul dbv cqt
          dby:f32[256] = reshape[dimensions=None new_sizes=(256,)] dbx
          dbz:f32[256] = mul dby cqq
          dca:f32[256] = neg dbz
          dcb:f32[256] = mul dca cqs
          dcc:f32[256] = div dbz 12800.0
          dcd:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dcc
          dce:f32[200,8,8,256] = mul dcd cqr
          dcf:f32[200,8,8,256] = neg dbt
          dcg:f32[256] = reduce_sum[axes=(0, 1, 2)] dcf
          dch:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dcg
          dci:f32[200,8,8,256] = add_any dce dbt
          dcj:f32[256] = reshape[dimensions=None new_sizes=(256,)] dch
          dck:f32[256] = add_any dcb dcj
          dcl:f32[256] = div dck 12800.0
          dcm:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dcl
          dcn:f32[200,8,8,256] = add_any dci dcm
          dco:f32[3,3,256,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 8, 8, 256)
            window_strides=(1, 1)
          ] cqn dcn
          dcp:f32[3,3,256,256] = rev[dimensions=(0, 1)] cqm
          dcq:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 256)
            window_strides=(1, 1)
          ] dcn dcp
          dcr:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          dcs:bool[200,8,8,256] = eq ckh True
          dct:f32[200,8,8,256] = select_n dcs dcr dcq
          dcu:f32[256] = reduce_sum[axes=(0, 1, 2)] dct
          dcv:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dcu
          dcw:f32[256] = reshape[dimensions=None new_sizes=(256,)] dcv
          dcx:f32[200,8,8,256] = mul ckk dct
          dcy:f32[256] = reduce_sum[axes=(0, 1, 2)] dcx
          dcz:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dcy
          dda:f32[200,8,8,256] = mul dct ckj
          ddb:f32[1,1,1,256] = mul cqh dcz
          ddc:f32[1,1,1,256] = mul dcz cqg
          ddd:f32[256] = reshape[dimensions=None new_sizes=(256,)] ddb
          dde:f32[1,1,1,256] = mul ddc cql
          ddf:f32[256] = reshape[dimensions=None new_sizes=(256,)] dde
          ddg:f32[256] = mul ddf cqi
          ddh:f32[256] = neg ddg
          ddi:f32[256] = mul ddh cqk
          ddj:f32[256] = div ddg 12800.0
          ddk:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] ddj
          ddl:f32[200,8,8,256] = mul ddk cqj
          ddm:f32[200,8,8,256] = neg dda
          ddn:f32[256] = reduce_sum[axes=(0, 1, 2)] ddm
          ddo:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] ddn
          ddp:f32[200,8,8,256] = add_any ddl dda
          ddq:f32[256] = reshape[dimensions=None new_sizes=(256,)] ddo
          ddr:f32[256] = add_any ddi ddq
          dds:f32[256] = div ddr 12800.0
          ddt:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dds
          ddu:f32[200,8,8,256] = add_any ddp ddt
          ddv:f32[3,3,256,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 8, 8, 256)
            window_strides=(1, 1)
          ] cqf ddu
          ddw:f32[3,3,256,256] = rev[dimensions=(0, 1)] cqe
          ddx:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 256)
            window_strides=(1, 1)
          ] ddu ddw
          ddy:f32[200,8,8,256] = add_any dbm ddx
          ddz:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          dea:bool[200,8,8,256] = eq ckl True
          deb:f32[200,8,8,256] = select_n dea ddz ddy
          dec:f32[256] = reduce_sum[axes=(0, 1, 2)] deb
          ded:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dec
          dee:f32[256] = reshape[dimensions=None new_sizes=(256,)] ded
          def:f32[200,8,8,256] = mul cpk deb
          deg:f32[256] = reduce_sum[axes=(0, 1, 2)] def
          deh:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] deg
          dei:f32[200,8,8,256] = mul deb cpj
          dej:f32[1,1,1,256] = mul cpz deh
          dek:f32[1,1,1,256] = mul deh cpy
          del:f32[256] = reshape[dimensions=None new_sizes=(256,)] dej
          dem:f32[1,1,1,256] = mul dek cqd
          den:f32[256] = reshape[dimensions=None new_sizes=(256,)] dem
          deo:f32[256] = mul den cqa
          dep:f32[256] = neg deo
          deq:f32[256] = mul dep cqc
          der:f32[256] = div deo 12800.0
          des:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] der
          det:f32[200,8,8,256] = mul des cqb
          deu:f32[200,8,8,256] = neg dei
          dev:f32[256] = reduce_sum[axes=(0, 1, 2)] deu
          dew:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dev
          dex:f32[200,8,8,256] = add_any det dei
          dey:f32[256] = reshape[dimensions=None new_sizes=(256,)] dew
          dez:f32[256] = add_any deq dey
          dfa:f32[256] = div dez 12800.0
          dfb:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dfa
          dfc:f32[200,8,8,256] = add_any dex dfb
          dfd:f32[3,3,256,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 8, 8, 256)
            window_strides=(1, 1)
          ] cpx dfc
          dfe:f32[3,3,256,256] = rev[dimensions=(0, 1)] cpw
          dff:f32[200,8,8,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 256, 256)
            window_strides=(1, 1)
          ] dfc dfe
          dfg:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 8, 8, 256)
          ] 0.0
          dfh:bool[200,8,8,256] = eq cpl True
          dfi:f32[200,8,8,256] = select_n dfh dfg dff
          dfj:f32[256] = reduce_sum[axes=(0, 1, 2)] dfi
          dfk:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dfj
          dfl:f32[256] = reshape[dimensions=None new_sizes=(256,)] dfk
          dfm:f32[200,8,8,256] = mul cpo dfi
          dfn:f32[256] = reduce_sum[axes=(0, 1, 2)] dfm
          dfo:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dfn
          dfp:f32[200,8,8,256] = mul dfi cpn
          dfq:f32[1,1,1,256] = mul cpr dfo
          dfr:f32[1,1,1,256] = mul dfo cpq
          dfs:f32[256] = reshape[dimensions=None new_sizes=(256,)] dfq
          dft:f32[1,1,1,256] = mul dfr cpv
          dfu:f32[256] = reshape[dimensions=None new_sizes=(256,)] dft
          dfv:f32[256] = mul dfu cps
          dfw:f32[256] = neg dfv
          dfx:f32[256] = mul dfw cpu
          dfy:f32[256] = div dfv 12800.0
          dfz:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dfy
          dga:f32[200,8,8,256] = mul dfz cpt
          dgb:f32[200,8,8,256] = neg dfp
          dgc:f32[256] = reduce_sum[axes=(0, 1, 2)] dgb
          dgd:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dgc
          dge:f32[200,8,8,256] = add_any dga dfp
          dgf:f32[256] = reshape[dimensions=None new_sizes=(256,)] dgd
          dgg:f32[256] = add_any dfx dgf
          dgh:f32[256] = div dgg 12800.0
          dgi:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dgh
          dgj:f32[200,8,8,256] = add_any dge dgi
          dgk:f32[3,3,128,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 0), (1, 0))
            precision=None
            preferred_element_type=None
            rhs_dilation=(2, 2)
            rhs_shape=(200, 8, 8, 256)
            window_strides=(1, 1)
          ] cpc dgj
          dgl:f32[3,3,128,256] = rev[dimensions=(0, 1)] cpp
          dgm:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(2, 2)
            lhs_shape=(200, 8, 8, 256)
            padding=((1, 2), (1, 2))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 256)
            window_strides=(1, 1)
          ] dgj dgl
          dgn:f32[256] = reduce_sum[axes=(0, 1, 2)] deb
          dgo:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dgn
          dgp:f32[256] = reshape[dimensions=None new_sizes=(256,)] dgo
          dgq:f32[200,8,8,256] = mul cko deb
          dgr:f32[256] = reduce_sum[axes=(0, 1, 2)] dgq
          dgs:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dgr
          dgt:f32[200,8,8,256] = mul deb ckn
          dgu:f32[1,1,1,256] = mul cpe dgs
          dgv:f32[1,1,1,256] = mul dgs cpd
          dgw:f32[256] = reshape[dimensions=None new_sizes=(256,)] dgu
          dgx:f32[1,1,1,256] = mul dgv cpi
          dgy:f32[256] = reshape[dimensions=None new_sizes=(256,)] dgx
          dgz:f32[256] = mul dgy cpf
          dha:f32[256] = neg dgz
          dhb:f32[256] = mul dha cph
          dhc:f32[256] = div dgz 12800.0
          dhd:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dhc
          dhe:f32[200,8,8,256] = mul dhd cpg
          dhf:f32[200,8,8,256] = neg dgt
          dhg:f32[256] = reduce_sum[axes=(0, 1, 2)] dhf
          dhh:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] dhg
          dhi:f32[200,8,8,256] = add_any dhe dgt
          dhj:f32[256] = reshape[dimensions=None new_sizes=(256,)] dhh
          dhk:f32[256] = add_any dhb dhj
          dhl:f32[256] = div dhk 12800.0
          dhm:f32[200,8,8,256] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 8, 8, 256)
          ] dhl
          dhn:f32[200,8,8,256] = add_any dhi dhm
          dho:f32[1,1,128,256] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((0, -1), (0, -1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(2, 2)
            rhs_shape=(200, 8, 8, 256)
            window_strides=(1, 1)
          ] cpc dhn
          dhp:f32[1,1,128,256] = rev[dimensions=(0, 1)] cpb
          dhq:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(2, 2)
            lhs_shape=(200, 8, 8, 256)
            padding=((0, 1), (0, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(1, 1, 128, 256)
            window_strides=(1, 1)
          ] dhn dhp
          dhr:f32[200,16,16,128] = add_any dgm dhq
          dhs:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          dht:bool[200,16,16,128] = eq ckp True
          dhu:f32[200,16,16,128] = select_n dht dhs dhr
          dhv:f32[128] = reduce_sum[axes=(0, 1, 2)] dhu
          dhw:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dhv
          dhx:f32[128] = reshape[dimensions=None new_sizes=(128,)] dhw
          dhy:f32[200,16,16,128] = mul cks dhu
          dhz:f32[128] = reduce_sum[axes=(0, 1, 2)] dhy
          dia:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dhz
          dib:f32[200,16,16,128] = mul dhu ckr
          dic:f32[1,1,1,128] = mul cow dia
          did:f32[1,1,1,128] = mul dia cov
          die:f32[128] = reshape[dimensions=None new_sizes=(128,)] dic
          dif:f32[1,1,1,128] = mul did cpa
          dig:f32[128] = reshape[dimensions=None new_sizes=(128,)] dif
          dih:f32[128] = mul dig cox
          dii:f32[128] = neg dih
          dij:f32[128] = mul dii coz
          dik:f32[128] = div dih 51200.0
          dil:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dik
          dim:f32[200,16,16,128] = mul dil coy
          din:f32[200,16,16,128] = neg dib
          dio:f32[128] = reduce_sum[axes=(0, 1, 2)] din
          dip:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dio
          diq:f32[200,16,16,128] = add_any dim dib
          dir:f32[128] = reshape[dimensions=None new_sizes=(128,)] dip
          dis:f32[128] = add_any dij dir
          dit:f32[128] = div dis 51200.0
          diu:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dit
          div:f32[200,16,16,128] = add_any diq diu
          diw:f32[3,3,128,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 16, 16, 128)
            window_strides=(1, 1)
          ] cou div
          dix:f32[3,3,128,128] = rev[dimensions=(0, 1)] cot
          diy:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 128)
            window_strides=(1, 1)
          ] div dix
          diz:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          dja:bool[200,16,16,128] = eq ckt True
          djb:f32[200,16,16,128] = select_n dja diz diy
          djc:f32[128] = reduce_sum[axes=(0, 1, 2)] djb
          djd:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] djc
          dje:f32[128] = reshape[dimensions=None new_sizes=(128,)] djd
          djf:f32[200,16,16,128] = mul ckw djb
          djg:f32[128] = reduce_sum[axes=(0, 1, 2)] djf
          djh:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] djg
          dji:f32[200,16,16,128] = mul djb ckv
          djj:f32[1,1,1,128] = mul coo djh
          djk:f32[1,1,1,128] = mul djh con
          djl:f32[128] = reshape[dimensions=None new_sizes=(128,)] djj
          djm:f32[1,1,1,128] = mul djk cos
          djn:f32[128] = reshape[dimensions=None new_sizes=(128,)] djm
          djo:f32[128] = mul djn cop
          djp:f32[128] = neg djo
          djq:f32[128] = mul djp cor
          djr:f32[128] = div djo 51200.0
          djs:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] djr
          djt:f32[200,16,16,128] = mul djs coq
          dju:f32[200,16,16,128] = neg dji
          djv:f32[128] = reduce_sum[axes=(0, 1, 2)] dju
          djw:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] djv
          djx:f32[200,16,16,128] = add_any djt dji
          djy:f32[128] = reshape[dimensions=None new_sizes=(128,)] djw
          djz:f32[128] = add_any djq djy
          dka:f32[128] = div djz 51200.0
          dkb:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dka
          dkc:f32[200,16,16,128] = add_any djx dkb
          dkd:f32[3,3,128,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 16, 16, 128)
            window_strides=(1, 1)
          ] com dkc
          dke:f32[3,3,128,128] = rev[dimensions=(0, 1)] col
          dkf:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 128)
            window_strides=(1, 1)
          ] dkc dke
          dkg:f32[200,16,16,128] = add_any dhu dkf
          dkh:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          dki:bool[200,16,16,128] = eq ckx True
          dkj:f32[200,16,16,128] = select_n dki dkh dkg
          dkk:f32[128] = reduce_sum[axes=(0, 1, 2)] dkj
          dkl:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dkk
          dkm:f32[128] = reshape[dimensions=None new_sizes=(128,)] dkl
          dkn:f32[200,16,16,128] = mul cnr dkj
          dko:f32[128] = reduce_sum[axes=(0, 1, 2)] dkn
          dkp:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dko
          dkq:f32[200,16,16,128] = mul dkj cnq
          dkr:f32[1,1,1,128] = mul cog dkp
          dks:f32[1,1,1,128] = mul dkp cof
          dkt:f32[128] = reshape[dimensions=None new_sizes=(128,)] dkr
          dku:f32[1,1,1,128] = mul dks cok
          dkv:f32[128] = reshape[dimensions=None new_sizes=(128,)] dku
          dkw:f32[128] = mul dkv coh
          dkx:f32[128] = neg dkw
          dky:f32[128] = mul dkx coj
          dkz:f32[128] = div dkw 51200.0
          dla:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dkz
          dlb:f32[200,16,16,128] = mul dla coi
          dlc:f32[200,16,16,128] = neg dkq
          dld:f32[128] = reduce_sum[axes=(0, 1, 2)] dlc
          dle:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dld
          dlf:f32[200,16,16,128] = add_any dlb dkq
          dlg:f32[128] = reshape[dimensions=None new_sizes=(128,)] dle
          dlh:f32[128] = add_any dky dlg
          dli:f32[128] = div dlh 51200.0
          dlj:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dli
          dlk:f32[200,16,16,128] = add_any dlf dlj
          dll:f32[3,3,128,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 16, 16, 128)
            window_strides=(1, 1)
          ] coe dlk
          dlm:f32[3,3,128,128] = rev[dimensions=(0, 1)] cod
          dln:f32[200,16,16,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 128, 128)
            window_strides=(1, 1)
          ] dlk dlm
          dlo:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 16, 16, 128)
          ] 0.0
          dlp:bool[200,16,16,128] = eq cns True
          dlq:f32[200,16,16,128] = select_n dlp dlo dln
          dlr:f32[128] = reduce_sum[axes=(0, 1, 2)] dlq
          dls:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dlr
          dlt:f32[128] = reshape[dimensions=None new_sizes=(128,)] dls
          dlu:f32[200,16,16,128] = mul cnv dlq
          dlv:f32[128] = reduce_sum[axes=(0, 1, 2)] dlu
          dlw:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dlv
          dlx:f32[200,16,16,128] = mul dlq cnu
          dly:f32[1,1,1,128] = mul cny dlw
          dlz:f32[1,1,1,128] = mul dlw cnx
          dma:f32[128] = reshape[dimensions=None new_sizes=(128,)] dly
          dmb:f32[1,1,1,128] = mul dlz coc
          dmc:f32[128] = reshape[dimensions=None new_sizes=(128,)] dmb
          dmd:f32[128] = mul dmc cnz
          dme:f32[128] = neg dmd
          dmf:f32[128] = mul dme cob
          dmg:f32[128] = div dmd 51200.0
          dmh:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dmg
          dmi:f32[200,16,16,128] = mul dmh coa
          dmj:f32[200,16,16,128] = neg dlx
          dmk:f32[128] = reduce_sum[axes=(0, 1, 2)] dmj
          dml:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dmk
          dmm:f32[200,16,16,128] = add_any dmi dlx
          dmn:f32[128] = reshape[dimensions=None new_sizes=(128,)] dml
          dmo:f32[128] = add_any dmf dmn
          dmp:f32[128] = div dmo 51200.0
          dmq:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dmp
          dmr:f32[200,16,16,128] = add_any dmm dmq
          dms:f32[3,3,64,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 0), (1, 0))
            precision=None
            preferred_element_type=None
            rhs_dilation=(2, 2)
            rhs_shape=(200, 16, 16, 128)
            window_strides=(1, 1)
          ] cnj dmr
          dmt:f32[3,3,64,128] = rev[dimensions=(0, 1)] cnw
          dmu:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(2, 2)
            lhs_shape=(200, 16, 16, 128)
            padding=((1, 2), (1, 2))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 128)
            window_strides=(1, 1)
          ] dmr dmt
          dmv:f32[128] = reduce_sum[axes=(0, 1, 2)] dkj
          dmw:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dmv
          dmx:f32[128] = reshape[dimensions=None new_sizes=(128,)] dmw
          dmy:f32[200,16,16,128] = mul cla dkj
          dmz:f32[128] = reduce_sum[axes=(0, 1, 2)] dmy
          dna:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dmz
          dnb:f32[200,16,16,128] = mul dkj ckz
          dnc:f32[1,1,1,128] = mul cnl dna
          dnd:f32[1,1,1,128] = mul dna cnk
          dne:f32[128] = reshape[dimensions=None new_sizes=(128,)] dnc
          dnf:f32[1,1,1,128] = mul dnd cnp
          dng:f32[128] = reshape[dimensions=None new_sizes=(128,)] dnf
          dnh:f32[128] = mul dng cnm
          dni:f32[128] = neg dnh
          dnj:f32[128] = mul dni cno
          dnk:f32[128] = div dnh 51200.0
          dnl:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dnk
          dnm:f32[200,16,16,128] = mul dnl cnn
          dnn:f32[200,16,16,128] = neg dnb
          dno:f32[128] = reduce_sum[axes=(0, 1, 2)] dnn
          dnp:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] dno
          dnq:f32[200,16,16,128] = add_any dnm dnb
          dnr:f32[128] = reshape[dimensions=None new_sizes=(128,)] dnp
          dns:f32[128] = add_any dnj dnr
          dnt:f32[128] = div dns 51200.0
          dnu:f32[200,16,16,128] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 16, 16, 128)
          ] dnt
          dnv:f32[200,16,16,128] = add_any dnq dnu
          dnw:f32[1,1,64,128] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((0, -1), (0, -1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(2, 2)
            rhs_shape=(200, 16, 16, 128)
            window_strides=(1, 1)
          ] cnj dnv
          dnx:f32[1,1,64,128] = rev[dimensions=(0, 1)] cni
          dny:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(2, 2)
            lhs_shape=(200, 16, 16, 128)
            padding=((0, 1), (0, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(1, 1, 64, 128)
            window_strides=(1, 1)
          ] dnv dnx
          dnz:f32[200,32,32,64] = add_any dmu dny
          doa:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          dob:bool[200,32,32,64] = eq clb True
          doc:f32[200,32,32,64] = select_n dob doa dnz
          dod:f32[64] = reduce_sum[axes=(0, 1, 2)] doc
          doe:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dod
          dof:f32[64] = reshape[dimensions=None new_sizes=(64,)] doe
          dog:f32[200,32,32,64] = mul cle doc
          doh:f32[64] = reduce_sum[axes=(0, 1, 2)] dog
          doi:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] doh
          doj:f32[200,32,32,64] = mul doc cld
          dok:f32[1,1,1,64] = mul cnd doi
          dol:f32[1,1,1,64] = mul doi cnc
          dom:f32[64] = reshape[dimensions=None new_sizes=(64,)] dok
          don:f32[1,1,1,64] = mul dol cnh
          doo:f32[64] = reshape[dimensions=None new_sizes=(64,)] don
          dop:f32[64] = mul doo cne
          doq:f32[64] = neg dop
          dor:f32[64] = mul doq cng
          dos:f32[64] = div dop 204800.0
          dot:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dos
          dou:f32[200,32,32,64] = mul dot cnf
          dov:f32[200,32,32,64] = neg doj
          dow:f32[64] = reduce_sum[axes=(0, 1, 2)] dov
          dox:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dow
          doy:f32[200,32,32,64] = add_any dou doj
          doz:f32[64] = reshape[dimensions=None new_sizes=(64,)] dox
          dpa:f32[64] = add_any dor doz
          dpb:f32[64] = div dpa 204800.0
          dpc:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dpb
          dpd:f32[200,32,32,64] = add_any doy dpc
          dpe:f32[3,3,64,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 32, 32, 64)
            window_strides=(1, 1)
          ] cnb dpd
          dpf:f32[3,3,64,64] = rev[dimensions=(0, 1)] cna
          dpg:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] dpd dpf
          dph:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          dpi:bool[200,32,32,64] = eq clf True
          dpj:f32[200,32,32,64] = select_n dpi dph dpg
          dpk:f32[64] = reduce_sum[axes=(0, 1, 2)] dpj
          dpl:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dpk
          dpm:f32[64] = reshape[dimensions=None new_sizes=(64,)] dpl
          dpn:f32[200,32,32,64] = mul cli dpj
          dpo:f32[64] = reduce_sum[axes=(0, 1, 2)] dpn
          dpp:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dpo
          dpq:f32[200,32,32,64] = mul dpj clh
          dpr:f32[1,1,1,64] = mul cmv dpp
          dps:f32[1,1,1,64] = mul dpp cmu
          dpt:f32[64] = reshape[dimensions=None new_sizes=(64,)] dpr
          dpu:f32[1,1,1,64] = mul dps cmz
          dpv:f32[64] = reshape[dimensions=None new_sizes=(64,)] dpu
          dpw:f32[64] = mul dpv cmw
          dpx:f32[64] = neg dpw
          dpy:f32[64] = mul dpx cmy
          dpz:f32[64] = div dpw 204800.0
          dqa:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dpz
          dqb:f32[200,32,32,64] = mul dqa cmx
          dqc:f32[200,32,32,64] = neg dpq
          dqd:f32[64] = reduce_sum[axes=(0, 1, 2)] dqc
          dqe:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dqd
          dqf:f32[200,32,32,64] = add_any dqb dpq
          dqg:f32[64] = reshape[dimensions=None new_sizes=(64,)] dqe
          dqh:f32[64] = add_any dpy dqg
          dqi:f32[64] = div dqh 204800.0
          dqj:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dqi
          dqk:f32[200,32,32,64] = add_any dqf dqj
          dql:f32[3,3,64,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 32, 32, 64)
            window_strides=(1, 1)
          ] cmt dqk
          dqm:f32[3,3,64,64] = rev[dimensions=(0, 1)] cms
          dqn:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] dqk dqm
          dqo:f32[200,32,32,64] = add_any doc dqn
          dqp:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          dqq:bool[200,32,32,64] = eq clj True
          dqr:f32[200,32,32,64] = select_n dqq dqp dqo
          dqs:f32[64] = reduce_sum[axes=(0, 1, 2)] dqr
          dqt:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dqs
          dqu:f32[64] = reshape[dimensions=None new_sizes=(64,)] dqt
          dqv:f32[200,32,32,64] = mul clm dqr
          dqw:f32[64] = reduce_sum[axes=(0, 1, 2)] dqv
          dqx:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dqw
          dqy:f32[200,32,32,64] = mul dqr cll
          dqz:f32[1,1,1,64] = mul cmn dqx
          dra:f32[1,1,1,64] = mul dqx cmm
          drb:f32[64] = reshape[dimensions=None new_sizes=(64,)] dqz
          drc:f32[1,1,1,64] = mul dra cmr
          drd:f32[64] = reshape[dimensions=None new_sizes=(64,)] drc
          dre:f32[64] = mul drd cmo
          drf:f32[64] = neg dre
          drg:f32[64] = mul drf cmq
          drh:f32[64] = div dre 204800.0
          dri:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] drh
          drj:f32[200,32,32,64] = mul dri cmp
          drk:f32[200,32,32,64] = neg dqy
          drl:f32[64] = reduce_sum[axes=(0, 1, 2)] drk
          drm:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] drl
          drn:f32[200,32,32,64] = add_any drj dqy
          dro:f32[64] = reshape[dimensions=None new_sizes=(64,)] drm
          drp:f32[64] = add_any drg dro
          drq:f32[64] = div drp 204800.0
          drr:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] drq
          drs:f32[200,32,32,64] = add_any drn drr
          drt:f32[3,3,64,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 32, 32, 64)
            window_strides=(1, 1)
          ] cml drs
          dru:f32[3,3,64,64] = rev[dimensions=(0, 1)] cmk
          drv:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] drs dru
          drw:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          drx:bool[200,32,32,64] = eq cln True
          dry:f32[200,32,32,64] = select_n drx drw drv
          drz:f32[64] = reduce_sum[axes=(0, 1, 2)] dry
          dsa:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] drz
          dsb:f32[64] = reshape[dimensions=None new_sizes=(64,)] dsa
          dsc:f32[200,32,32,64] = mul clq dry
          dsd:f32[64] = reduce_sum[axes=(0, 1, 2)] dsc
          dse:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dsd
          dsf:f32[200,32,32,64] = mul dry clp
          dsg:f32[1,1,1,64] = mul cmf dse
          dsh:f32[1,1,1,64] = mul dse cme
          dsi:f32[64] = reshape[dimensions=None new_sizes=(64,)] dsg
          dsj:f32[1,1,1,64] = mul dsh cmj
          dsk:f32[64] = reshape[dimensions=None new_sizes=(64,)] dsj
          dsl:f32[64] = mul dsk cmg
          dsm:f32[64] = neg dsl
          dsn:f32[64] = mul dsm cmi
          dso:f32[64] = div dsl 204800.0
          dsp:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dso
          dsq:f32[200,32,32,64] = mul dsp cmh
          dsr:f32[200,32,32,64] = neg dsf
          dss:f32[64] = reduce_sum[axes=(0, 1, 2)] dsr
          dst:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dss
          dsu:f32[200,32,32,64] = add_any dsq dsf
          dsv:f32[64] = reshape[dimensions=None new_sizes=(64,)] dst
          dsw:f32[64] = add_any dsn dsv
          dsx:f32[64] = div dsw 204800.0
          dsy:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dsx
          dsz:f32[200,32,32,64] = add_any dsu dsy
          dta:f32[3,3,64,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 32, 32, 64)
            window_strides=(1, 1)
          ] cmd dsz
          dtb:f32[3,3,64,64] = rev[dimensions=(0, 1)] cmc
          dtc:f32[200,32,32,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 64)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(3, 3, 64, 64)
            window_strides=(1, 1)
          ] dsz dtb
          dtd:f32[200,32,32,64] = add_any dqr dtc
          dte:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=()
            shape=(200, 32, 32, 64)
          ] 0.0
          dtf:bool[200,32,32,64] = eq clr True
          dtg:f32[200,32,32,64] = select_n dtf dte dtd
          dth:f32[64] = reduce_sum[axes=(0, 1, 2)] dtg
          dti:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dth
          dtj:f32[64] = reshape[dimensions=None new_sizes=(64,)] dti
          dtk:f32[200,32,32,64] = mul clu dtg
          dtl:f32[64] = reduce_sum[axes=(0, 1, 2)] dtk
          dtm:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dtl
          dtn:f32[200,32,32,64] = mul dtg clt
          dto:f32[1,1,1,64] = mul clx dtm
          dtp:f32[1,1,1,64] = mul dtm clw
          dtq:f32[64] = reshape[dimensions=None new_sizes=(64,)] dto
          dtr:f32[1,1,1,64] = mul dtp cmb
          dts:f32[64] = reshape[dimensions=None new_sizes=(64,)] dtr
          dtt:f32[64] = mul dts cly
          dtu:f32[64] = neg dtt
          dtv:f32[64] = mul dtu cma
          dtw:f32[64] = div dtt 204800.0
          dtx:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] dtw
          dty:f32[200,32,32,64] = mul dtx clz
          dtz:f32[200,32,32,64] = neg dtn
          dua:f32[64] = reduce_sum[axes=(0, 1, 2)] dtz
          dub:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] dua
          duc:f32[200,32,32,64] = add_any dty dtn
          dud:f32[64] = reshape[dimensions=None new_sizes=(64,)] dub
          due:f32[64] = add_any dtv dud
          duf:f32[64] = div due 204800.0
          dug:f32[200,32,32,64] = broadcast_in_dim[
            broadcast_dimensions=(3,)
            shape=(200, 32, 32, 64)
          ] duf
          duh:f32[200,32,32,64] = add_any duc dug
          dui:f32[3,3,3,64] = conv_general_dilated[
            batch_group_count=1
            dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
            feature_group_count=1
            lhs_dilation=(1, 1)
            lhs_shape=(200, 32, 32, 3)
            padding=((1, 1), (1, 1))
            precision=None
            preferred_element_type=None
            rhs_dilation=(1, 1)
            rhs_shape=(200, 32, 32, 64)
            window_strides=(1, 1)
          ] clv duh
        in (cuw, cuy, dsb, dsi, dqu, drb, dta, drt, dpm, dpt, dof, dom, dql, dpe,
          dlt, dma, dkm, dkt, dms, dll, dnw, dmx, dne, dje, djl, dhx, die, dkd, diw,
          dfl, dfs, dee, del, dgk, dfd, dho, dgp, dgw, dcw, ddd, dbp, dbw, ddv, dco,
          czd, czk, cxw, cyd, dac, cyv, dbg, dah, dao, cwo, cwv, cvh, cvo, cxn, cwg,
          dtj, dtq, dui) }
      name=batched_loss_fn
    ] if ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd
      je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc
      kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks h kt ku kv kw kx ky kz i la
      lb lc ld le lf lg n lh li lj lk ll lm ln o lo lp lq lr ls lt lu v lv lw lx
      ly lz ma mb mc md me mf mg mh t mi mj mk ml mm mn u mo mp mq mr ms mt mu bc
      mv mw mx my mz na nb bd nc nd ne nf ng nh ni bk nj nk nl nm nn no np nq nr
      ns nt nu nv bi nw nx ny nz oa ob bj oc od oe of og oh oi br oj ok ol om on
      oo op bs oq or os ot ou ov ow bz ox oy oz pa pb pc pd pe pf pg ph pi pj bx
      pk pl pm pn po pp by pq pr ps pt pu pv pw cg px py pz qa qb qc qd ch qe qf
      qg qh qi qj qk c ql qm qn qo qp qq qr qs qt qu qv qw qx qy qz ra rb rc rd re
      rf rg rh ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz 1.0
    duj:f32[100] duk:f32[512,100] dul:f32[64] dum:f32[64] dun:f32[64] duo:f32[64]
      dup:f32[3,3,64,64] duq:f32[3,3,64,64] dur:f32[64] dus:f32[64] dut:f32[64] duu:f32[64]
      duv:f32[3,3,64,64] duw:f32[3,3,64,64] dux:f32[128] duy:f32[128] duz:f32[128]
      dva:f32[128] dvb:f32[3,3,64,128] dvc:f32[3,3,128,128] dvd:f32[1,1,64,128] dve:f32[128]
      dvf:f32[128] dvg:f32[128] dvh:f32[128] dvi:f32[128] dvj:f32[128] dvk:f32[3,3,128,128]
      dvl:f32[3,3,128,128] dvm:f32[256] dvn:f32[256] dvo:f32[256] dvp:f32[256] dvq:f32[3,3,128,256]
      dvr:f32[3,3,256,256] dvs:f32[1,1,128,256] dvt:f32[256] dvu:f32[256] dvv:f32[256]
      dvw:f32[256] dvx:f32[256] dvy:f32[256] dvz:f32[3,3,256,256] dwa:f32[3,3,256,256]
      dwb:f32[512] dwc:f32[512] dwd:f32[512] dwe:f32[512] dwf:f32[3,3,256,512] dwg:f32[3,3,512,512]
      dwh:f32[1,1,256,512] dwi:f32[512] dwj:f32[512] dwk:f32[512] dwl:f32[512] dwm:f32[512]
      dwn:f32[512] dwo:f32[3,3,512,512] dwp:f32[3,3,512,512] dwq:f32[64] dwr:f32[64]
      dws:f32[3,3,3,64] = psum[axes=('device',) axis_index_groups=None] che chf chg
      chh chi chj chk chl chm chn cho chp chq chr chs cht chu chv chw chx chy chz
      cia cib cic cid cie cif cig cih cii cij cik cil cim cin cio cip ciq cir cis
      cit ciu civ ciw cix ciy ciz cja cjb cjc cjd cje cjf cjg cjh cji cjj cjk cjl
      cjm cjn
    dwt:f32[100] = div duj 1.0
    dwu:f32[512,100] = div duk 1.0
    dwv:f32[64] = div dul 1.0
    dww:f32[64] = div dum 1.0
    dwx:f32[64] = div dun 1.0
    dwy:f32[64] = div duo 1.0
    dwz:f32[3,3,64,64] = div dup 1.0
    dxa:f32[3,3,64,64] = div duq 1.0
    dxb:f32[64] = div dur 1.0
    dxc:f32[64] = div dus 1.0
    dxd:f32[64] = div dut 1.0
    dxe:f32[64] = div duu 1.0
    dxf:f32[3,3,64,64] = div duv 1.0
    dxg:f32[3,3,64,64] = div duw 1.0
    dxh:f32[128] = div dux 1.0
    dxi:f32[128] = div duy 1.0
    dxj:f32[128] = div duz 1.0
    dxk:f32[128] = div dva 1.0
    dxl:f32[3,3,64,128] = div dvb 1.0
    dxm:f32[3,3,128,128] = div dvc 1.0
    dxn:f32[1,1,64,128] = div dvd 1.0
    dxo:f32[128] = div dve 1.0
    dxp:f32[128] = div dvf 1.0
    dxq:f32[128] = div dvg 1.0
    dxr:f32[128] = div dvh 1.0
    dxs:f32[128] = div dvi 1.0
    dxt:f32[128] = div dvj 1.0
    dxu:f32[3,3,128,128] = div dvk 1.0
    dxv:f32[3,3,128,128] = div dvl 1.0
    dxw:f32[256] = div dvm 1.0
    dxx:f32[256] = div dvn 1.0
    dxy:f32[256] = div dvo 1.0
    dxz:f32[256] = div dvp 1.0
    dya:f32[3,3,128,256] = div dvq 1.0
    dyb:f32[3,3,256,256] = div dvr 1.0
    dyc:f32[1,1,128,256] = div dvs 1.0
    dyd:f32[256] = div dvt 1.0
    dye:f32[256] = div dvu 1.0
    dyf:f32[256] = div dvv 1.0
    dyg:f32[256] = div dvw 1.0
    dyh:f32[256] = div dvx 1.0
    dyi:f32[256] = div dvy 1.0
    dyj:f32[3,3,256,256] = div dvz 1.0
    dyk:f32[3,3,256,256] = div dwa 1.0
    dyl:f32[512] = div dwb 1.0
    dym:f32[512] = div dwc 1.0
    dyn:f32[512] = div dwd 1.0
    dyo:f32[512] = div dwe 1.0
    dyp:f32[3,3,256,512] = div dwf 1.0
    dyq:f32[3,3,512,512] = div dwg 1.0
    dyr:f32[1,1,256,512] = div dwh 1.0
    dys:f32[512] = div dwi 1.0
    dyt:f32[512] = div dwj 1.0
    dyu:f32[512] = div dwk 1.0
    dyv:f32[512] = div dwl 1.0
    dyw:f32[512] = div dwm 1.0
    dyx:f32[512] = div dwn 1.0
    dyy:f32[3,3,512,512] = div dwo 1.0
    dyz:f32[3,3,512,512] = div dwp 1.0
    dza:f32[64] = div dwq 1.0
    dzb:f32[64] = div dwr 1.0
    dzc:f32[3,3,3,64] = div dws 1.0
    dzd:i32[] dze:i32[] dzf:f32[] = psum[
      axes=('device',)
      axis_index_groups=None
    ] go gp gq
    dzg:f32[] = convert_element_type[new_dtype=float32 weak_type=False] dzd
    dzh:f32[] = div dzg 1.0
    dzi:f32[] = convert_element_type[new_dtype=float32 weak_type=False] dze
    dzj:f32[] = div dzi 1.0
    dzk:f32[] = div dzf 1.0
    dzl:bool[] = lt cl 2147483647
    dzm:i32[] = add cl 1
    dzn:i32[] = xla_call[
      call_jaxpr={ lambda ; dzo:bool[] dzp:i32[] dzq:i32[]. let
          dzr:i32[] = convert_element_type[new_dtype=int32 weak_type=False] dzq
          dzs:i32[] = select_n dzo dzr dzp
        in (dzs,) }
      name=_where
    ] dzl dzm 2147483647
    dzt:i32[] = sub 37500 dzn
    dzu:i32[] = xla_call[
      call_jaxpr={ lambda ; dzv:i32[]. let dzw:i32[] = sign dzv in (dzw,) }
      name=sign
    ] dzt
    dzx:f32[] = convert_element_type[new_dtype=float32 weak_type=True] dzu
    dzy:f32[] = max 0.0 dzx
    dzz:f32[] = mul 0.01 dzy
    eaa:f32[] = sub 1.0 dzy
    eab:f32[] = mul eaa 0.1
    eac:f32[] = mul eab 0.01
    ead:f32[] = add dzz eac
    eae:i32[] = sub 56250 dzn
    eaf:i32[] = xla_call[
      call_jaxpr={ lambda ; eag:i32[]. let eah:i32[] = sign eag in (eah,) }
      name=sign
    ] eae
    eai:f32[] = convert_element_type[new_dtype=float32 weak_type=True] eaf
    eaj:f32[] = max 0.0 eai
    eak:f32[] = mul ead eaj
    eal:f32[] = sub 1.0 eaj
    eam:f32[] = mul eal 0.1
    ean:f32[] = mul eam ead
    eao:f32[] = add eak ean
    eap:f32[] = convert_element_type[new_dtype=float32 weak_type=False] eao
    eaq:f32[] = mul -1.0 eap
    ear:f32[100] = mul cn co
    eas:f32[100] = add dwt ear
    eat:f32[512,100] = mul cn cp
    eau:f32[512,100] = add dwu eat
    eav:f32[64] = mul cn cq
    eaw:f32[64] = add dwv eav
    eax:f32[64] = mul cn cr
    eay:f32[64] = add dww eax
    eaz:f32[64] = mul cn cs
    eba:f32[64] = add dwx eaz
    ebb:f32[64] = mul cn ct
    ebc:f32[64] = add dwy ebb
    ebd:f32[3,3,64,64] = mul cn cu
    ebe:f32[3,3,64,64] = add dwz ebd
    ebf:f32[3,3,64,64] = mul cn cv
    ebg:f32[3,3,64,64] = add dxa ebf
    ebh:f32[64] = mul cn cw
    ebi:f32[64] = add dxb ebh
    ebj:f32[64] = mul cn cx
    ebk:f32[64] = add dxc ebj
    ebl:f32[64] = mul cn cy
    ebm:f32[64] = add dxd ebl
    ebn:f32[64] = mul cn cz
    ebo:f32[64] = add dxe ebn
    ebp:f32[3,3,64,64] = mul cn da
    ebq:f32[3,3,64,64] = add dxf ebp
    ebr:f32[3,3,64,64] = mul cn db
    ebs:f32[3,3,64,64] = add dxg ebr
    ebt:f32[128] = mul cn dc
    ebu:f32[128] = add dxh ebt
    ebv:f32[128] = mul cn dd
    ebw:f32[128] = add dxi ebv
    ebx:f32[128] = mul cn de
    eby:f32[128] = add dxj ebx
    ebz:f32[128] = mul cn df
    eca:f32[128] = add dxk ebz
    ecb:f32[3,3,64,128] = mul cn dg
    ecc:f32[3,3,64,128] = add dxl ecb
    ecd:f32[3,3,128,128] = mul cn dh
    ece:f32[3,3,128,128] = add dxm ecd
    ecf:f32[1,1,64,128] = mul cn di
    ecg:f32[1,1,64,128] = add dxn ecf
    ech:f32[128] = mul cn dj
    eci:f32[128] = add dxo ech
    ecj:f32[128] = mul cn dk
    eck:f32[128] = add dxp ecj
    ecl:f32[128] = mul cn dl
    ecm:f32[128] = add dxq ecl
    ecn:f32[128] = mul cn dm
    eco:f32[128] = add dxr ecn
    ecp:f32[128] = mul cn dn
    ecq:f32[128] = add dxs ecp
    ecr:f32[128] = mul cn do
    ecs:f32[128] = add dxt ecr
    ect:f32[3,3,128,128] = mul cn dp
    ecu:f32[3,3,128,128] = add dxu ect
    ecv:f32[3,3,128,128] = mul cn dq
    ecw:f32[3,3,128,128] = add dxv ecv
    ecx:f32[256] = mul cn dr
    ecy:f32[256] = add dxw ecx
    ecz:f32[256] = mul cn ds
    eda:f32[256] = add dxx ecz
    edb:f32[256] = mul cn dt
    edc:f32[256] = add dxy edb
    edd:f32[256] = mul cn du
    ede:f32[256] = add dxz edd
    edf:f32[3,3,128,256] = mul cn dv
    edg:f32[3,3,128,256] = add dya edf
    edh:f32[3,3,256,256] = mul cn dw
    edi:f32[3,3,256,256] = add dyb edh
    edj:f32[1,1,128,256] = mul cn dx
    edk:f32[1,1,128,256] = add dyc edj
    edl:f32[256] = mul cn dy
    edm:f32[256] = add dyd edl
    edn:f32[256] = mul cn dz
    edo:f32[256] = add dye edn
    edp:f32[256] = mul cn ea
    edq:f32[256] = add dyf edp
    edr:f32[256] = mul cn eb
    eds:f32[256] = add dyg edr
    edt:f32[256] = mul cn ec
    edu:f32[256] = add dyh edt
    edv:f32[256] = mul cn ed
    edw:f32[256] = add dyi edv
    edx:f32[3,3,256,256] = mul cn ee
    edy:f32[3,3,256,256] = add dyj edx
    edz:f32[3,3,256,256] = mul cn ef
    eea:f32[3,3,256,256] = add dyk edz
    eeb:f32[512] = mul cn eg
    eec:f32[512] = add dyl eeb
    eed:f32[512] = mul cn eh
    eee:f32[512] = add dym eed
    eef:f32[512] = mul cn ei
    eeg:f32[512] = add dyn eef
    eeh:f32[512] = mul cn ej
    eei:f32[512] = add dyo eeh
    eej:f32[3,3,256,512] = mul cn ek
    eek:f32[3,3,256,512] = add dyp eej
    eel:f32[3,3,512,512] = mul cn el
    eem:f32[3,3,512,512] = add dyq eel
    een:f32[1,1,256,512] = mul cn em
    eeo:f32[1,1,256,512] = add dyr een
    eep:f32[512] = mul cn en
    eeq:f32[512] = add dys eep
    eer:f32[512] = mul cn eo
    ees:f32[512] = add dyt eer
    eet:f32[512] = mul cn ep
    eeu:f32[512] = add dyu eet
    eev:f32[512] = mul cn eq
    eew:f32[512] = add dyv eev
    eex:f32[512] = mul cn er
    eey:f32[512] = add dyw eex
    eez:f32[512] = mul cn es
    efa:f32[512] = add dyx eez
    efb:f32[3,3,512,512] = mul cn et
    efc:f32[3,3,512,512] = add dyy efb
    efd:f32[3,3,512,512] = mul cn eu
    efe:f32[3,3,512,512] = add dyz efd
    eff:f32[64] = mul cn ev
    efg:f32[64] = add dza eff
    efh:f32[64] = mul cn ew
    efi:f32[64] = add dzb efh
    efj:f32[3,3,3,64] = mul cn ex
    efk:f32[3,3,3,64] = add dzc efj
    efl:f32[100] = mul eaq eas
    efm:f32[512,100] = mul eaq eau
    efn:f32[64] = mul eaq eaw
    efo:f32[64] = mul eaq eay
    efp:f32[64] = mul eaq eba
    efq:f32[64] = mul eaq ebc
    efr:f32[3,3,64,64] = mul eaq ebe
    efs:f32[3,3,64,64] = mul eaq ebg
    eft:f32[64] = mul eaq ebi
    efu:f32[64] = mul eaq ebk
    efv:f32[64] = mul eaq ebm
    efw:f32[64] = mul eaq ebo
    efx:f32[3,3,64,64] = mul eaq ebq
    efy:f32[3,3,64,64] = mul eaq ebs
    efz:f32[128] = mul eaq ebu
    ega:f32[128] = mul eaq ebw
    egb:f32[128] = mul eaq eby
    egc:f32[128] = mul eaq eca
    egd:f32[3,3,64,128] = mul eaq ecc
    ege:f32[3,3,128,128] = mul eaq ece
    egf:f32[1,1,64,128] = mul eaq ecg
    egg:f32[128] = mul eaq eci
    egh:f32[128] = mul eaq eck
    egi:f32[128] = mul eaq ecm
    egj:f32[128] = mul eaq eco
    egk:f32[128] = mul eaq ecq
    egl:f32[128] = mul eaq ecs
    egm:f32[3,3,128,128] = mul eaq ecu
    egn:f32[3,3,128,128] = mul eaq ecw
    ego:f32[256] = mul eaq ecy
    egp:f32[256] = mul eaq eda
    egq:f32[256] = mul eaq edc
    egr:f32[256] = mul eaq ede
    egs:f32[3,3,128,256] = mul eaq edg
    egt:f32[3,3,256,256] = mul eaq edi
    egu:f32[1,1,128,256] = mul eaq edk
    egv:f32[256] = mul eaq edm
    egw:f32[256] = mul eaq edo
    egx:f32[256] = mul eaq edq
    egy:f32[256] = mul eaq eds
    egz:f32[256] = mul eaq edu
    eha:f32[256] = mul eaq edw
    ehb:f32[3,3,256,256] = mul eaq edy
    ehc:f32[3,3,256,256] = mul eaq eea
    ehd:f32[512] = mul eaq eec
    ehe:f32[512] = mul eaq eee
    ehf:f32[512] = mul eaq eeg
    ehg:f32[512] = mul eaq eei
    ehh:f32[3,3,256,512] = mul eaq eek
    ehi:f32[3,3,512,512] = mul eaq eem
    ehj:f32[1,1,256,512] = mul eaq eeo
    ehk:f32[512] = mul eaq eeq
    ehl:f32[512] = mul eaq ees
    ehm:f32[512] = mul eaq eeu
    ehn:f32[512] = mul eaq eew
    eho:f32[512] = mul eaq eey
    ehp:f32[512] = mul eaq efa
    ehq:f32[3,3,512,512] = mul eaq efc
    ehr:f32[3,3,512,512] = mul eaq efe
    ehs:f32[64] = mul eaq efg
    eht:f32[64] = mul eaq efi
    ehu:f32[3,3,3,64] = mul eaq efk
    ehv:f32[100] = mul 9.999999747378752e-05 b
    ehw:f32[100] = add efl ehv
    ehx:f32[512,100] = mul 9.999999747378752e-05 c
    ehy:f32[512,100] = add efm ehx
    ehz:f32[64] = mul 9.999999747378752e-05 d
    eia:f32[64] = add efn ehz
    eib:f32[64] = mul 9.999999747378752e-05 e
    eic:f32[64] = add efo eib
    eid:f32[64] = mul 9.999999747378752e-05 f
    eie:f32[64] = add efp eid
    eif:f32[64] = mul 9.999999747378752e-05 g
    eig:f32[64] = add efq eif
    eih:f32[3,3,64,64] = mul 9.999999747378752e-05 h
    eii:f32[3,3,64,64] = add efr eih
    eij:f32[3,3,64,64] = mul 9.999999747378752e-05 i
    eik:f32[3,3,64,64] = add efs eij
    eil:f32[64] = mul 9.999999747378752e-05 j
    eim:f32[64] = add eft eil
    ein:f32[64] = mul 9.999999747378752e-05 k
    eio:f32[64] = add efu ein
    eip:f32[64] = mul 9.999999747378752e-05 l
    eiq:f32[64] = add efv eip
    eir:f32[64] = mul 9.999999747378752e-05 m
    eis:f32[64] = add efw eir
    eit:f32[3,3,64,64] = mul 9.999999747378752e-05 n
    eiu:f32[3,3,64,64] = add efx eit
    eiv:f32[3,3,64,64] = mul 9.999999747378752e-05 o
    eiw:f32[3,3,64,64] = add efy eiv
    eix:f32[128] = mul 9.999999747378752e-05 p
    eiy:f32[128] = add efz eix
    eiz:f32[128] = mul 9.999999747378752e-05 q
    eja:f32[128] = add ega eiz
    ejb:f32[128] = mul 9.999999747378752e-05 r
    ejc:f32[128] = add egb ejb
    ejd:f32[128] = mul 9.999999747378752e-05 s
    eje:f32[128] = add egc ejd
    ejf:f32[3,3,64,128] = mul 9.999999747378752e-05 t
    ejg:f32[3,3,64,128] = add egd ejf
    ejh:f32[3,3,128,128] = mul 9.999999747378752e-05 u
    eji:f32[3,3,128,128] = add ege ejh
    ejj:f32[1,1,64,128] = mul 9.999999747378752e-05 v
    ejk:f32[1,1,64,128] = add egf ejj
    ejl:f32[128] = mul 9.999999747378752e-05 w
    ejm:f32[128] = add egg ejl
    ejn:f32[128] = mul 9.999999747378752e-05 x
    ejo:f32[128] = add egh ejn
    ejp:f32[128] = mul 9.999999747378752e-05 y
    ejq:f32[128] = add egi ejp
    ejr:f32[128] = mul 9.999999747378752e-05 z
    ejs:f32[128] = add egj ejr
    ejt:f32[128] = mul 9.999999747378752e-05 ba
    eju:f32[128] = add egk ejt
    ejv:f32[128] = mul 9.999999747378752e-05 bb
    ejw:f32[128] = add egl ejv
    ejx:f32[3,3,128,128] = mul 9.999999747378752e-05 bc
    ejy:f32[3,3,128,128] = add egm ejx
    ejz:f32[3,3,128,128] = mul 9.999999747378752e-05 bd
    eka:f32[3,3,128,128] = add egn ejz
    ekb:f32[256] = mul 9.999999747378752e-05 be
    ekc:f32[256] = add ego ekb
    ekd:f32[256] = mul 9.999999747378752e-05 bf
    eke:f32[256] = add egp ekd
    ekf:f32[256] = mul 9.999999747378752e-05 bg
    ekg:f32[256] = add egq ekf
    ekh:f32[256] = mul 9.999999747378752e-05 bh
    eki:f32[256] = add egr ekh
    ekj:f32[3,3,128,256] = mul 9.999999747378752e-05 bi
    ekk:f32[3,3,128,256] = add egs ekj
    ekl:f32[3,3,256,256] = mul 9.999999747378752e-05 bj
    ekm:f32[3,3,256,256] = add egt ekl
    ekn:f32[1,1,128,256] = mul 9.999999747378752e-05 bk
    eko:f32[1,1,128,256] = add egu ekn
    ekp:f32[256] = mul 9.999999747378752e-05 bl
    ekq:f32[256] = add egv ekp
    ekr:f32[256] = mul 9.999999747378752e-05 bm
    eks:f32[256] = add egw ekr
    ekt:f32[256] = mul 9.999999747378752e-05 bn
    eku:f32[256] = add egx ekt
    ekv:f32[256] = mul 9.999999747378752e-05 bo
    ekw:f32[256] = add egy ekv
    ekx:f32[256] = mul 9.999999747378752e-05 bp
    eky:f32[256] = add egz ekx
    ekz:f32[256] = mul 9.999999747378752e-05 bq
    ela:f32[256] = add eha ekz
    elb:f32[3,3,256,256] = mul 9.999999747378752e-05 br
    elc:f32[3,3,256,256] = add ehb elb
    eld:f32[3,3,256,256] = mul 9.999999747378752e-05 bs
    ele:f32[3,3,256,256] = add ehc eld
    elf:f32[512] = mul 9.999999747378752e-05 bt
    elg:f32[512] = add ehd elf
    elh:f32[512] = mul 9.999999747378752e-05 bu
    eli:f32[512] = add ehe elh
    elj:f32[512] = mul 9.999999747378752e-05 bv
    elk:f32[512] = add ehf elj
    ell:f32[512] = mul 9.999999747378752e-05 bw
    elm:f32[512] = add ehg ell
    eln:f32[3,3,256,512] = mul 9.999999747378752e-05 bx
    elo:f32[3,3,256,512] = add ehh eln
    elp:f32[3,3,512,512] = mul 9.999999747378752e-05 by
    elq:f32[3,3,512,512] = add ehi elp
    elr:f32[1,1,256,512] = mul 9.999999747378752e-05 bz
    els:f32[1,1,256,512] = add ehj elr
    elt:f32[512] = mul 9.999999747378752e-05 ca
    elu:f32[512] = add ehk elt
    elv:f32[512] = mul 9.999999747378752e-05 cb
    elw:f32[512] = add ehl elv
    elx:f32[512] = mul 9.999999747378752e-05 cc
    ely:f32[512] = add ehm elx
    elz:f32[512] = mul 9.999999747378752e-05 cd
    ema:f32[512] = add ehn elz
    emb:f32[512] = mul 9.999999747378752e-05 ce
    emc:f32[512] = add eho emb
    emd:f32[512] = mul 9.999999747378752e-05 cf
    eme:f32[512] = add ehp emd
    emf:f32[3,3,512,512] = mul 9.999999747378752e-05 cg
    emg:f32[3,3,512,512] = add ehq emf
    emh:f32[3,3,512,512] = mul 9.999999747378752e-05 ch
    emi:f32[3,3,512,512] = add ehr emh
    emj:f32[64] = mul 9.999999747378752e-05 ci
    emk:f32[64] = add ehs emj
    eml:f32[64] = mul 9.999999747378752e-05 cj
    emm:f32[64] = add eht eml
    emn:f32[3,3,3,64] = mul 9.999999747378752e-05 ck
    emo:f32[3,3,3,64] = add ehu emn
    emp:f32[100] = add b ehw
    emq:f32[512,100] = add c ehy
    emr:f32[64] = add d eia
    ems:f32[64] = add e eic
    emt:f32[64] = add f eie
    emu:f32[64] = add g eig
    emv:f32[3,3,64,64] = add h eii
    emw:f32[3,3,64,64] = add i eik
    emx:f32[64] = add j eim
    emy:f32[64] = add k eio
    emz:f32[64] = add l eiq
    ena:f32[64] = add m eis
    enb:f32[3,3,64,64] = add n eiu
    enc:f32[3,3,64,64] = add o eiw
    end:f32[128] = add p eiy
    ene:f32[128] = add q eja
    enf:f32[128] = add r ejc
    eng:f32[128] = add s eje
    enh:f32[3,3,64,128] = add t ejg
    eni:f32[3,3,128,128] = add u eji
    enj:f32[1,1,64,128] = add v ejk
    enk:f32[128] = add w ejm
    enl:f32[128] = add x ejo
    enm:f32[128] = add y ejq
    enn:f32[128] = add z ejs
    eno:f32[128] = add ba eju
    enp:f32[128] = add bb ejw
    enq:f32[3,3,128,128] = add bc ejy
    enr:f32[3,3,128,128] = add bd eka
    ens:f32[256] = add be ekc
    ent:f32[256] = add bf eke
    enu:f32[256] = add bg ekg
    env:f32[256] = add bh eki
    enw:f32[3,3,128,256] = add bi ekk
    enx:f32[3,3,256,256] = add bj ekm
    eny:f32[1,1,128,256] = add bk eko
    enz:f32[256] = add bl ekq
    eoa:f32[256] = add bm eks
    eob:f32[256] = add bn eku
    eoc:f32[256] = add bo ekw
    eod:f32[256] = add bp eky
    eoe:f32[256] = add bq ela
    eof:f32[3,3,256,256] = add br elc
    eog:f32[3,3,256,256] = add bs ele
    eoh:f32[512] = add bt elg
    eoi:f32[512] = add bu eli
    eoj:f32[512] = add bv elk
    eok:f32[512] = add bw elm
    eol:f32[3,3,256,512] = add bx elo
    eom:f32[3,3,512,512] = add by elq
    eon:f32[1,1,256,512] = add bz els
    eoo:f32[512] = add ca elu
    eop:f32[512] = add cb elw
    eoq:f32[512] = add cc ely
    eor:f32[512] = add cd ema
    eos:f32[512] = add ce emc
    eot:f32[512] = add cf eme
    eou:f32[3,3,512,512] = add cg emg
    eov:f32[3,3,512,512] = add ch emi
    eow:f32[64] = add ci emk
    eox:f32[64] = add cj emm
    eoy:f32[3,3,3,64] = add ck emo
    eoz:i32[] = add a 1
  in (eoz, emp, emq, emr, ems, emt, emu, emv, emw, emx, emy, emz, ena, enb, enc,
    end, ene, enf, eng, enh, eni, enj, enk, enl, enm, enn, eno, enp, enq, enr, ens,
    ent, enu, env, enw, enx, eny, enz, eoa, eob, eoc, eod, eoe, eof, eog, eoh, eoi,
    eoj, eok, eol, eom, eon, eoo, eop, eoq, eor, eos, eot, eou, eov, eow, eox, eoy,
    dzn, eap, cn, eas, eau, eaw, eay, eba, ebc, ebe, ebg, ebi, ebk, ebm, ebo, ebq,
    ebs, ebu, ebw, eby, eca, ecc, ece, ecg, eci, eck, ecm, eco, ecq, ecs, ecu, ecw,
    ecy, eda, edc, ede, edg, edi, edk, edm, edo, edq, eds, edu, edw, edy, eea, eec,
    eee, eeg, eei, eek, eem, eeo, eeq, ees, eeu, eew, eey, efa, efc, efe, efg, efi,
    efk, gr, gs, gt, gu, gv, gw, gx, gy, gz, ha, hb, hc, hd, he, hf, hg, hh, hi,
    hj, hk, hl, hm, hn, ho, hp, hq, hr, hs, ht, hu, hv, hw, hx, hy, hz, ia, ib, ic,
    id, ie, dzh, dzj, dzk) }, ())

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1087, in _lower_jaxpr_to_fun_cached
    func_op = ctx.cached_call_jaxpr_lowerings[key]
KeyError: ('batched_loss_fn', { lambda ; a:f32[200,100] b:f32[200,1] c:f32[200,100] d:bool[200,4,4,512] e:f32[200,4,4,512]
    f:f32[1,1,1,512] g:f32[200,4,4,512] h:bool[200,4,4,512] i:f32[200,4,4,512] j:f32[1,1,1,512]
    k:f32[200,4,4,512] l:bool[200,4,4,512] m:f32[200,4,4,512] n:f32[1,1,1,512] o:f32[200,4,4,512]
    p:bool[200,8,8,256] q:f32[200,8,8,256] r:f32[1,1,1,256] s:f32[200,8,8,256] t:bool[200,8,8,256]
    u:f32[200,8,8,256] v:f32[1,1,1,256] w:f32[200,8,8,256] x:bool[200,8,8,256] y:f32[200,8,8,256]
    z:f32[1,1,1,256] ba:f32[200,8,8,256] bb:bool[200,16,16,128] bc:f32[200,16,16,128]
    bd:f32[1,1,1,128] be:f32[200,16,16,128] bf:bool[200,16,16,128] bg:f32[200,16,16,128]
    bh:f32[1,1,1,128] bi:f32[200,16,16,128] bj:bool[200,16,16,128] bk:f32[200,16,16,128]
    bl:f32[1,1,1,128] bm:f32[200,16,16,128] bn:bool[200,32,32,64] bo:f32[200,32,32,64]
    bp:f32[1,1,1,64] bq:f32[200,32,32,64] br:bool[200,32,32,64] bs:f32[200,32,32,64]
    bt:f32[1,1,1,64] bu:f32[200,32,32,64] bv:bool[200,32,32,64] bw:f32[200,32,32,64]
    bx:f32[1,1,1,64] by:f32[200,32,32,64] bz:bool[200,32,32,64] ca:f32[200,32,32,64]
    cb:f32[1,1,1,64] cc:f32[200,32,32,64] cd:bool[200,32,32,64] ce:f32[200,32,32,64]
    cf:f32[1,1,1,64] cg:f32[200,32,32,64] ch:f32[200,32,32,3] ci:f32[1,1,1,64] cj:f32[1,1,1,64]
    ck:f32[64] cl:f32[200,32,32,64] cm:f32[64] cn:f32[1,1,1,64] co:f32[3,3,64,64]
    cp:f32[200,32,32,64] cq:f32[1,1,1,64] cr:f32[1,1,1,64] cs:f32[64] ct:f32[200,32,32,64]
    cu:f32[64] cv:f32[1,1,1,64] cw:f32[3,3,64,64] cx:f32[200,32,32,64] cy:f32[1,1,1,64]
    cz:f32[1,1,1,64] da:f32[64] db:f32[200,32,32,64] dc:f32[64] dd:f32[1,1,1,64]
    de:f32[3,3,64,64] df:f32[200,32,32,64] dg:f32[1,1,1,64] dh:f32[1,1,1,64] di:f32[64]
    dj:f32[200,32,32,64] dk:f32[64] dl:f32[1,1,1,64] dm:f32[3,3,64,64] dn:f32[200,32,32,64]
    do:f32[1,1,1,64] dp:f32[1,1,1,64] dq:f32[64] dr:f32[200,32,32,64] ds:f32[64]
    dt:f32[1,1,1,64] du:f32[1,1,64,128] dv:f32[200,32,32,64] dw:f32[1,1,1,128] dx:f32[1,1,1,128]
    dy:f32[128] dz:f32[200,16,16,128] ea:f32[128] eb:f32[1,1,1,128] ec:f32[1,1,1,128]
    ed:f32[200,16,16,128] ee:bool[200,16,16,128] ef:f32[200,16,16,128] eg:f32[1,1,1,128]
    eh:f32[200,16,16,128] ei:f32[3,3,64,128] ej:f32[1,1,1,128] ek:f32[1,1,1,128]
    el:f32[128] em:f32[200,16,16,128] en:f32[128] eo:f32[1,1,1,128] ep:f32[3,3,128,128]
    eq:f32[200,16,16,128] er:f32[1,1,1,128] es:f32[1,1,1,128] et:f32[128] eu:f32[200,16,16,128]
    ev:f32[128] ew:f32[1,1,1,128] ex:f32[3,3,128,128] ey:f32[200,16,16,128] ez:f32[1,1,1,128]
    fa:f32[1,1,1,128] fb:f32[128] fc:f32[200,16,16,128] fd:f32[128] fe:f32[1,1,1,128]
    ff:f32[3,3,128,128] fg:f32[200,16,16,128] fh:f32[1,1,1,128] fi:f32[1,1,1,128]
    fj:f32[128] fk:f32[200,16,16,128] fl:f32[128] fm:f32[1,1,1,128] fn:f32[1,1,128,256]
    fo:f32[200,16,16,128] fp:f32[1,1,1,256] fq:f32[1,1,1,256] fr:f32[256] fs:f32[200,8,8,256]
    ft:f32[256] fu:f32[1,1,1,256] fv:f32[1,1,1,256] fw:f32[200,8,8,256] fx:bool[200,8,8,256]
    fy:f32[200,8,8,256] fz:f32[1,1,1,256] ga:f32[200,8,8,256] gb:f32[3,3,128,256]
    gc:f32[1,1,1,256] gd:f32[1,1,1,256] ge:f32[256] gf:f32[200,8,8,256] gg:f32[256]
    gh:f32[1,1,1,256] gi:f32[3,3,256,256] gj:f32[200,8,8,256] gk:f32[1,1,1,256] gl:f32[1,1,1,256]
    gm:f32[256] gn:f32[200,8,8,256] go:f32[256] gp:f32[1,1,1,256] gq:f32[3,3,256,256]
    gr:f32[200,8,8,256] gs:f32[1,1,1,256] gt:f32[1,1,1,256] gu:f32[256] gv:f32[200,8,8,256]
    gw:f32[256] gx:f32[1,1,1,256] gy:f32[3,3,256,256] gz:f32[200,8,8,256] ha:f32[1,1,1,256]
    hb:f32[1,1,1,256] hc:f32[256] hd:f32[200,8,8,256] he:f32[256] hf:f32[1,1,1,256]
    hg:f32[1,1,256,512] hh:f32[200,8,8,256] hi:f32[1,1,1,512] hj:f32[1,1,1,512] hk:f32[512]
    hl:f32[200,4,4,512] hm:f32[512] hn:f32[1,1,1,512] ho:f32[1,1,1,512] hp:f32[200,4,4,512]
    hq:bool[200,4,4,512] hr:f32[200,4,4,512] hs:f32[1,1,1,512] ht:f32[200,4,4,512]
    hu:f32[3,3,256,512] hv:f32[1,1,1,512] hw:f32[1,1,1,512] hx:f32[512] hy:f32[200,4,4,512]
    hz:f32[512] ia:f32[1,1,1,512] ib:f32[3,3,512,512] ic:f32[200,4,4,512] id:f32[1,1,1,512]
    ie:f32[1,1,1,512] if:f32[512] ig:f32[200,4,4,512] ih:f32[512] ii:f32[1,1,1,512]
    ij:f32[3,3,512,512] ik:f32[200,4,4,512] il:f32[1,1,1,512] im:f32[1,1,1,512] in:f32[512]
    io:f32[200,4,4,512] ip:f32[512] iq:f32[1,1,1,512] ir:f32[3,3,512,512] is:f32[200,4,4,512]
    it:f32[1,1,1,512] iu:f32[1,1,1,512] iv:f32[512] iw:f32[200,4,4,512] ix:f32[512]
    iy:f32[1,1,1,512] iz:f32[512,100] ja:f32[200,512] jb:f32[] jc:f32[] jd:f32[]
    je:f32[] jf:f32[] jg:f32[] jh:f32[] ji:f32[] jj:f32[] jk:f32[] jl:f32[] jm:f32[]
    jn:f32[] jo:f32[] jp:f32[] jq:f32[] jr:f32[] js:f32[] jt:f32[] ju:f32[] jv:f32[]
    jw:f32[] jx:f32[] jy:f32[] jz:f32[] ka:f32[] kb:f32[] kc:f32[] kd:f32[] ke:f32[]
    kf:f32[] kg:f32[] kh:f32[] ki:f32[] kj:f32[] kk:f32[] kl:f32[] km:f32[] kn:f32[]
    ko:f32[] kp:f32[]. let
    kq:f32[200] = broadcast_in_dim[broadcast_dimensions=() shape=(200,)] kp
    kr:f32[200] = neg kq
    ks:f32[200,100] = broadcast_in_dim[
      broadcast_dimensions=(0,)
      shape=(200, 100)
    ] kr
    kt:f32[200,100] = mul a ks
    ku:f32[200,100] = xla_call[
      call_jaxpr={ lambda ; kv:f32[200,1] kw:f32[200,100] kx:f32[200,100]. let
          ky:f32[200,100] = neg kx
          kz:f32[200] = reduce_sum[axes=(1,)] ky
          la:f32[200,1] = reshape[dimensions=None new_sizes=(200, 1)] kz
          lb:f32[200,1] = div la kv
          lc:f32[200] = reduce_sum[axes=(1,)] lb
          ld:f32[200,100] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(200, 100)
          ] lc
          le:f32[200,100] = mul ld kw
          lf:f32[200,100] = add_any kx le
        in (lf,) }
      name=log_softmax
    ] b c kt
    lg:f32[100] = reduce_sum[axes=(0,)] ku
    lh:f32[1,100] = reshape[dimensions=None new_sizes=(1, 100)] lg
    li:f32[100] = reshape[dimensions=None new_sizes=(100,)] lh
    lj:f32[100,512] = dot_general[
      dimension_numbers=(((0,), (0,)), ((), ()))
      precision=None
      preferred_element_type=None
    ] ku ja
    lk:f32[512,100] = transpose[permutation=(1, 0)] lj
    ll:f32[200,512] = dot_general[
      dimension_numbers=(((1,), (1,)), ((), ()))
      precision=None
      preferred_element_type=None
    ] ku iz
    lm:f32[200,512] = div ll 16.0
    ln:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(200, 4, 4, 512)
    ] lm
    lo:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 4, 4, 512)
    ] 0.0
    lp:bool[200,4,4,512] = eq d True
    lq:f32[200,4,4,512] = select_n lp lo ln
    lr:f32[512] = reduce_sum[axes=(0, 1, 2)] lq
    ls:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] lr
    lt:f32[512] = reshape[dimensions=None new_sizes=(512,)] ls
    lu:f32[200,4,4,512] = mul g lq
    lv:f32[512] = reduce_sum[axes=(0, 1, 2)] lu
    lw:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] lv
    lx:f32[200,4,4,512] = mul lq f
    ly:f32[1,1,1,512] = mul iu lw
    lz:f32[1,1,1,512] = mul lw it
    ma:f32[512] = reshape[dimensions=None new_sizes=(512,)] ly
    mb:f32[1,1,1,512] = mul lz iy
    mc:f32[512] = reshape[dimensions=None new_sizes=(512,)] mb
    md:f32[512] = mul mc iv
    me:f32[512] = neg md
    mf:f32[512] = mul me ix
    mg:f32[512] = div md 3200.0
    mh:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] mg
    mi:f32[200,4,4,512] = mul mh iw
    mj:f32[200,4,4,512] = neg lx
    mk:f32[512] = reduce_sum[axes=(0, 1, 2)] mj
    ml:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] mk
    mm:f32[200,4,4,512] = add_any mi lx
    mn:f32[512] = reshape[dimensions=None new_sizes=(512,)] ml
    mo:f32[512] = add_any mf mn
    mp:f32[512] = div mo 3200.0
    mq:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] mp
    mr:f32[200,4,4,512] = add_any mm mq
    ms:f32[3,3,512,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 4, 4, 512)
      window_strides=(1, 1)
    ] is mr
    mt:f32[3,3,512,512] = rev[dimensions=(0, 1)] ir
    mu:f32[200,4,4,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 512, 512)
      window_strides=(1, 1)
    ] mr mt
    mv:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 4, 4, 512)
    ] 0.0
    mw:bool[200,4,4,512] = eq h True
    mx:f32[200,4,4,512] = select_n mw mv mu
    my:f32[512] = reduce_sum[axes=(0, 1, 2)] mx
    mz:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] my
    na:f32[512] = reshape[dimensions=None new_sizes=(512,)] mz
    nb:f32[200,4,4,512] = mul k mx
    nc:f32[512] = reduce_sum[axes=(0, 1, 2)] nb
    nd:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] nc
    ne:f32[200,4,4,512] = mul mx j
    nf:f32[1,1,1,512] = mul im nd
    ng:f32[1,1,1,512] = mul nd il
    nh:f32[512] = reshape[dimensions=None new_sizes=(512,)] nf
    ni:f32[1,1,1,512] = mul ng iq
    nj:f32[512] = reshape[dimensions=None new_sizes=(512,)] ni
    nk:f32[512] = mul nj in
    nl:f32[512] = neg nk
    nm:f32[512] = mul nl ip
    nn:f32[512] = div nk 3200.0
    no:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] nn
    np:f32[200,4,4,512] = mul no io
    nq:f32[200,4,4,512] = neg ne
    nr:f32[512] = reduce_sum[axes=(0, 1, 2)] nq
    ns:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] nr
    nt:f32[200,4,4,512] = add_any np ne
    nu:f32[512] = reshape[dimensions=None new_sizes=(512,)] ns
    nv:f32[512] = add_any nm nu
    nw:f32[512] = div nv 3200.0
    nx:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] nw
    ny:f32[200,4,4,512] = add_any nt nx
    nz:f32[3,3,512,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 4, 4, 512)
      window_strides=(1, 1)
    ] ik ny
    oa:f32[3,3,512,512] = rev[dimensions=(0, 1)] ij
    ob:f32[200,4,4,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 512, 512)
      window_strides=(1, 1)
    ] ny oa
    oc:f32[200,4,4,512] = add_any lq ob
    od:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 4, 4, 512)
    ] 0.0
    oe:bool[200,4,4,512] = eq l True
    of:f32[200,4,4,512] = select_n oe od oc
    og:f32[512] = reduce_sum[axes=(0, 1, 2)] of
    oh:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] og
    oi:f32[512] = reshape[dimensions=None new_sizes=(512,)] oh
    oj:f32[200,4,4,512] = mul hp of
    ok:f32[512] = reduce_sum[axes=(0, 1, 2)] oj
    ol:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] ok
    om:f32[200,4,4,512] = mul of ho
    on:f32[1,1,1,512] = mul ie ol
    oo:f32[1,1,1,512] = mul ol id
    op:f32[512] = reshape[dimensions=None new_sizes=(512,)] on
    oq:f32[1,1,1,512] = mul oo ii
    or:f32[512] = reshape[dimensions=None new_sizes=(512,)] oq
    os:f32[512] = mul or if
    ot:f32[512] = neg os
    ou:f32[512] = mul ot ih
    ov:f32[512] = div os 3200.0
    ow:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] ov
    ox:f32[200,4,4,512] = mul ow ig
    oy:f32[200,4,4,512] = neg om
    oz:f32[512] = reduce_sum[axes=(0, 1, 2)] oy
    pa:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] oz
    pb:f32[200,4,4,512] = add_any ox om
    pc:f32[512] = reshape[dimensions=None new_sizes=(512,)] pa
    pd:f32[512] = add_any ou pc
    pe:f32[512] = div pd 3200.0
    pf:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] pe
    pg:f32[200,4,4,512] = add_any pb pf
    ph:f32[3,3,512,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 4, 4, 512)
      window_strides=(1, 1)
    ] ic pg
    pi:f32[3,3,512,512] = rev[dimensions=(0, 1)] ib
    pj:f32[200,4,4,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 512, 512)
      window_strides=(1, 1)
    ] pg pi
    pk:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 4, 4, 512)
    ] 0.0
    pl:bool[200,4,4,512] = eq hq True
    pm:f32[200,4,4,512] = select_n pl pk pj
    pn:f32[512] = reduce_sum[axes=(0, 1, 2)] pm
    po:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] pn
    pp:f32[512] = reshape[dimensions=None new_sizes=(512,)] po
    pq:f32[200,4,4,512] = mul ht pm
    pr:f32[512] = reduce_sum[axes=(0, 1, 2)] pq
    ps:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] pr
    pt:f32[200,4,4,512] = mul pm hs
    pu:f32[1,1,1,512] = mul hw ps
    pv:f32[1,1,1,512] = mul ps hv
    pw:f32[512] = reshape[dimensions=None new_sizes=(512,)] pu
    px:f32[1,1,1,512] = mul pv ia
    py:f32[512] = reshape[dimensions=None new_sizes=(512,)] px
    pz:f32[512] = mul py hx
    qa:f32[512] = neg pz
    qb:f32[512] = mul qa hz
    qc:f32[512] = div pz 3200.0
    qd:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] qc
    qe:f32[200,4,4,512] = mul qd hy
    qf:f32[200,4,4,512] = neg pt
    qg:f32[512] = reduce_sum[axes=(0, 1, 2)] qf
    qh:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] qg
    qi:f32[200,4,4,512] = add_any qe pt
    qj:f32[512] = reshape[dimensions=None new_sizes=(512,)] qh
    qk:f32[512] = add_any qb qj
    ql:f32[512] = div qk 3200.0
    qm:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] ql
    qn:f32[200,4,4,512] = add_any qi qm
    qo:f32[3,3,256,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 0), (1, 0))
      precision=None
      preferred_element_type=None
      rhs_dilation=(2, 2)
      rhs_shape=(200, 4, 4, 512)
      window_strides=(1, 1)
    ] hh qn
    qp:f32[3,3,256,512] = rev[dimensions=(0, 1)] hu
    qq:f32[200,8,8,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(2, 2)
      lhs_shape=(200, 4, 4, 512)
      padding=((1, 2), (1, 2))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 256, 512)
      window_strides=(1, 1)
    ] qn qp
    qr:f32[512] = reduce_sum[axes=(0, 1, 2)] of
    qs:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] qr
    qt:f32[512] = reshape[dimensions=None new_sizes=(512,)] qs
    qu:f32[200,4,4,512] = mul o of
    qv:f32[512] = reduce_sum[axes=(0, 1, 2)] qu
    qw:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] qv
    qx:f32[200,4,4,512] = mul of n
    qy:f32[1,1,1,512] = mul hj qw
    qz:f32[1,1,1,512] = mul qw hi
    ra:f32[512] = reshape[dimensions=None new_sizes=(512,)] qy
    rb:f32[1,1,1,512] = mul qz hn
    rc:f32[512] = reshape[dimensions=None new_sizes=(512,)] rb
    rd:f32[512] = mul rc hk
    re:f32[512] = neg rd
    rf:f32[512] = mul re hm
    rg:f32[512] = div rd 3200.0
    rh:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] rg
    ri:f32[200,4,4,512] = mul rh hl
    rj:f32[200,4,4,512] = neg qx
    rk:f32[512] = reduce_sum[axes=(0, 1, 2)] rj
    rl:f32[1,1,1,512] = reshape[dimensions=None new_sizes=(1, 1, 1, 512)] rk
    rm:f32[200,4,4,512] = add_any ri qx
    rn:f32[512] = reshape[dimensions=None new_sizes=(512,)] rl
    ro:f32[512] = add_any rf rn
    rp:f32[512] = div ro 3200.0
    rq:f32[200,4,4,512] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 4, 4, 512)
    ] rp
    rr:f32[200,4,4,512] = add_any rm rq
    rs:f32[1,1,256,512] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((0, -1), (0, -1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(2, 2)
      rhs_shape=(200, 4, 4, 512)
      window_strides=(1, 1)
    ] hh rr
    rt:f32[1,1,256,512] = rev[dimensions=(0, 1)] hg
    ru:f32[200,8,8,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(2, 2)
      lhs_shape=(200, 4, 4, 512)
      padding=((0, 1), (0, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(1, 1, 256, 512)
      window_strides=(1, 1)
    ] rr rt
    rv:f32[200,8,8,256] = add_any qq ru
    rw:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 8, 8, 256)
    ] 0.0
    rx:bool[200,8,8,256] = eq p True
    ry:f32[200,8,8,256] = select_n rx rw rv
    rz:f32[256] = reduce_sum[axes=(0, 1, 2)] ry
    sa:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] rz
    sb:f32[256] = reshape[dimensions=None new_sizes=(256,)] sa
    sc:f32[200,8,8,256] = mul s ry
    sd:f32[256] = reduce_sum[axes=(0, 1, 2)] sc
    se:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] sd
    sf:f32[200,8,8,256] = mul ry r
    sg:f32[1,1,1,256] = mul hb se
    sh:f32[1,1,1,256] = mul se ha
    si:f32[256] = reshape[dimensions=None new_sizes=(256,)] sg
    sj:f32[1,1,1,256] = mul sh hf
    sk:f32[256] = reshape[dimensions=None new_sizes=(256,)] sj
    sl:f32[256] = mul sk hc
    sm:f32[256] = neg sl
    sn:f32[256] = mul sm he
    so:f32[256] = div sl 12800.0
    sp:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] so
    sq:f32[200,8,8,256] = mul sp hd
    sr:f32[200,8,8,256] = neg sf
    ss:f32[256] = reduce_sum[axes=(0, 1, 2)] sr
    st:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] ss
    su:f32[200,8,8,256] = add_any sq sf
    sv:f32[256] = reshape[dimensions=None new_sizes=(256,)] st
    sw:f32[256] = add_any sn sv
    sx:f32[256] = div sw 12800.0
    sy:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] sx
    sz:f32[200,8,8,256] = add_any su sy
    ta:f32[3,3,256,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 8, 8, 256)
      window_strides=(1, 1)
    ] gz sz
    tb:f32[3,3,256,256] = rev[dimensions=(0, 1)] gy
    tc:f32[200,8,8,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 256, 256)
      window_strides=(1, 1)
    ] sz tb
    td:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 8, 8, 256)
    ] 0.0
    te:bool[200,8,8,256] = eq t True
    tf:f32[200,8,8,256] = select_n te td tc
    tg:f32[256] = reduce_sum[axes=(0, 1, 2)] tf
    th:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tg
    ti:f32[256] = reshape[dimensions=None new_sizes=(256,)] th
    tj:f32[200,8,8,256] = mul w tf
    tk:f32[256] = reduce_sum[axes=(0, 1, 2)] tj
    tl:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tk
    tm:f32[200,8,8,256] = mul tf v
    tn:f32[1,1,1,256] = mul gt tl
    to:f32[1,1,1,256] = mul tl gs
    tp:f32[256] = reshape[dimensions=None new_sizes=(256,)] tn
    tq:f32[1,1,1,256] = mul to gx
    tr:f32[256] = reshape[dimensions=None new_sizes=(256,)] tq
    ts:f32[256] = mul tr gu
    tt:f32[256] = neg ts
    tu:f32[256] = mul tt gw
    tv:f32[256] = div ts 12800.0
    tw:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] tv
    tx:f32[200,8,8,256] = mul tw gv
    ty:f32[200,8,8,256] = neg tm
    tz:f32[256] = reduce_sum[axes=(0, 1, 2)] ty
    ua:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] tz
    ub:f32[200,8,8,256] = add_any tx tm
    uc:f32[256] = reshape[dimensions=None new_sizes=(256,)] ua
    ud:f32[256] = add_any tu uc
    ue:f32[256] = div ud 12800.0
    uf:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] ue
    ug:f32[200,8,8,256] = add_any ub uf
    uh:f32[3,3,256,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 8, 8, 256)
      window_strides=(1, 1)
    ] gr ug
    ui:f32[3,3,256,256] = rev[dimensions=(0, 1)] gq
    uj:f32[200,8,8,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 256, 256)
      window_strides=(1, 1)
    ] ug ui
    uk:f32[200,8,8,256] = add_any ry uj
    ul:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 8, 8, 256)
    ] 0.0
    um:bool[200,8,8,256] = eq x True
    un:f32[200,8,8,256] = select_n um ul uk
    uo:f32[256] = reduce_sum[axes=(0, 1, 2)] un
    up:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] uo
    uq:f32[256] = reshape[dimensions=None new_sizes=(256,)] up
    ur:f32[200,8,8,256] = mul fw un
    us:f32[256] = reduce_sum[axes=(0, 1, 2)] ur
    ut:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] us
    uu:f32[200,8,8,256] = mul un fv
    uv:f32[1,1,1,256] = mul gl ut
    uw:f32[1,1,1,256] = mul ut gk
    ux:f32[256] = reshape[dimensions=None new_sizes=(256,)] uv
    uy:f32[1,1,1,256] = mul uw gp
    uz:f32[256] = reshape[dimensions=None new_sizes=(256,)] uy
    va:f32[256] = mul uz gm
    vb:f32[256] = neg va
    vc:f32[256] = mul vb go
    vd:f32[256] = div va 12800.0
    ve:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] vd
    vf:f32[200,8,8,256] = mul ve gn
    vg:f32[200,8,8,256] = neg uu
    vh:f32[256] = reduce_sum[axes=(0, 1, 2)] vg
    vi:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] vh
    vj:f32[200,8,8,256] = add_any vf uu
    vk:f32[256] = reshape[dimensions=None new_sizes=(256,)] vi
    vl:f32[256] = add_any vc vk
    vm:f32[256] = div vl 12800.0
    vn:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] vm
    vo:f32[200,8,8,256] = add_any vj vn
    vp:f32[3,3,256,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 8, 8, 256)
      window_strides=(1, 1)
    ] gj vo
    vq:f32[3,3,256,256] = rev[dimensions=(0, 1)] gi
    vr:f32[200,8,8,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 256, 256)
      window_strides=(1, 1)
    ] vo vq
    vs:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 8, 8, 256)
    ] 0.0
    vt:bool[200,8,8,256] = eq fx True
    vu:f32[200,8,8,256] = select_n vt vs vr
    vv:f32[256] = reduce_sum[axes=(0, 1, 2)] vu
    vw:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] vv
    vx:f32[256] = reshape[dimensions=None new_sizes=(256,)] vw
    vy:f32[200,8,8,256] = mul ga vu
    vz:f32[256] = reduce_sum[axes=(0, 1, 2)] vy
    wa:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] vz
    wb:f32[200,8,8,256] = mul vu fz
    wc:f32[1,1,1,256] = mul gd wa
    wd:f32[1,1,1,256] = mul wa gc
    we:f32[256] = reshape[dimensions=None new_sizes=(256,)] wc
    wf:f32[1,1,1,256] = mul wd gh
    wg:f32[256] = reshape[dimensions=None new_sizes=(256,)] wf
    wh:f32[256] = mul wg ge
    wi:f32[256] = neg wh
    wj:f32[256] = mul wi gg
    wk:f32[256] = div wh 12800.0
    wl:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] wk
    wm:f32[200,8,8,256] = mul wl gf
    wn:f32[200,8,8,256] = neg wb
    wo:f32[256] = reduce_sum[axes=(0, 1, 2)] wn
    wp:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] wo
    wq:f32[200,8,8,256] = add_any wm wb
    wr:f32[256] = reshape[dimensions=None new_sizes=(256,)] wp
    ws:f32[256] = add_any wj wr
    wt:f32[256] = div ws 12800.0
    wu:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] wt
    wv:f32[200,8,8,256] = add_any wq wu
    ww:f32[3,3,128,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 0), (1, 0))
      precision=None
      preferred_element_type=None
      rhs_dilation=(2, 2)
      rhs_shape=(200, 8, 8, 256)
      window_strides=(1, 1)
    ] fo wv
    wx:f32[3,3,128,256] = rev[dimensions=(0, 1)] gb
    wy:f32[200,16,16,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(2, 2)
      lhs_shape=(200, 8, 8, 256)
      padding=((1, 2), (1, 2))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 128, 256)
      window_strides=(1, 1)
    ] wv wx
    wz:f32[256] = reduce_sum[axes=(0, 1, 2)] un
    xa:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] wz
    xb:f32[256] = reshape[dimensions=None new_sizes=(256,)] xa
    xc:f32[200,8,8,256] = mul ba un
    xd:f32[256] = reduce_sum[axes=(0, 1, 2)] xc
    xe:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] xd
    xf:f32[200,8,8,256] = mul un z
    xg:f32[1,1,1,256] = mul fq xe
    xh:f32[1,1,1,256] = mul xe fp
    xi:f32[256] = reshape[dimensions=None new_sizes=(256,)] xg
    xj:f32[1,1,1,256] = mul xh fu
    xk:f32[256] = reshape[dimensions=None new_sizes=(256,)] xj
    xl:f32[256] = mul xk fr
    xm:f32[256] = neg xl
    xn:f32[256] = mul xm ft
    xo:f32[256] = div xl 12800.0
    xp:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] xo
    xq:f32[200,8,8,256] = mul xp fs
    xr:f32[200,8,8,256] = neg xf
    xs:f32[256] = reduce_sum[axes=(0, 1, 2)] xr
    xt:f32[1,1,1,256] = reshape[dimensions=None new_sizes=(1, 1, 1, 256)] xs
    xu:f32[200,8,8,256] = add_any xq xf
    xv:f32[256] = reshape[dimensions=None new_sizes=(256,)] xt
    xw:f32[256] = add_any xn xv
    xx:f32[256] = div xw 12800.0
    xy:f32[200,8,8,256] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 8, 8, 256)
    ] xx
    xz:f32[200,8,8,256] = add_any xu xy
    ya:f32[1,1,128,256] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((0, -1), (0, -1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(2, 2)
      rhs_shape=(200, 8, 8, 256)
      window_strides=(1, 1)
    ] fo xz
    yb:f32[1,1,128,256] = rev[dimensions=(0, 1)] fn
    yc:f32[200,16,16,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(2, 2)
      lhs_shape=(200, 8, 8, 256)
      padding=((0, 1), (0, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(1, 1, 128, 256)
      window_strides=(1, 1)
    ] xz yb
    yd:f32[200,16,16,128] = add_any wy yc
    ye:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 16, 16, 128)
    ] 0.0
    yf:bool[200,16,16,128] = eq bb True
    yg:f32[200,16,16,128] = select_n yf ye yd
    yh:f32[128] = reduce_sum[axes=(0, 1, 2)] yg
    yi:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] yh
    yj:f32[128] = reshape[dimensions=None new_sizes=(128,)] yi
    yk:f32[200,16,16,128] = mul be yg
    yl:f32[128] = reduce_sum[axes=(0, 1, 2)] yk
    ym:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] yl
    yn:f32[200,16,16,128] = mul yg bd
    yo:f32[1,1,1,128] = mul fi ym
    yp:f32[1,1,1,128] = mul ym fh
    yq:f32[128] = reshape[dimensions=None new_sizes=(128,)] yo
    yr:f32[1,1,1,128] = mul yp fm
    ys:f32[128] = reshape[dimensions=None new_sizes=(128,)] yr
    yt:f32[128] = mul ys fj
    yu:f32[128] = neg yt
    yv:f32[128] = mul yu fl
    yw:f32[128] = div yt 51200.0
    yx:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] yw
    yy:f32[200,16,16,128] = mul yx fk
    yz:f32[200,16,16,128] = neg yn
    za:f32[128] = reduce_sum[axes=(0, 1, 2)] yz
    zb:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] za
    zc:f32[200,16,16,128] = add_any yy yn
    zd:f32[128] = reshape[dimensions=None new_sizes=(128,)] zb
    ze:f32[128] = add_any yv zd
    zf:f32[128] = div ze 51200.0
    zg:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] zf
    zh:f32[200,16,16,128] = add_any zc zg
    zi:f32[3,3,128,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 16, 16, 128)
      window_strides=(1, 1)
    ] fg zh
    zj:f32[3,3,128,128] = rev[dimensions=(0, 1)] ff
    zk:f32[200,16,16,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 128, 128)
      window_strides=(1, 1)
    ] zh zj
    zl:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 16, 16, 128)
    ] 0.0
    zm:bool[200,16,16,128] = eq bf True
    zn:f32[200,16,16,128] = select_n zm zl zk
    zo:f32[128] = reduce_sum[axes=(0, 1, 2)] zn
    zp:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] zo
    zq:f32[128] = reshape[dimensions=None new_sizes=(128,)] zp
    zr:f32[200,16,16,128] = mul bi zn
    zs:f32[128] = reduce_sum[axes=(0, 1, 2)] zr
    zt:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] zs
    zu:f32[200,16,16,128] = mul zn bh
    zv:f32[1,1,1,128] = mul fa zt
    zw:f32[1,1,1,128] = mul zt ez
    zx:f32[128] = reshape[dimensions=None new_sizes=(128,)] zv
    zy:f32[1,1,1,128] = mul zw fe
    zz:f32[128] = reshape[dimensions=None new_sizes=(128,)] zy
    baa:f32[128] = mul zz fb
    bab:f32[128] = neg baa
    bac:f32[128] = mul bab fd
    bad:f32[128] = div baa 51200.0
    bae:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bad
    baf:f32[200,16,16,128] = mul bae fc
    bag:f32[200,16,16,128] = neg zu
    bah:f32[128] = reduce_sum[axes=(0, 1, 2)] bag
    bai:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bah
    baj:f32[200,16,16,128] = add_any baf zu
    bak:f32[128] = reshape[dimensions=None new_sizes=(128,)] bai
    bal:f32[128] = add_any bac bak
    bam:f32[128] = div bal 51200.0
    ban:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bam
    bao:f32[200,16,16,128] = add_any baj ban
    bap:f32[3,3,128,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 16, 16, 128)
      window_strides=(1, 1)
    ] ey bao
    baq:f32[3,3,128,128] = rev[dimensions=(0, 1)] ex
    bar:f32[200,16,16,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 128, 128)
      window_strides=(1, 1)
    ] bao baq
    bas:f32[200,16,16,128] = add_any yg bar
    bat:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 16, 16, 128)
    ] 0.0
    bau:bool[200,16,16,128] = eq bj True
    bav:f32[200,16,16,128] = select_n bau bat bas
    baw:f32[128] = reduce_sum[axes=(0, 1, 2)] bav
    bax:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] baw
    bay:f32[128] = reshape[dimensions=None new_sizes=(128,)] bax
    baz:f32[200,16,16,128] = mul ed bav
    bba:f32[128] = reduce_sum[axes=(0, 1, 2)] baz
    bbb:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bba
    bbc:f32[200,16,16,128] = mul bav ec
    bbd:f32[1,1,1,128] = mul es bbb
    bbe:f32[1,1,1,128] = mul bbb er
    bbf:f32[128] = reshape[dimensions=None new_sizes=(128,)] bbd
    bbg:f32[1,1,1,128] = mul bbe ew
    bbh:f32[128] = reshape[dimensions=None new_sizes=(128,)] bbg
    bbi:f32[128] = mul bbh et
    bbj:f32[128] = neg bbi
    bbk:f32[128] = mul bbj ev
    bbl:f32[128] = div bbi 51200.0
    bbm:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bbl
    bbn:f32[200,16,16,128] = mul bbm eu
    bbo:f32[200,16,16,128] = neg bbc
    bbp:f32[128] = reduce_sum[axes=(0, 1, 2)] bbo
    bbq:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bbp
    bbr:f32[200,16,16,128] = add_any bbn bbc
    bbs:f32[128] = reshape[dimensions=None new_sizes=(128,)] bbq
    bbt:f32[128] = add_any bbk bbs
    bbu:f32[128] = div bbt 51200.0
    bbv:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bbu
    bbw:f32[200,16,16,128] = add_any bbr bbv
    bbx:f32[3,3,128,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 16, 16, 128)
      window_strides=(1, 1)
    ] eq bbw
    bby:f32[3,3,128,128] = rev[dimensions=(0, 1)] ep
    bbz:f32[200,16,16,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 128, 128)
      window_strides=(1, 1)
    ] bbw bby
    bca:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 16, 16, 128)
    ] 0.0
    bcb:bool[200,16,16,128] = eq ee True
    bcc:f32[200,16,16,128] = select_n bcb bca bbz
    bcd:f32[128] = reduce_sum[axes=(0, 1, 2)] bcc
    bce:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bcd
    bcf:f32[128] = reshape[dimensions=None new_sizes=(128,)] bce
    bcg:f32[200,16,16,128] = mul eh bcc
    bch:f32[128] = reduce_sum[axes=(0, 1, 2)] bcg
    bci:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bch
    bcj:f32[200,16,16,128] = mul bcc eg
    bck:f32[1,1,1,128] = mul ek bci
    bcl:f32[1,1,1,128] = mul bci ej
    bcm:f32[128] = reshape[dimensions=None new_sizes=(128,)] bck
    bcn:f32[1,1,1,128] = mul bcl eo
    bco:f32[128] = reshape[dimensions=None new_sizes=(128,)] bcn
    bcp:f32[128] = mul bco el
    bcq:f32[128] = neg bcp
    bcr:f32[128] = mul bcq en
    bcs:f32[128] = div bcp 51200.0
    bct:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bcs
    bcu:f32[200,16,16,128] = mul bct em
    bcv:f32[200,16,16,128] = neg bcj
    bcw:f32[128] = reduce_sum[axes=(0, 1, 2)] bcv
    bcx:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bcw
    bcy:f32[200,16,16,128] = add_any bcu bcj
    bcz:f32[128] = reshape[dimensions=None new_sizes=(128,)] bcx
    bda:f32[128] = add_any bcr bcz
    bdb:f32[128] = div bda 51200.0
    bdc:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bdb
    bdd:f32[200,16,16,128] = add_any bcy bdc
    bde:f32[3,3,64,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 0), (1, 0))
      precision=None
      preferred_element_type=None
      rhs_dilation=(2, 2)
      rhs_shape=(200, 16, 16, 128)
      window_strides=(1, 1)
    ] dv bdd
    bdf:f32[3,3,64,128] = rev[dimensions=(0, 1)] ei
    bdg:f32[200,32,32,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(2, 2)
      lhs_shape=(200, 16, 16, 128)
      padding=((1, 2), (1, 2))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 64, 128)
      window_strides=(1, 1)
    ] bdd bdf
    bdh:f32[128] = reduce_sum[axes=(0, 1, 2)] bav
    bdi:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bdh
    bdj:f32[128] = reshape[dimensions=None new_sizes=(128,)] bdi
    bdk:f32[200,16,16,128] = mul bm bav
    bdl:f32[128] = reduce_sum[axes=(0, 1, 2)] bdk
    bdm:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bdl
    bdn:f32[200,16,16,128] = mul bav bl
    bdo:f32[1,1,1,128] = mul dx bdm
    bdp:f32[1,1,1,128] = mul bdm dw
    bdq:f32[128] = reshape[dimensions=None new_sizes=(128,)] bdo
    bdr:f32[1,1,1,128] = mul bdp eb
    bds:f32[128] = reshape[dimensions=None new_sizes=(128,)] bdr
    bdt:f32[128] = mul bds dy
    bdu:f32[128] = neg bdt
    bdv:f32[128] = mul bdu ea
    bdw:f32[128] = div bdt 51200.0
    bdx:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bdw
    bdy:f32[200,16,16,128] = mul bdx dz
    bdz:f32[200,16,16,128] = neg bdn
    bea:f32[128] = reduce_sum[axes=(0, 1, 2)] bdz
    beb:f32[1,1,1,128] = reshape[dimensions=None new_sizes=(1, 1, 1, 128)] bea
    bec:f32[200,16,16,128] = add_any bdy bdn
    bed:f32[128] = reshape[dimensions=None new_sizes=(128,)] beb
    bee:f32[128] = add_any bdv bed
    bef:f32[128] = div bee 51200.0
    beg:f32[200,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 16, 16, 128)
    ] bef
    beh:f32[200,16,16,128] = add_any bec beg
    bei:f32[1,1,64,128] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((0, -1), (0, -1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(2, 2)
      rhs_shape=(200, 16, 16, 128)
      window_strides=(1, 1)
    ] dv beh
    bej:f32[1,1,64,128] = rev[dimensions=(0, 1)] du
    bek:f32[200,32,32,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(2, 2)
      lhs_shape=(200, 16, 16, 128)
      padding=((0, 1), (0, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(1, 1, 64, 128)
      window_strides=(1, 1)
    ] beh bej
    bel:f32[200,32,32,64] = add_any bdg bek
    bem:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 32, 32, 64)
    ] 0.0
    ben:bool[200,32,32,64] = eq bn True
    beo:f32[200,32,32,64] = select_n ben bem bel
    bep:f32[64] = reduce_sum[axes=(0, 1, 2)] beo
    beq:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bep
    ber:f32[64] = reshape[dimensions=None new_sizes=(64,)] beq
    bes:f32[200,32,32,64] = mul bq beo
    bet:f32[64] = reduce_sum[axes=(0, 1, 2)] bes
    beu:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bet
    bev:f32[200,32,32,64] = mul beo bp
    bew:f32[1,1,1,64] = mul dp beu
    bex:f32[1,1,1,64] = mul beu do
    bey:f32[64] = reshape[dimensions=None new_sizes=(64,)] bew
    bez:f32[1,1,1,64] = mul bex dt
    bfa:f32[64] = reshape[dimensions=None new_sizes=(64,)] bez
    bfb:f32[64] = mul bfa dq
    bfc:f32[64] = neg bfb
    bfd:f32[64] = mul bfc ds
    bfe:f32[64] = div bfb 204800.0
    bff:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bfe
    bfg:f32[200,32,32,64] = mul bff dr
    bfh:f32[200,32,32,64] = neg bev
    bfi:f32[64] = reduce_sum[axes=(0, 1, 2)] bfh
    bfj:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bfi
    bfk:f32[200,32,32,64] = add_any bfg bev
    bfl:f32[64] = reshape[dimensions=None new_sizes=(64,)] bfj
    bfm:f32[64] = add_any bfd bfl
    bfn:f32[64] = div bfm 204800.0
    bfo:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bfn
    bfp:f32[200,32,32,64] = add_any bfk bfo
    bfq:f32[3,3,64,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 32, 32, 64)
      window_strides=(1, 1)
    ] dn bfp
    bfr:f32[3,3,64,64] = rev[dimensions=(0, 1)] dm
    bfs:f32[200,32,32,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 64, 64)
      window_strides=(1, 1)
    ] bfp bfr
    bft:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 32, 32, 64)
    ] 0.0
    bfu:bool[200,32,32,64] = eq br True
    bfv:f32[200,32,32,64] = select_n bfu bft bfs
    bfw:f32[64] = reduce_sum[axes=(0, 1, 2)] bfv
    bfx:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bfw
    bfy:f32[64] = reshape[dimensions=None new_sizes=(64,)] bfx
    bfz:f32[200,32,32,64] = mul bu bfv
    bga:f32[64] = reduce_sum[axes=(0, 1, 2)] bfz
    bgb:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bga
    bgc:f32[200,32,32,64] = mul bfv bt
    bgd:f32[1,1,1,64] = mul dh bgb
    bge:f32[1,1,1,64] = mul bgb dg
    bgf:f32[64] = reshape[dimensions=None new_sizes=(64,)] bgd
    bgg:f32[1,1,1,64] = mul bge dl
    bgh:f32[64] = reshape[dimensions=None new_sizes=(64,)] bgg
    bgi:f32[64] = mul bgh di
    bgj:f32[64] = neg bgi
    bgk:f32[64] = mul bgj dk
    bgl:f32[64] = div bgi 204800.0
    bgm:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bgl
    bgn:f32[200,32,32,64] = mul bgm dj
    bgo:f32[200,32,32,64] = neg bgc
    bgp:f32[64] = reduce_sum[axes=(0, 1, 2)] bgo
    bgq:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bgp
    bgr:f32[200,32,32,64] = add_any bgn bgc
    bgs:f32[64] = reshape[dimensions=None new_sizes=(64,)] bgq
    bgt:f32[64] = add_any bgk bgs
    bgu:f32[64] = div bgt 204800.0
    bgv:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bgu
    bgw:f32[200,32,32,64] = add_any bgr bgv
    bgx:f32[3,3,64,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 32, 32, 64)
      window_strides=(1, 1)
    ] df bgw
    bgy:f32[3,3,64,64] = rev[dimensions=(0, 1)] de
    bgz:f32[200,32,32,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 64, 64)
      window_strides=(1, 1)
    ] bgw bgy
    bha:f32[200,32,32,64] = add_any beo bgz
    bhb:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 32, 32, 64)
    ] 0.0
    bhc:bool[200,32,32,64] = eq bv True
    bhd:f32[200,32,32,64] = select_n bhc bhb bha
    bhe:f32[64] = reduce_sum[axes=(0, 1, 2)] bhd
    bhf:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bhe
    bhg:f32[64] = reshape[dimensions=None new_sizes=(64,)] bhf
    bhh:f32[200,32,32,64] = mul by bhd
    bhi:f32[64] = reduce_sum[axes=(0, 1, 2)] bhh
    bhj:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bhi
    bhk:f32[200,32,32,64] = mul bhd bx
    bhl:f32[1,1,1,64] = mul cz bhj
    bhm:f32[1,1,1,64] = mul bhj cy
    bhn:f32[64] = reshape[dimensions=None new_sizes=(64,)] bhl
    bho:f32[1,1,1,64] = mul bhm dd
    bhp:f32[64] = reshape[dimensions=None new_sizes=(64,)] bho
    bhq:f32[64] = mul bhp da
    bhr:f32[64] = neg bhq
    bhs:f32[64] = mul bhr dc
    bht:f32[64] = div bhq 204800.0
    bhu:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bht
    bhv:f32[200,32,32,64] = mul bhu db
    bhw:f32[200,32,32,64] = neg bhk
    bhx:f32[64] = reduce_sum[axes=(0, 1, 2)] bhw
    bhy:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bhx
    bhz:f32[200,32,32,64] = add_any bhv bhk
    bia:f32[64] = reshape[dimensions=None new_sizes=(64,)] bhy
    bib:f32[64] = add_any bhs bia
    bic:f32[64] = div bib 204800.0
    bid:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bic
    bie:f32[200,32,32,64] = add_any bhz bid
    bif:f32[3,3,64,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 32, 32, 64)
      window_strides=(1, 1)
    ] cx bie
    big:f32[3,3,64,64] = rev[dimensions=(0, 1)] cw
    bih:f32[200,32,32,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 64, 64)
      window_strides=(1, 1)
    ] bie big
    bii:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 32, 32, 64)
    ] 0.0
    bij:bool[200,32,32,64] = eq bz True
    bik:f32[200,32,32,64] = select_n bij bii bih
    bil:f32[64] = reduce_sum[axes=(0, 1, 2)] bik
    bim:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bil
    bin:f32[64] = reshape[dimensions=None new_sizes=(64,)] bim
    bio:f32[200,32,32,64] = mul cc bik
    bip:f32[64] = reduce_sum[axes=(0, 1, 2)] bio
    biq:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bip
    bir:f32[200,32,32,64] = mul bik cb
    bis:f32[1,1,1,64] = mul cr biq
    bit:f32[1,1,1,64] = mul biq cq
    biu:f32[64] = reshape[dimensions=None new_sizes=(64,)] bis
    biv:f32[1,1,1,64] = mul bit cv
    biw:f32[64] = reshape[dimensions=None new_sizes=(64,)] biv
    bix:f32[64] = mul biw cs
    biy:f32[64] = neg bix
    biz:f32[64] = mul biy cu
    bja:f32[64] = div bix 204800.0
    bjb:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bja
    bjc:f32[200,32,32,64] = mul bjb ct
    bjd:f32[200,32,32,64] = neg bir
    bje:f32[64] = reduce_sum[axes=(0, 1, 2)] bjd
    bjf:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bje
    bjg:f32[200,32,32,64] = add_any bjc bir
    bjh:f32[64] = reshape[dimensions=None new_sizes=(64,)] bjf
    bji:f32[64] = add_any biz bjh
    bjj:f32[64] = div bji 204800.0
    bjk:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bjj
    bjl:f32[200,32,32,64] = add_any bjg bjk
    bjm:f32[3,3,64,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 32, 32, 64)
      window_strides=(1, 1)
    ] cp bjl
    bjn:f32[3,3,64,64] = rev[dimensions=(0, 1)] co
    bjo:f32[200,32,32,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 64)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(3, 3, 64, 64)
      window_strides=(1, 1)
    ] bjl bjn
    bjp:f32[200,32,32,64] = add_any bhd bjo
    bjq:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=()
      shape=(200, 32, 32, 64)
    ] 0.0
    bjr:bool[200,32,32,64] = eq cd True
    bjs:f32[200,32,32,64] = select_n bjr bjq bjp
    bjt:f32[64] = reduce_sum[axes=(0, 1, 2)] bjs
    bju:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bjt
    bjv:f32[64] = reshape[dimensions=None new_sizes=(64,)] bju
    bjw:f32[200,32,32,64] = mul cg bjs
    bjx:f32[64] = reduce_sum[axes=(0, 1, 2)] bjw
    bjy:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bjx
    bjz:f32[200,32,32,64] = mul bjs cf
    bka:f32[1,1,1,64] = mul cj bjy
    bkb:f32[1,1,1,64] = mul bjy ci
    bkc:f32[64] = reshape[dimensions=None new_sizes=(64,)] bka
    bkd:f32[1,1,1,64] = mul bkb cn
    bke:f32[64] = reshape[dimensions=None new_sizes=(64,)] bkd
    bkf:f32[64] = mul bke ck
    bkg:f32[64] = neg bkf
    bkh:f32[64] = mul bkg cm
    bki:f32[64] = div bkf 204800.0
    bkj:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bki
    bkk:f32[200,32,32,64] = mul bkj cl
    bkl:f32[200,32,32,64] = neg bjz
    bkm:f32[64] = reduce_sum[axes=(0, 1, 2)] bkl
    bkn:f32[1,1,1,64] = reshape[dimensions=None new_sizes=(1, 1, 1, 64)] bkm
    bko:f32[200,32,32,64] = add_any bkk bjz
    bkp:f32[64] = reshape[dimensions=None new_sizes=(64,)] bkn
    bkq:f32[64] = add_any bkh bkp
    bkr:f32[64] = div bkq 204800.0
    bks:f32[200,32,32,64] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(200, 32, 32, 64)
    ] bkr
    bkt:f32[200,32,32,64] = add_any bko bks
    bku:f32[3,3,3,64] = conv_general_dilated[
      batch_group_count=1
      dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1))
      feature_group_count=1
      lhs_dilation=(1, 1)
      lhs_shape=(200, 32, 32, 3)
      padding=((1, 1), (1, 1))
      precision=None
      preferred_element_type=None
      rhs_dilation=(1, 1)
      rhs_shape=(200, 32, 32, 64)
      window_strides=(1, 1)
    ] ch bkt
  in (li, lk, bin, biu, bhg, bhn, bjm, bif, bfy, bgf, ber, bey, bgx, bfq, bcf, bcm,
    bay, bbf, bde, bbx, bei, bdj, bdq, zq, zx, yj, yq, bap, zi, vx, we, uq, ux, ww,
    vp, ya, xb, xi, ti, tp, sb, si, uh, ta, pp, pw, oi, op, qo, ph, rs, qt, ra, na,
    nh, lt, ma, nz, ms, bjv, bkc, bku) }, ())

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train/trainer.py", line 439, in <module>
    app.run(_main)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/absl/app.py", line 312, in run
    _run_main(main, args)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/absl/app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "train/trainer.py", line 437, in _main
    main(config)
  File "train/trainer.py", line 299, in main
    state = train_model(
  File "train/trainer.py", line 343, in train_model
    state, train_metrics = train_epoch(
  File "/home/shreyaspadhy_gmail_com/linearised-NNs/jaxutils/train/utils.py", line 95, in train_epoch
    state, metrics = train_step_fn(state, *batch)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/_src/api.py", line 2156, in cache_miss
    out_tree, out_flat = f_pmapped_(*args, **kwargs)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/_src/api.py", line 2032, in pmap_f
    out = pxla.xla_pmap(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/core.py", line 2040, in bind
    return map_bind(self, fun, *args, **params)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/core.py", line 2072, in map_bind
    outs = primitive.process(top_trace, fun, tracers, params)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/core.py", line 2043, in process
    return trace.process_map(self, fun, tracers, params)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/core.py", line 687, in process_call
    return primitive.impl(f, *tracers, **params)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/pxla.py", line 907, in xla_pmap_impl
    compiled_fun, fingerprint = parallel_callable(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/linear_util.py", line 295, in memoized_fun
    ans = call(fun, *args)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/pxla.py", line 935, in parallel_callable
    pmap_computation = lower_parallel_callable(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/pxla.py", line 1170, in lower_parallel_callable
    lowering_result = mlir.lower_jaxpr_to_module(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 618, in lower_jaxpr_to_module
    lower_jaxpr_to_fun(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 881, in lower_jaxpr_to_fun
    out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1008, in jaxpr_subcomp
    ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1119, in _xla_call_lower
    out_nodes, tokens = _call_lowering(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1105, in _call_lowering
    symbol_name = _lower_jaxpr_to_fun_cached(ctx, fn_name, call_jaxpr, effects).name.value
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1089, in _lower_jaxpr_to_fun_cached
    func_op = lower_jaxpr_to_fun(ctx, fn_name, call_jaxpr, effects)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 881, in lower_jaxpr_to_fun
    out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1008, in jaxpr_subcomp
    ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1119, in _xla_call_lower
    out_nodes, tokens = _call_lowering(
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1105, in _call_lowering
    symbol_name = _lower_jaxpr_to_fun_cached(ctx, fn_name, call_jaxpr, effects).name.value
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 1089, in _lower_jaxpr_to_fun_cached
    func_op = lower_jaxpr_to_fun(ctx, fn_name, call_jaxpr, effects)
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 881, in lower_jaxpr_to_fun
    out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),
  File "/home/shreyaspadhy_gmail_com/.local/lib/python3.8/site-packages/jax/interpreters/mlir.py", line 978, in jaxpr_subcomp
    loc = _source_info_to_location(eqn.primitive, eqn.params, source_info,
KeyboardInterrupt
2022-08-20 02:21:05.694003: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
